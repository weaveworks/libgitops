diff --git a/Makefile b/Makefile
index 4f3230b..1f2c88b 100644
--- a/Makefile
+++ b/Makefile
@@ -1,5 +1,5 @@
 UID_GID ?= $(shell id -u):$(shell id -g)
-GO_VERSION ?= 1.14.4
+GO_VERSION ?= 1.15.6
 GIT_VERSION := $(shell hack/ldflags.sh --version-only)
 PROJECT := github.com/weaveworks/libgitops
 BOUNDING_API_DIRS := ${PROJECT}/cmd/apis/sample
@@ -7,7 +7,6 @@ API_DIRS := ${PROJECT}/cmd/sample-app/apis/sample,${PROJECT}/cmd/sample-app/apis
 SRC_PKGS := cmd pkg
 DOCKER_ARGS := --rm
 CACHE_DIR := $(shell pwd)/bin/cache
-API_DOCS := api/sample-app.md api/runtime.md
 BINARIES := bin/sample-app bin/sample-gitops bin/sample-watch
 
 # If we're not running in CI, run Docker interactively
@@ -39,7 +38,6 @@ test-internal:
 tidy: docker-tidy-internal
 tidy-internal: /go/bin/goimports
 	go mod tidy
-	hack/generate-client.sh
 	gofmt -s -w ${SRC_PKGS}
 	goimports -w ${SRC_PKGS}
 
diff --git a/cmd/common/common.go b/cmd/common/common.go
index dcba7c6..f011dac 100644
--- a/cmd/common/common.go
+++ b/cmd/common/common.go
@@ -13,8 +13,8 @@ import (
 	"github.com/spf13/pflag"
 	"github.com/weaveworks/libgitops/cmd/sample-app/apis/sample/v1alpha1"
 	"github.com/weaveworks/libgitops/cmd/sample-app/version"
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/storage"
+	"github.com/weaveworks/libgitops/pkg/storage/client"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
 )
 
 var (
@@ -25,10 +25,6 @@ func init() {
 	rand.Seed(time.Now().UnixNano())
 }
 
-func CarKeyForName(name string) storage.ObjectKey {
-	return storage.NewObjectKey(storage.NewKindKey(CarGVK), runtime.NewIdentifier("default/"+name))
-}
-
 func NewCar(name string) *v1alpha1.Car {
 	obj := &v1alpha1.Car{}
 	obj.Name = name
@@ -38,17 +34,17 @@ func NewCar(name string) *v1alpha1.Car {
 	return obj
 }
 
-func SetNewCarStatus(s storage.Storage, key storage.ObjectKey) error {
-	obj, err := s.Get(key)
+func SetNewCarStatus(ctx context.Context, c client.Client, name string) error {
+	car := &v1alpha1.Car{}
+	err := c.Get(ctx, core.ObjectKey{Name: name}, car)
 	if err != nil {
 		return err
 	}
 
-	car := obj.(*v1alpha1.Car)
 	car.Status.Distance = rand.Uint64()
 	car.Status.Speed = rand.Float64() * 100
 
-	return s.Update(car)
+	return c.Update(ctx, car)
 }
 
 func ParseVersionFlag() {
@@ -75,8 +71,8 @@ func NewEcho() *echo.Echo {
 func StartEcho(e *echo.Echo) error {
 	// Start the server
 	go func() {
-		if err := e.Start(":8888"); err != nil {
-			e.Logger.Info("shutting down the server")
+		if err := e.Start(":8881"); err != nil {
+			e.Logger.Info("shutting down the server", err)
 		}
 	}()
 
diff --git a/pkg/logs/flag/flag.go b/cmd/common/logs/flag/flag.go
similarity index 84%
rename from pkg/logs/flag/flag.go
rename to cmd/common/logs/flag/flag.go
index 3c226cf..83f5967 100644
--- a/pkg/logs/flag/flag.go
+++ b/cmd/common/logs/flag/flag.go
@@ -5,6 +5,9 @@ import (
 	"github.com/spf13/pflag"
 )
 
+// TODO: Use these flags in the sample binaries?
+// TODO: Move to the way controller-runtime does logs instead?
+
 type LogLevelFlag struct {
 	value *logrus.Level
 }
diff --git a/pkg/logs/logs.go b/cmd/common/logs/logs.go
similarity index 95%
rename from pkg/logs/logs.go
rename to cmd/common/logs/logs.go
index 1ca78f1..c5b11a8 100644
--- a/pkg/logs/logs.go
+++ b/cmd/common/logs/logs.go
@@ -8,6 +8,8 @@ import (
 	log "github.com/sirupsen/logrus"
 )
 
+// TODO: Move to the way controller-runtime does logs instead?
+
 // Quiet specifies whether to only print machine-readable IDs
 var Quiet bool
 
diff --git a/cmd/sample-app/client/client.go b/cmd/sample-app/client/client.go
deleted file mode 100644
index e4d9824..0000000
--- a/cmd/sample-app/client/client.go
+++ /dev/null
@@ -1,61 +0,0 @@
-// TODO: Docs
-
-// +build ignore
-
-package client
-
-import (
-	api "github.com/weaveworks/libgitops/cmd/sample-app/apis/sample"
-	"github.com/weaveworks/libgitops/pkg/client"
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/storage"
-
-	"k8s.io/apimachinery/pkg/runtime/schema"
-)
-
-// TODO: Autogenerate this!
-
-// NewClient creates a client for the specified storage
-func NewClient(s storage.Storage) *Client {
-	return &Client{
-		SampleInternalClient: NewSampleInternalClient(s),
-	}
-}
-
-// Client is a struct providing high-level access to objects in a storage
-// The resource-specific client interfaces are automatically generated based
-// off client_resource_template.go. The auto-generation can be done with hack/client.sh
-// At the moment SampleInternalClient is the default client. If more than this client
-// is created in the future, the SampleInternalClient will be accessible under
-// Client.SampleInternal() instead.
-type Client struct {
-	*SampleInternalClient
-}
-
-func NewSampleInternalClient(s storage.Storage) *SampleInternalClient {
-	return &SampleInternalClient{
-		storage:        s,
-		dynamicClients: map[schema.GroupVersionKind]client.DynamicClient{},
-		gv:             api.SchemeGroupVersion,
-	}
-}
-
-type SampleInternalClient struct {
-	storage          storage.Storage
-	gv               schema.GroupVersion
-	carClient        CarClient
-	motorcycleClient MotorcycleClient
-	dynamicClients   map[schema.GroupVersionKind]client.DynamicClient
-}
-
-// Dynamic returns the DynamicClient for the Client instance, for the specific kind
-func (c *SampleInternalClient) Dynamic(kind runtime.Kind) (dc client.DynamicClient) {
-	var ok bool
-	gvk := c.gv.WithKind(kind.Title())
-	if dc, ok = c.dynamicClients[gvk]; !ok {
-		dc = client.NewDynamicClient(c.storage, gvk)
-		c.dynamicClients[gvk] = dc
-	}
-
-	return
-}
diff --git a/cmd/sample-app/client/zz_generated.client_car.go b/cmd/sample-app/client/zz_generated.client_car.go
deleted file mode 100644
index 2661d45..0000000
--- a/cmd/sample-app/client/zz_generated.client_car.go
+++ /dev/null
@@ -1,152 +0,0 @@
-// +build ignore
-
-/*
-	Note: This file is autogenerated! Do not edit it manually!
-	Edit client_car_template.go instead, and run
-	hack/generate-client.sh afterwards.
-*/
-
-package client
-
-import (
-	"fmt"
-
-	api "github.com/weaveworks/libgitops/cmd/sample-app/apis/sample"
-
-	log "github.com/sirupsen/logrus"
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/storage"
-	"github.com/weaveworks/libgitops/pkg/storage/filterer"
-	"k8s.io/apimachinery/pkg/runtime/schema"
-)
-
-// CarClient is an interface for accessing Car-specific API objects
-type CarClient interface {
-	// New returns a new Car
-	New() *api.Car
-	// Get returns the Car matching given UID from the storage
-	Get(runtime.UID) (*api.Car, error)
-	// Set saves the given Car into persistent storage
-	Set(*api.Car) error
-	// Patch performs a strategic merge patch on the object with
-	// the given UID, using the byte-encoded patch given
-	Patch(runtime.UID, []byte) error
-	// Find returns the Car matching the given filter, filters can
-	// match e.g. the Object's Name, UID or a specific property
-	Find(filter filterer.BaseFilter) (*api.Car, error)
-	// FindAll returns multiple Cars matching the given filter, filters can
-	// match e.g. the Object's Name, UID or a specific property
-	FindAll(filter filterer.BaseFilter) ([]*api.Car, error)
-	// Delete deletes the Car with the given UID from the storage
-	Delete(uid runtime.UID) error
-	// List returns a list of all Cars available
-	List() ([]*api.Car, error)
-}
-
-// Cars returns the CarClient for the Client object
-func (c *SampleInternalClient) Cars() CarClient {
-	if c.carClient == nil {
-		c.carClient = newCarClient(c.storage, c.gv)
-	}
-
-	return c.carClient
-}
-
-// carClient is a struct implementing the CarClient interface
-// It uses a shared storage instance passed from the Client together with its own Filterer
-type carClient struct {
-	storage  storage.Storage
-	filterer *filterer.Filterer
-	gvk      schema.GroupVersionKind
-}
-
-// newCarClient builds the carClient struct using the storage implementation and a new Filterer
-func newCarClient(s storage.Storage, gv schema.GroupVersion) CarClient {
-	return &carClient{
-		storage:  s,
-		filterer: filterer.NewFilterer(s),
-		gvk:      gv.WithKind(api.KindCar.Title()),
-	}
-}
-
-// New returns a new Object of its kind
-func (c *carClient) New() *api.Car {
-	log.Tracef("Client.New; GVK: %v", c.gvk)
-	obj, err := c.storage.New(c.gvk)
-	if err != nil {
-		panic(fmt.Sprintf("Client.New must not return an error: %v", err))
-	}
-	return obj.(*api.Car)
-}
-
-// Find returns a single Car based on the given Filter
-func (c *carClient) Find(filter filterer.BaseFilter) (*api.Car, error) {
-	log.Tracef("Client.Find; GVK: %v", c.gvk)
-	object, err := c.filterer.Find(c.gvk, filter)
-	if err != nil {
-		return nil, err
-	}
-
-	return object.(*api.Car), nil
-}
-
-// FindAll returns multiple Cars based on the given Filter
-func (c *carClient) FindAll(filter filterer.BaseFilter) ([]*api.Car, error) {
-	log.Tracef("Client.FindAll; GVK: %v", c.gvk)
-	matches, err := c.filterer.FindAll(c.gvk, filter)
-	if err != nil {
-		return nil, err
-	}
-
-	results := make([]*api.Car, 0, len(matches))
-	for _, item := range matches {
-		results = append(results, item.(*api.Car))
-	}
-
-	return results, nil
-}
-
-// Get returns the Car matching given UID from the storage
-func (c *carClient) Get(uid runtime.UID) (*api.Car, error) {
-	log.Tracef("Client.Get; UID: %q, GVK: %v", uid, c.gvk)
-	object, err := c.storage.Get(c.gvk, uid)
-	if err != nil {
-		return nil, err
-	}
-
-	return object.(*api.Car), nil
-}
-
-// Set saves the given Car into the persistent storage
-func (c *carClient) Set(car *api.Car) error {
-	log.Tracef("Client.Set; UID: %q, GVK: %v", car.GetUID(), c.gvk)
-	return c.storage.Set(c.gvk, car)
-}
-
-// Patch performs a strategic merge patch on the object with
-// the given UID, using the byte-encoded patch given
-func (c *carClient) Patch(uid runtime.UID, patch []byte) error {
-	return c.storage.Patch(c.gvk, uid, patch)
-}
-
-// Delete deletes the Car from the storage
-func (c *carClient) Delete(uid runtime.UID) error {
-	log.Tracef("Client.Delete; UID: %q, GVK: %v", uid, c.gvk)
-	return c.storage.Delete(c.gvk, uid)
-}
-
-// List returns a list of all Cars available
-func (c *carClient) List() ([]*api.Car, error) {
-	log.Tracef("Client.List; GVK: %v", c.gvk)
-	list, err := c.storage.List(c.gvk)
-	if err != nil {
-		return nil, err
-	}
-
-	results := make([]*api.Car, 0, len(list))
-	for _, item := range list {
-		results = append(results, item.(*api.Car))
-	}
-
-	return results, nil
-}
diff --git a/cmd/sample-app/client/zz_generated.client_motorcycle.go b/cmd/sample-app/client/zz_generated.client_motorcycle.go
deleted file mode 100644
index 7256e00..0000000
--- a/cmd/sample-app/client/zz_generated.client_motorcycle.go
+++ /dev/null
@@ -1,152 +0,0 @@
-// +build ignore
-
-/*
-	Note: This file is autogenerated! Do not edit it manually!
-	Edit client_motorcycle_template.go instead, and run
-	hack/generate-client.sh afterwards.
-*/
-
-package client
-
-import (
-	"fmt"
-
-	api "github.com/weaveworks/libgitops/cmd/sample-app/apis/sample"
-
-	log "github.com/sirupsen/logrus"
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/storage"
-	"github.com/weaveworks/libgitops/pkg/storage/filterer"
-	"k8s.io/apimachinery/pkg/runtime/schema"
-)
-
-// MotorcycleClient is an interface for accessing Motorcycle-specific API objects
-type MotorcycleClient interface {
-	// New returns a new Motorcycle
-	New() *api.Motorcycle
-	// Get returns the Motorcycle matching given UID from the storage
-	Get(runtime.UID) (*api.Motorcycle, error)
-	// Set saves the given Motorcycle into persistent storage
-	Set(*api.Motorcycle) error
-	// Patch performs a strategic merge patch on the object with
-	// the given UID, using the byte-encoded patch given
-	Patch(runtime.UID, []byte) error
-	// Find returns the Motorcycle matching the given filter, filters can
-	// match e.g. the Object's Name, UID or a specific property
-	Find(filter filterer.BaseFilter) (*api.Motorcycle, error)
-	// FindAll returns multiple Motorcycles matching the given filter, filters can
-	// match e.g. the Object's Name, UID or a specific property
-	FindAll(filter filterer.BaseFilter) ([]*api.Motorcycle, error)
-	// Delete deletes the Motorcycle with the given UID from the storage
-	Delete(uid runtime.UID) error
-	// List returns a list of all Motorcycles available
-	List() ([]*api.Motorcycle, error)
-}
-
-// Motorcycles returns the MotorcycleClient for the Client object
-func (c *SampleInternalClient) Motorcycles() MotorcycleClient {
-	if c.motorcycleClient == nil {
-		c.motorcycleClient = newMotorcycleClient(c.storage, c.gv)
-	}
-
-	return c.motorcycleClient
-}
-
-// motorcycleClient is a struct implementing the MotorcycleClient interface
-// It uses a shared storage instance passed from the Client together with its own Filterer
-type motorcycleClient struct {
-	storage  storage.Storage
-	filterer *filterer.Filterer
-	gvk      schema.GroupVersionKind
-}
-
-// newMotorcycleClient builds the motorcycleClient struct using the storage implementation and a new Filterer
-func newMotorcycleClient(s storage.Storage, gv schema.GroupVersion) MotorcycleClient {
-	return &motorcycleClient{
-		storage:  s,
-		filterer: filterer.NewFilterer(s),
-		gvk:      gv.WithKind(api.KindMotorcycle.Title()),
-	}
-}
-
-// New returns a new Object of its kind
-func (c *motorcycleClient) New() *api.Motorcycle {
-	log.Tracef("Client.New; GVK: %v", c.gvk)
-	obj, err := c.storage.New(c.gvk)
-	if err != nil {
-		panic(fmt.Sprintf("Client.New must not return an error: %v", err))
-	}
-	return obj.(*api.Motorcycle)
-}
-
-// Find returns a single Motorcycle based on the given Filter
-func (c *motorcycleClient) Find(filter filterer.BaseFilter) (*api.Motorcycle, error) {
-	log.Tracef("Client.Find; GVK: %v", c.gvk)
-	object, err := c.filterer.Find(c.gvk, filter)
-	if err != nil {
-		return nil, err
-	}
-
-	return object.(*api.Motorcycle), nil
-}
-
-// FindAll returns multiple Motorcycles based on the given Filter
-func (c *motorcycleClient) FindAll(filter filterer.BaseFilter) ([]*api.Motorcycle, error) {
-	log.Tracef("Client.FindAll; GVK: %v", c.gvk)
-	matches, err := c.filterer.FindAll(c.gvk, filter)
-	if err != nil {
-		return nil, err
-	}
-
-	results := make([]*api.Motorcycle, 0, len(matches))
-	for _, item := range matches {
-		results = append(results, item.(*api.Motorcycle))
-	}
-
-	return results, nil
-}
-
-// Get returns the Motorcycle matching given UID from the storage
-func (c *motorcycleClient) Get(uid runtime.UID) (*api.Motorcycle, error) {
-	log.Tracef("Client.Get; UID: %q, GVK: %v", uid, c.gvk)
-	object, err := c.storage.Get(c.gvk, uid)
-	if err != nil {
-		return nil, err
-	}
-
-	return object.(*api.Motorcycle), nil
-}
-
-// Set saves the given Motorcycle into the persistent storage
-func (c *motorcycleClient) Set(motorcycle *api.Motorcycle) error {
-	log.Tracef("Client.Set; UID: %q, GVK: %v", motorcycle.GetUID(), c.gvk)
-	return c.storage.Set(c.gvk, motorcycle)
-}
-
-// Patch performs a strategic merge patch on the object with
-// the given UID, using the byte-encoded patch given
-func (c *motorcycleClient) Patch(uid runtime.UID, patch []byte) error {
-	return c.storage.Patch(c.gvk, uid, patch)
-}
-
-// Delete deletes the Motorcycle from the storage
-func (c *motorcycleClient) Delete(uid runtime.UID) error {
-	log.Tracef("Client.Delete; UID: %q, GVK: %v", uid, c.gvk)
-	return c.storage.Delete(c.gvk, uid)
-}
-
-// List returns a list of all Motorcycles available
-func (c *motorcycleClient) List() ([]*api.Motorcycle, error) {
-	log.Tracef("Client.List; GVK: %v", c.gvk)
-	list, err := c.storage.List(c.gvk)
-	if err != nil {
-		return nil, err
-	}
-
-	results := make([]*api.Motorcycle, 0, len(list))
-	for _, item := range list {
-		results = append(results, item.(*api.Motorcycle))
-	}
-
-	return results, nil
-}
diff --git a/cmd/sample-app/main.go b/cmd/sample-app/main.go
index ea119a9..2812acc 100644
--- a/cmd/sample-app/main.go
+++ b/cmd/sample-app/main.go
@@ -2,7 +2,10 @@ package main
 
 import (
 	"bytes"
+	"context"
+	"encoding/json"
 	"fmt"
+	"io/ioutil"
 	"net/http"
 	"os"
 
@@ -10,12 +13,19 @@ import (
 	"github.com/sirupsen/logrus"
 	"github.com/spf13/pflag"
 	"github.com/weaveworks/libgitops/cmd/common"
+	"github.com/weaveworks/libgitops/cmd/common/logs"
 	"github.com/weaveworks/libgitops/cmd/sample-app/apis/sample/scheme"
 	"github.com/weaveworks/libgitops/cmd/sample-app/apis/sample/v1alpha1"
-	"github.com/weaveworks/libgitops/pkg/logs"
-	"github.com/weaveworks/libgitops/pkg/runtime"
 	"github.com/weaveworks/libgitops/pkg/serializer"
-	"github.com/weaveworks/libgitops/pkg/storage"
+	"github.com/weaveworks/libgitops/pkg/storage/backend"
+	"github.com/weaveworks/libgitops/pkg/storage/client"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem"
+	"github.com/weaveworks/libgitops/pkg/storage/kube"
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
+	"k8s.io/apimachinery/pkg/types"
+	ctrlclient "sigs.k8s.io/controller-runtime/pkg/client"
 )
 
 var manifestDirFlag = pflag.String("data-dir", "/tmp/libgitops/manifest", "Where to store the YAML files")
@@ -25,27 +35,43 @@ func main() {
 	common.ParseVersionFlag()
 
 	// Run the application
-	if err := run(); err != nil {
+	if err := run(*manifestDirFlag); err != nil {
 		fmt.Println(err)
 		os.Exit(1)
 	}
 }
 
-func run() error {
+func run(manifestDir string) error {
+	ctx := context.Background()
 	// Create the manifest directory
-	if err := os.MkdirAll(*manifestDirFlag, 0755); err != nil {
+	if err := os.MkdirAll(manifestDir, 0755); err != nil {
 		return err
 	}
 
 	// Set the log level
 	logs.Logger.SetLevel(logrus.InfoLevel)
 
-	plainStorage := storage.NewGenericStorage(
-		storage.NewGenericRawStorage(*manifestDirFlag, v1alpha1.SchemeGroupVersion, serializer.ContentTypeYAML),
-		scheme.Serializer,
-		[]runtime.IdentifierFactory{runtime.Metav1NameIdentifier},
+	s, err := filesystem.NewSimpleStorage(
+		manifestDir,
+		core.StaticNamespacer{NamespacedIsDefaultPolicy: false},
+		filesystem.SimpleFileFinderOptions{
+			DisableGroupDirectory: true,
+			ContentType:           serializer.ContentTypeYAML,
+		},
 	)
-	defer func() { _ = plainStorage.Close() }()
+	if err != nil {
+		return err
+	}
+
+	b, err := backend.NewGeneric(s, scheme.Serializer, kube.NewNamespaceEnforcer(), nil, nil)
+	if err != nil {
+		return err
+	}
+
+	plainClient, err := client.NewGeneric(b, scheme.Serializer.Patcher())
+	if err != nil {
+		return err
+	}
 
 	e := common.NewEcho()
 
@@ -55,7 +81,8 @@ func run() error {
 			return echo.NewHTTPError(http.StatusBadRequest, "Please set name")
 		}
 
-		obj, err := plainStorage.Get(common.CarKeyForName(name))
+		obj := &v1alpha1.Car{}
+		err := plainClient.Get(ctx, core.ObjectKey{Name: name}, obj)
 		if err != nil {
 			return err
 		}
@@ -66,13 +93,92 @@ func run() error {
 		return c.JSONBlob(http.StatusOK, content.Bytes())
 	})
 
+	e.GET("/meta/", func(c echo.Context) error {
+		list := &metav1.PartialObjectMetadataList{}
+		list.SetGroupVersionKind(v1alpha1.SchemeGroupVersion.WithKind("CarList"))
+		err := plainClient.List(ctx, list)
+		if err != nil {
+			return err
+		}
+		var content bytes.Buffer
+		if err := scheme.Serializer.Encoder().Encode(serializer.NewJSONFrameWriter(&content), list); err != nil {
+			return err
+		}
+		return c.JSONBlob(http.StatusOK, content.Bytes())
+	})
+
+	e.GET("/meta/:name", func(c echo.Context) error {
+		name := c.Param("name")
+		if len(name) == 0 {
+			return echo.NewHTTPError(http.StatusBadRequest, "Please set name")
+		}
+
+		obj := &metav1.PartialObjectMetadata{}
+		obj.SetGroupVersionKind(v1alpha1.SchemeGroupVersion.WithKind("Car"))
+		err := plainClient.Get(ctx, core.ObjectKey{
+			Name: name,
+		}, obj)
+		if err != nil {
+			return err
+		}
+		var content bytes.Buffer
+		if err := scheme.Serializer.Encoder().Encode(serializer.NewJSONFrameWriter(&content), obj); err != nil {
+			return err
+		}
+		return c.JSONBlob(http.StatusOK, content.Bytes())
+	})
+
+	e.GET("/unstructured/", func(c echo.Context) error {
+		list := &unstructured.UnstructuredList{}
+		list.SetGroupVersionKind(v1alpha1.SchemeGroupVersion.WithKind("CarList"))
+		err := plainClient.List(ctx, list)
+		if err != nil {
+			return err
+		}
+		var content bytes.Buffer
+		if err := scheme.Serializer.Encoder().Encode(serializer.NewJSONFrameWriter(&content), list); err != nil {
+			return err
+		}
+		var newcontent bytes.Buffer
+		if err := json.Indent(&newcontent, content.Bytes(), "", "  "); err != nil {
+			return err
+		}
+		return c.JSONBlob(http.StatusOK, newcontent.Bytes())
+	})
+
+	e.GET("/unstructured/:name", func(c echo.Context) error {
+		name := c.Param("name")
+		if len(name) == 0 {
+			return echo.NewHTTPError(http.StatusBadRequest, "Please set name")
+		}
+
+		obj := &unstructured.Unstructured{}
+		obj.SetGroupVersionKind(v1alpha1.SchemeGroupVersion.WithKind("Car"))
+		err := plainClient.Get(ctx, core.ObjectKey{
+			Name: name,
+		}, obj)
+		if err != nil {
+			return err
+		}
+		var content bytes.Buffer
+		// This does for some reason not pretty-encode the output
+		if err := scheme.Serializer.Encoder().Encode(serializer.NewJSONFrameWriter(&content), obj); err != nil {
+			return err
+		}
+		var newcontent bytes.Buffer
+		if err := json.Indent(&newcontent, content.Bytes(), "", "  "); err != nil {
+			return err
+		}
+		return c.JSONBlob(http.StatusOK, newcontent.Bytes())
+	})
+
 	e.POST("/plain/:name", func(c echo.Context) error {
 		name := c.Param("name")
 		if len(name) == 0 {
 			return echo.NewHTTPError(http.StatusBadRequest, "Please set name")
 		}
 
-		if err := plainStorage.Create(common.NewCar(name)); err != nil {
+		if err := plainClient.Create(ctx, common.NewCar(name)); err != nil {
 			return err
 		}
 		return c.String(200, "OK!")
@@ -84,11 +190,45 @@ func run() error {
 			return echo.NewHTTPError(http.StatusBadRequest, "Please set name")
 		}
 
-		if err := common.SetNewCarStatus(plainStorage, common.CarKeyForName(name)); err != nil {
+		if err := common.SetNewCarStatus(ctx, plainClient, name); err != nil {
 			return err
 		}
 		return c.String(200, "OK!")
 	})
 
+	e.PATCH("/plain/:name", func(c echo.Context) error {
+		name := c.Param("name")
+		if len(name) == 0 {
+			return echo.NewHTTPError(http.StatusBadRequest, "Please set name")
+		}
+
+		body, err := ioutil.ReadAll(c.Request().Body)
+		if err != nil {
+			return err
+		}
+		c.Request().Body.Close()
+
+		car := &v1alpha1.Car{}
+		err = plainClient.Get(ctx, core.ObjectKey{
+			Name: name,
+		}, car)
+		if err != nil {
+			return err
+		}
+
+		if err := plainClient.Patch(ctx, car, ctrlclient.RawPatch(types.MergePatchType, body)); err != nil {
+			return err
+		}
+
+		return c.JSON(200, car)
+	})
+
 	return common.StartEcho(e)
 }
+
+/*
+type noNamespacesRESTMapper struct{}
+
+func (noNamespacesRESTMapper) RESTMapping(gk schema.GroupKind, versions ...string) (*meta.RESTMapping, error) {
+	return &meta.RESTMapping{Scope: meta.RESTScopeRoot}, nil
+}*/
diff --git a/cmd/sample-gitops/main.go b/cmd/sample-gitops/main.go
index e8c2180..d18a9d5 100644
--- a/cmd/sample-gitops/main.go
+++ b/cmd/sample-gitops/main.go
@@ -1,9 +1,11 @@
 package main
 
 import (
+	"bytes"
 	"context"
 	"fmt"
 	"io/ioutil"
+	"math/rand"
 	"net/http"
 	"os"
 	"time"
@@ -15,14 +17,22 @@ import (
 	"github.com/sirupsen/logrus"
 	"github.com/spf13/pflag"
 	"github.com/weaveworks/libgitops/cmd/common"
+	"github.com/weaveworks/libgitops/cmd/common/logs"
 	"github.com/weaveworks/libgitops/cmd/sample-app/apis/sample/scheme"
-	"github.com/weaveworks/libgitops/pkg/gitdir"
-	"github.com/weaveworks/libgitops/pkg/logs"
-	"github.com/weaveworks/libgitops/pkg/storage"
-	"github.com/weaveworks/libgitops/pkg/storage/transaction"
-	githubpr "github.com/weaveworks/libgitops/pkg/storage/transaction/pullrequest/github"
-	"github.com/weaveworks/libgitops/pkg/storage/watch"
-	"github.com/weaveworks/libgitops/pkg/storage/watch/update"
+	"github.com/weaveworks/libgitops/cmd/sample-app/apis/sample/v1alpha1"
+	"github.com/weaveworks/libgitops/pkg/serializer"
+	"github.com/weaveworks/libgitops/pkg/storage/backend"
+	"github.com/weaveworks/libgitops/pkg/storage/client"
+	"github.com/weaveworks/libgitops/pkg/storage/client/transactional"
+	"github.com/weaveworks/libgitops/pkg/storage/client/transactional/distributed"
+	"github.com/weaveworks/libgitops/pkg/storage/client/transactional/distributed/git"
+	githubpr "github.com/weaveworks/libgitops/pkg/storage/client/transactional/distributed/git/github"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"github.com/weaveworks/libgitops/pkg/storage/event"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem"
+	unstructuredevent "github.com/weaveworks/libgitops/pkg/storage/filesystem/unstructured/event"
+	"github.com/weaveworks/libgitops/pkg/storage/kube"
+	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
 )
 
 var (
@@ -30,8 +40,9 @@ var (
 	authorNameFlag  = pflag.String("author-name", defaultAuthorName, "Author name for Git commits")
 	authorEmailFlag = pflag.String("author-email", defaultAuthorEmail, "Author email for Git commits")
 	gitURLFlag      = pflag.String("git-url", "", "HTTPS Git URL; where the Git repository is, e.g. https://github.com/luxas/ignite-gitops")
-	prAssigneeFlag  = pflag.StringSlice("pr-assignees", nil, "What user logins to assign for the created PR. The user must have pull access to the repo.")
 	prMilestoneFlag = pflag.String("pr-milestone", "", "What milestone to tag the PR with")
+	prAssigneesFlag = pflag.StringSlice("pr-assignees", nil, "What user logins to assign for the created PR. The user must have pull access to the repo.")
+	prLabelsFlag    = pflag.StringSlice("pr-labels", nil, "What labels to apply on the created PR. The labels must already exist. E.g. \"user/bot,actuator/libgitops,kind/status-update\"")
 )
 
 const (
@@ -46,7 +57,16 @@ func main() {
 	common.ParseVersionFlag()
 
 	// Run the application
-	if err := run(*identityFlag, *gitURLFlag, os.Getenv("GITHUB_TOKEN"), *authorNameFlag, *authorEmailFlag); err != nil {
+	if err := run(
+		*identityFlag,
+		*gitURLFlag,
+		os.Getenv("GITHUB_TOKEN"),
+		*authorNameFlag,
+		*authorEmailFlag,
+		*prMilestoneFlag,
+		*prAssigneesFlag,
+		*prLabelsFlag,
+	); err != nil {
 		fmt.Println(err)
 		os.Exit(1)
 	}
@@ -60,7 +80,8 @@ func expandAndRead(filePath string) ([]byte, error) {
 	return ioutil.ReadFile(expandedPath)
 }
 
-func run(identityFile, gitURL, ghToken, authorName, authorEmail string) error {
+func run(identityFile, gitURL, ghToken, authorName, authorEmail, prMilestone string,
+	prAssignees, prLabels []string) error {
 	// Validate parameters
 	if len(identityFile) == 0 {
 		return fmt.Errorf("--identity-file is required")
@@ -69,7 +90,7 @@ func run(identityFile, gitURL, ghToken, authorName, authorEmail string) error {
 		return fmt.Errorf("--git-url is required")
 	}
 	if len(ghToken) == 0 {
-		return fmt.Errorf("--github-token is required")
+		return fmt.Errorf("GITHUB_TOKEN is required")
 	}
 	if len(authorName) == 0 {
 		return fmt.Errorf("--author-name is required")
@@ -78,6 +99,9 @@ func run(identityFile, gitURL, ghToken, authorName, authorEmail string) error {
 		return fmt.Errorf("--author-email is required")
 	}
 
+	// Set the log level
+	logs.Logger.SetLevel(logrus.TraceLevel)
+
 	// Read the identity and known_hosts files
 	identityContent, err := expandAndRead(identityFile)
 	if err != nil {
@@ -101,58 +125,101 @@ func run(identityFile, gitURL, ghToken, authorName, authorEmail string) error {
 	}
 
 	// Authenticate to the GitDirectory using Git SSH
-	authMethod, err := gitdir.NewSSHAuthMethod(identityContent, knownHostsContent)
+	authMethod, err := git.NewSSHAuthMethod(identityContent, knownHostsContent)
 	if err != nil {
 		return err
 	}
 
-	// Construct the GitDirectory implementation which backs the storage
-	gitDir, err := gitdir.NewGitDirectory(repoRef, gitdir.GitDirectoryOptions{
+	ctx, cancel := context.WithCancel(context.Background())
+
+	defer func() { cancel() }()
+
+	// Construct the LocalClone implementation which backs the storage
+	localClone, err := git.NewLocalClone(ctx, repoRef, git.LocalCloneOptions{
 		Branch:     "master",
-		Interval:   10 * time.Second,
 		AuthMethod: authMethod,
 	})
 	if err != nil {
 		return err
 	}
 
-	// Create a new PR provider for the GitStorage
-	prProvider, err := githubpr.NewGitHubPRProvider(ghClient)
+	rawManifest, err := unstructuredevent.NewManifest(
+		localClone.Dir(),
+		filesystem.DefaultContentTyper,
+		core.StaticNamespacer{NamespacedIsDefaultPolicy: false}, // all objects root-spaced
+		&core.SerializerObjectRecognizer{Serializer: scheme.Serializer},
+		filesystem.DefaultPathExcluders(),
+	)
 	if err != nil {
 		return err
 	}
-	// Create a new GitStorage using the GitDirectory, PR provider, and Serializer
-	gitStorage, err := transaction.NewGitStorage(gitDir, prProvider, scheme.Serializer)
+
+	// Create the channel to receive events to, and register it with the EventStorage
+	updates := make(event.ObjectEventStream, 4096)
+	if err := rawManifest.WatchForObjectEvents(ctx, updates); err != nil {
+		return err
+	}
+
+	defer func() { _ = rawManifest.Close() }()
+
+	b, err := backend.NewGeneric(rawManifest, scheme.Serializer, kube.NewNamespaceEnforcer(), nil, nil)
 	if err != nil {
 		return err
 	}
 
-	// Set the log level
-	logs.Logger.SetLevel(logrus.InfoLevel)
+	gitClient, err := client.NewGeneric(b, scheme.Serializer.Patcher())
+	if err != nil {
+		return err
+	}
 
-	watchStorage, err := watch.NewManifestStorage(gitDir.Dir(), scheme.Serializer)
+	txGeneralClient, err := transactional.NewGeneric(gitClient, localClone, nil)
 	if err != nil {
 		return err
 	}
-	defer func() { _ = watchStorage.Close() }()
 
-	updates := make(chan update.Update, 4096)
-	watchStorage.SetUpdateStream(updates)
+	txClient, err := distributed.NewClient(txGeneralClient, localClone)
+	if err != nil {
+		return err
+	}
+
+	// Create a new CommitHook for sending PRs
+	prCommitHook, err := githubpr.NewGitHubPRCommitHandler(ghClient, localClone.RepositoryRef())
+	if err != nil {
+		return err
+	}
+
+	// Register the PR CommitHook with the BranchManager
+	// This needs to be done after the distributed.NewClient call, so
+	// it has been able to handle pushing of the branch first.
+	localClone.CommitHookChain().Register(prCommitHook)
+
+	// Start the sync loop in the background
+	txClient.StartResyncLoop(ctx, 15*time.Second)
 
 	go func() {
 		for upd := range updates {
-			logrus.Infof("Got %s update for: %v %v", upd.Event, upd.PartialObject.GetObjectKind().GroupVersionKind(), upd.PartialObject.GetObjectMeta())
+			logrus.Infof("Got %s update for: %v %v", upd.Type, upd.ID.GroupKind(), upd.ID.ObjectKey())
 		}
 	}()
 
 	e := common.NewEcho()
 
 	e.GET("/git/", func(c echo.Context) error {
-		objs, err := gitStorage.List(storage.NewKindKey(common.CarGVK))
-		if err != nil {
+		list := &unstructured.UnstructuredList{}
+		list.SetGroupVersionKind(v1alpha1.SchemeGroupVersion.WithKind("CarList"))
+
+		/*if br := c.QueryParam("branch"); len(br) != 0 {
+			ctx = core.WithVersionRef(ctx, core.NewBranchRef(br))
+		}*/
+
+		if err := txClient.List(ctx, list); err != nil {
+			return err
+		}
+		var content bytes.Buffer
+		if err := scheme.Serializer.Encoder().Encode(serializer.NewJSONFrameWriter(&content), list); err != nil {
 			return err
 		}
-		return c.JSON(http.StatusOK, objs)
+		return c.JSONBlob(http.StatusOK, content.Bytes())
 	})
 
 	e.PUT("/git/:name", func(c echo.Context) error {
@@ -161,26 +228,36 @@ func run(identityFile, gitURL, ghToken, authorName, authorEmail string) error {
 			return echo.NewHTTPError(http.StatusBadRequest, "Please set name")
 		}
 
-		objKey := common.CarKeyForName(name)
-		err := gitStorage.Transaction(context.Background(), fmt.Sprintf("%s-update-", name), func(ctx context.Context, s storage.Storage) (transaction.CommitResult, error) {
+		car := v1alpha1.Car{}
+		carKey := core.ObjectKey{Name: name}
 
-			// Update the status of the car
-			if err := common.SetNewCarStatus(s, objKey); err != nil {
-				return nil, err
-			}
+		branchCtx := core.WithVersionRef(ctx, core.NewBranchRef(localClone.MainBranch()))
 
-			return &transaction.GenericPullRequestResult{
-				CommitResult: &transaction.GenericCommitResult{
-					AuthorName:  authorName,
-					AuthorEmail: authorEmail,
-					Title:       "Update Car speed",
-					Description: "We really need to sync this state!",
+		headBranch := fmt.Sprintf("%s-update-", name)
+		err := txClient.
+			BranchTransaction(branchCtx, headBranch).
+			Get(carKey, &car).
+			Custom(func(ctx context.Context) error {
+				car.Status.Distance = rand.Uint64()
+				car.Status.Speed = rand.Float64() * 100
+				return nil
+			}).
+			Update(&car).
+			CreateTx(githubpr.GenericPullRequest{
+				Commit: transactional.GenericCommit{
+					Author: transactional.GenericCommitAuthor{
+						Name:  authorName,
+						Email: authorEmail,
+					},
+					Message: transactional.GenericCommitMessage{
+						Title:       "Update Car speed",
+						Description: "We really need to sync this state!",
+					},
 				},
-				Labels:    []string{"user/bot", "actuator/libgitops", "kind/status-update"},
-				Assignees: *prAssigneeFlag,
-				Milestone: *prMilestoneFlag,
-			}, nil
-		})
+				Labels:    prLabels,
+				Assignees: prAssignees,
+				Milestone: prMilestone,
+			}).Error()
 		if err != nil {
 			return err
 		}
diff --git a/cmd/sample-watch/main.go b/cmd/sample-watch/main.go
index ef1aec0..c81a279 100644
--- a/cmd/sample-watch/main.go
+++ b/cmd/sample-watch/main.go
@@ -2,6 +2,7 @@ package main
 
 import (
 	"bytes"
+	"context"
 	"fmt"
 	"net/http"
 	"os"
@@ -10,11 +11,17 @@ import (
 	"github.com/sirupsen/logrus"
 	"github.com/spf13/pflag"
 	"github.com/weaveworks/libgitops/cmd/common"
+	"github.com/weaveworks/libgitops/cmd/common/logs"
 	"github.com/weaveworks/libgitops/cmd/sample-app/apis/sample/scheme"
-	"github.com/weaveworks/libgitops/pkg/logs"
+	"github.com/weaveworks/libgitops/cmd/sample-app/apis/sample/v1alpha1"
 	"github.com/weaveworks/libgitops/pkg/serializer"
-	"github.com/weaveworks/libgitops/pkg/storage/watch"
-	"github.com/weaveworks/libgitops/pkg/storage/watch/update"
+	"github.com/weaveworks/libgitops/pkg/storage/backend"
+	"github.com/weaveworks/libgitops/pkg/storage/client"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"github.com/weaveworks/libgitops/pkg/storage/event"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem"
+	unstructuredevent "github.com/weaveworks/libgitops/pkg/storage/filesystem/unstructured/event"
+	"github.com/weaveworks/libgitops/pkg/storage/kube"
 )
 
 var watchDirFlag = pflag.String("watch-dir", "/tmp/libgitops/watch", "Where to watch for YAML/JSON manifests")
@@ -24,33 +31,55 @@ func main() {
 	common.ParseVersionFlag()
 
 	// Run the application
-	if err := run(); err != nil {
+	if err := run(*watchDirFlag); err != nil {
 		fmt.Println(err)
 		os.Exit(1)
 	}
 }
 
-func run() error {
+func run(watchDir string) error {
 	// Create the watch directory
 	if err := os.MkdirAll(*watchDirFlag, 0755); err != nil {
 		return err
 	}
 
 	// Set the log level
-	logs.Logger.SetLevel(logrus.InfoLevel)
+	logs.Logger.SetLevel(logrus.TraceLevel)
 
-	watchStorage, err := watch.NewManifestStorage(*watchDirFlag, scheme.Serializer)
+	ctx := context.Background()
+
+	rawManifest, err := unstructuredevent.NewManifest(
+		watchDir,
+		filesystem.DefaultContentTyper,
+		core.StaticNamespacer{NamespacedIsDefaultPolicy: false}, // all objects root-spaced
+		&core.SerializerObjectRecognizer{Serializer: scheme.Serializer},
+		filesystem.DefaultPathExcluders(),
+	)
+	if err != nil {
+		return err
+	}
+
+	// Create the channel to receive events to, and register it with the EventStorage
+	updates := make(event.ObjectEventStream, 4096)
+	if err := rawManifest.WatchForObjectEvents(ctx, updates); err != nil {
+		return err
+	}
+
+	b, err := backend.NewGeneric(rawManifest, scheme.Serializer, kube.NewNamespaceEnforcer(), nil, nil)
+	if err != nil {
+		return err
+	}
+
+	watchStorage, err := client.NewGeneric(b, scheme.Serializer.Patcher())
 	if err != nil {
 		return err
 	}
-	defer func() { _ = watchStorage.Close() }()
 
-	updates := make(chan update.Update, 4096)
-	watchStorage.SetUpdateStream(updates)
+	defer func() { _ = rawManifest.Close() }()
 
 	go func() {
 		for upd := range updates {
-			logrus.Infof("Got %s update for: %v %v", upd.Event, upd.PartialObject.GetObjectKind().GroupVersionKind(), upd.PartialObject.GetObjectMeta())
+			logrus.Infof("Got %s update for: %v %v", upd.Type, upd.ID.GroupKind(), upd.ID.ObjectKey())
 		}
 	}()
 
@@ -62,7 +91,8 @@ func run() error {
 			return echo.NewHTTPError(http.StatusBadRequest, "Please set name")
 		}
 
-		obj, err := watchStorage.Get(common.CarKeyForName(name))
+		obj := &v1alpha1.Car{}
+		err := watchStorage.Get(ctx, core.ObjectKey{Name: name}, obj)
 		if err != nil {
 			return err
 		}
@@ -79,7 +109,7 @@ func run() error {
 			return echo.NewHTTPError(http.StatusBadRequest, "Please set name")
 		}
 
-		if err := common.SetNewCarStatus(watchStorage, common.CarKeyForName(name)); err != nil {
+		if err := common.SetNewCarStatus(ctx, watchStorage, name); err != nil {
 			return err
 		}
 		return c.String(200, "OK!")
diff --git a/go.mod b/go.mod
index c03013f..499f482 100644
--- a/go.mod
+++ b/go.mod
@@ -1,31 +1,30 @@
 module github.com/weaveworks/libgitops
 
-go 1.14
+go 1.15
 
-replace (
-	github.com/docker/distribution => github.com/docker/distribution v2.7.1+incompatible
-	github.com/googleapis/gnostic => github.com/googleapis/gnostic v0.3.0
-)
+replace github.com/docker/distribution => github.com/docker/distribution v2.7.1+incompatible
 
 require (
-	github.com/fluxcd/go-git-providers v0.0.2
-	github.com/fluxcd/toolkit v0.0.1-beta.2
-	github.com/go-git/go-git/v5 v5.1.0
-	github.com/go-openapi/spec v0.19.8
+	github.com/evanphx/json-patch v4.9.0+incompatible
+	github.com/fluxcd/go-git-providers v0.0.3
+	github.com/fluxcd/pkg/ssh v0.0.5
+	github.com/go-git/go-git/v5 v5.2.0
+	github.com/go-openapi/spec v0.20.0
 	github.com/google/go-github/v32 v32.1.0
 	github.com/labstack/echo v3.3.10+incompatible
 	github.com/labstack/gommon v0.3.0 // indirect
 	github.com/mattn/go-isatty v0.0.12 // indirect
 	github.com/mitchellh/go-homedir v1.1.0
 	github.com/rjeczalik/notify v0.9.2
-	github.com/sirupsen/logrus v1.6.0
+	github.com/sirupsen/logrus v1.7.0
+	github.com/spf13/afero v1.2.2
 	github.com/spf13/pflag v1.0.5
 	github.com/stretchr/testify v1.6.1
-	golang.org/x/net v0.0.0-20200625001655-4c5254603344 // indirect
-	golang.org/x/sys v0.0.0-20200812155832-6a926be9bd1d
-	k8s.io/apimachinery v0.18.6
-	k8s.io/kube-openapi v0.0.0-20200410145947-61e04a5be9a6
-	sigs.k8s.io/controller-runtime v0.6.0
-	sigs.k8s.io/kustomize/kyaml v0.1.11
-	sigs.k8s.io/yaml v1.2.0
+	golang.org/x/sys v0.0.0-20210108172913-0df2131ae363
+	k8s.io/api v0.19.2
+	k8s.io/apimachinery v0.19.6
+	k8s.io/kube-openapi v0.0.0-20200805222855-6aeccd4b50c6
+	k8s.io/utils v0.0.0-20200912215256-4140de9c8800
+	sigs.k8s.io/controller-runtime v0.7.0
+	sigs.k8s.io/kustomize/kyaml v0.10.5
 )
diff --git a/go.sum b/go.sum
index c1ecf37..b401269 100644
--- a/go.sum
+++ b/go.sum
@@ -1,28 +1,34 @@
-bazil.org/fuse v0.0.0-20160811212531-371fbbdaa898/go.mod h1:Xbm+BRKSBEpa4q4hTSxohYNQpsxXPbPry4JJWOB3LB8=
 cloud.google.com/go v0.26.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=
 cloud.google.com/go v0.34.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=
 cloud.google.com/go v0.38.0/go.mod h1:990N+gfupTy94rShfmMCWGDn0LpTmnzTp2qbd1dvSRU=
+cloud.google.com/go v0.44.1/go.mod h1:iSa0KzasP4Uvy3f1mN/7PiObzGgflwredwwASm/v6AU=
+cloud.google.com/go v0.44.2/go.mod h1:60680Gw3Yr4ikxnPRS/oxxkBccT6SA1yMk63TGekxKY=
+cloud.google.com/go v0.45.1/go.mod h1:RpBamKRgapWJb87xiFSdk4g1CME7QZg3uwTez+TSTjc=
+cloud.google.com/go v0.46.3/go.mod h1:a6bKKbmY7er1mI7TEI4lsAkts/mkhTSZK8w33B4RAg0=
+cloud.google.com/go v0.51.0/go.mod h1:hWtGJ6gnXH+KgDv+V0zFGDvpi07n3z8ZNj3T1RW0Gcw=
+cloud.google.com/go/bigquery v1.0.1/go.mod h1:i/xbL2UlR5RvWAURpBYZTtm/cXjCha9lbfbpx4poX+o=
+cloud.google.com/go/datastore v1.0.0/go.mod h1:LXYbyblFSglQ5pkeyhO+Qmw7ukd3C+pD7TKLgZqpHYE=
+cloud.google.com/go/pubsub v1.0.1/go.mod h1:R0Gpsv3s54REJCy4fxDixWD93lHJMoZTyQ2kNxGRt3I=
+cloud.google.com/go/storage v1.0.0/go.mod h1:IhtSnM/ZTZV8YYJWCY8RULGVqBDmpoyjwiyrjsg+URw=
+dmitri.shuralyov.com/gpu/mtl v0.0.0-20190408044501-666a987793e9/go.mod h1:H6x//7gZCb22OMCxBHrMx7a5I7Hp++hsVxbQ4BYO7hU=
 github.com/360EntSecGroup-Skylar/excelize v1.4.1/go.mod h1:vnax29X2usfl7HHkBrX5EvSCJcmH3dT9luvxzu8iGAE=
 github.com/Azure/go-ansiterm v0.0.0-20170929234023-d6e3b3328b78/go.mod h1:LmzpDX56iTiv29bbRTIsUNlaFfuhWRQBWjQdVyAevI8=
 github.com/Azure/go-autorest/autorest v0.9.0/go.mod h1:xyHB1BMZT0cuDHU7I0+g046+BFDTQ8rEZB0s4Yfa6bI=
+github.com/Azure/go-autorest/autorest v0.9.6/go.mod h1:/FALq9T/kS7b5J5qsQ+RSTUdAmGFqi0vUdVNNx8q630=
 github.com/Azure/go-autorest/autorest/adal v0.5.0/go.mod h1:8Z9fGy2MpX0PvDjB1pEgQTmVqjGhiHBW7RJJEciWzS0=
+github.com/Azure/go-autorest/autorest/adal v0.8.2/go.mod h1:ZjhuQClTqx435SRJ2iMlOxPYt3d2C/T/7TiQCVZSn3Q=
 github.com/Azure/go-autorest/autorest/date v0.1.0/go.mod h1:plvfp3oPSKwf2DNjlBjWF/7vwR+cUD/ELuzDCXwHUVA=
+github.com/Azure/go-autorest/autorest/date v0.2.0/go.mod h1:vcORJHLJEh643/Ioh9+vPmf1Ij9AEBM5FuBIXLmIy0g=
 github.com/Azure/go-autorest/autorest/mocks v0.1.0/go.mod h1:OTyCOPRA2IgIlWxVYxBee2F5Gr4kF2zd2J5cFRaIDN0=
 github.com/Azure/go-autorest/autorest/mocks v0.2.0/go.mod h1:OTyCOPRA2IgIlWxVYxBee2F5Gr4kF2zd2J5cFRaIDN0=
+github.com/Azure/go-autorest/autorest/mocks v0.3.0/go.mod h1:a8FDP3DYzQ4RYfVAxAN3SVSiiO77gL2j2ronKKP0syM=
 github.com/Azure/go-autorest/logger v0.1.0/go.mod h1:oExouG+K6PryycPJfVSxi/koC6LSNgds39diKLz7Vrc=
 github.com/Azure/go-autorest/tracing v0.5.0/go.mod h1:r/s2XiOKccPW3HrqB+W0TQzfbtp2fGCgRFtBroKn4Dk=
+github.com/BurntSushi/toml v0.3.1 h1:WXkYYl6Yr3qBf1K79EBnL4mak0OimBfB0XUf9Vl28OQ=
 github.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU=
 github.com/BurntSushi/xgb v0.0.0-20160522181843-27f122750802/go.mod h1:IVnqGOEym/WlBOVXweHU+Q+/VP0lqqI8lqeDx9IjBqo=
-github.com/MakeNowJust/heredoc v0.0.0-20170808103936-bb23615498cd/go.mod h1:64YHyfSL2R96J44Nlwm39UHepQbyR5q10x7iYa1ks2E=
-github.com/Masterminds/goutils v1.1.0/go.mod h1:8cTjp+g8YejhMuvIA5y2vz3BpJxksy863GQaJW2MFNU=
-github.com/Masterminds/semver/v3 v3.0.3/go.mod h1:VPu/7SZ7ePZ3QOrcuXROw5FAcLl4a0cBrbBpGY/8hQs=
-github.com/Masterminds/sprig/v3 v3.0.2/go.mod h1:oesJ8kPONMONaZgtiHNzUShJbksypC5kWczhZAf6+aU=
-github.com/Masterminds/vcs v1.13.1/go.mod h1:N09YCmOQr6RLxC6UNHzuVwAdodYbbnycGHSmwVJjcKA=
-github.com/Microsoft/go-winio v0.4.15-0.20190919025122-fc70bd9a86b5/go.mod h1:tTuCMEN+UleMWgg9dVx4Hu52b1bJo+59jBh3ajtinzw=
-github.com/Microsoft/hcsshim v0.8.7/go.mod h1:OHd7sQqRFrYd3RmSgbgji+ctCwkbq2wbEYNSzOYtcBQ=
 github.com/NYTimes/gziphandler v0.0.0-20170623195520-56545f4a5d46/go.mod h1:3wb06e3pkSAbeQ52E9H9iFoQsEEwGN64994WTCIhntQ=
 github.com/OneOfOne/xxhash v1.2.2/go.mod h1:HSdplMjZKSmBqAxg5vPj2TmRDmfkzw+cTzAElWljhcU=
-github.com/OpenPeeDeeP/depguard v1.0.1/go.mod h1:xsIw86fROiiwelg+jB2uM9PiKihMMmUx/1V+TNhjQvM=
 github.com/PuerkitoBio/goquery v1.5.0/go.mod h1:qD2PgZ9lccMbQlc7eEOjaeRlFQON7xY8kdmcsrnKqMg=
 github.com/PuerkitoBio/purell v1.0.0 h1:0GoNN3taZV6QI81IXgCbxMyEaJDXMSIjArYBCYzVVvs=
 github.com/PuerkitoBio/purell v1.0.0/go.mod h1:c11w/QuzBsJSee3cPx9rAFu61PvFxuPbtSwDGJws/X0=
@@ -33,12 +39,13 @@ github.com/PuerkitoBio/urlesc v0.0.0-20160726150825-5bd2802263f2 h1:JCHLVE3B+kJd
 github.com/PuerkitoBio/urlesc v0.0.0-20160726150825-5bd2802263f2/go.mod h1:uGdkoq3SwY9Y+13GIhn11/XLaGBb4BfwItxLd5jeuXE=
 github.com/PuerkitoBio/urlesc v0.0.0-20170810143723-de5bf2ad4578 h1:d+Bc7a5rLufV/sSk/8dngufqelfh6jnri85riMAaF/M=
 github.com/PuerkitoBio/urlesc v0.0.0-20170810143723-de5bf2ad4578/go.mod h1:uGdkoq3SwY9Y+13GIhn11/XLaGBb4BfwItxLd5jeuXE=
-github.com/StackExchange/wmi v0.0.0-20180116203802-5d049714c4a6/go.mod h1:3eOhrUMpNV+6aFIbp5/iudMxNCF27Vw2OZgy4xEx0Fg=
 github.com/agnivade/levenshtein v1.0.1/go.mod h1:CURSv5d9Uaml+FovSIICkLbAUZ9S4RqaHDIsdSBg7lM=
 github.com/alcortesm/tgz v0.0.0-20161220082320-9c5fe88206d7 h1:uSoVVbwJiQipAclBbw+8quDsfcvFjOpI5iCf4p/cqCs=
 github.com/alcortesm/tgz v0.0.0-20161220082320-9c5fe88206d7/go.mod h1:6zEj6s6u/ghQa61ZWa/C2Aw3RkjiTBOix7dkqa1VLIs=
 github.com/alecthomas/template v0.0.0-20160405071501-a0175ee3bccc/go.mod h1:LOuyumcjzFXgccqObfd/Ljyb9UuFJ6TxHnclSeseNhc=
+github.com/alecthomas/template v0.0.0-20190718012654-fb15b899a751/go.mod h1:LOuyumcjzFXgccqObfd/Ljyb9UuFJ6TxHnclSeseNhc=
 github.com/alecthomas/units v0.0.0-20151022065526-2efee857e7cf/go.mod h1:ybxpYRFXyAe+OPACYpWeL0wqObRcbAqCMya13uyzqw0=
+github.com/alecthomas/units v0.0.0-20190717042225-c3de453c63f4/go.mod h1:ybxpYRFXyAe+OPACYpWeL0wqObRcbAqCMya13uyzqw0=
 github.com/andreyvit/diff v0.0.0-20170406064948-c7f18ee00883/go.mod h1:rCTlJbsFo29Kk6CurOXKm700vrz8f0KW0JNfpkRJY/8=
 github.com/andybalholm/cascadia v1.0.0/go.mod h1:GsXiBklL0woXo1j/WYWtSYYC4ouU9PqHO0sqidkEA4Y=
 github.com/anmitsu/go-shlex v0.0.0-20161002113705-648efa622239 h1:kFOfPq6dUM1hTo4JG6LR5AXSUEsOjtdm0kw0FtQtMJA=
@@ -48,72 +55,46 @@ github.com/armon/go-socks5 v0.0.0-20160902184237-e75332964ef5 h1:0CwZNZbxp69SHPd
 github.com/armon/go-socks5 v0.0.0-20160902184237-e75332964ef5/go.mod h1:wHh0iHkYZB8zMSxRWpUBQtwG5a7fFgvEO+odwuTv2gs=
 github.com/asaskevich/govalidator v0.0.0-20180720115003-f9ffefc3facf/go.mod h1:lB+ZfQJz7igIIfQNfa7Ml4HSf2uFQQRzpGGRXenZAgY=
 github.com/asaskevich/govalidator v0.0.0-20190424111038-f61b66f89f4a/go.mod h1:lB+ZfQJz7igIIfQNfa7Ml4HSf2uFQQRzpGGRXenZAgY=
-github.com/asaskevich/govalidator v0.0.0-20200108200545-475eaeb16496/go.mod h1:oGkLhpf+kjZl6xBf758TQhh5XrAeiJv/7FRz/2spLIg=
 github.com/beorn7/perks v0.0.0-20180321164747-3a771d992973/go.mod h1:Dwedo/Wpr24TaqPxmxbtue+5NUziq4I4S80YR8gNf3Q=
 github.com/beorn7/perks v1.0.0/go.mod h1:KWe93zE9D1o94FZ5RNwFwVgaQK1VOXiVxmqh+CedLV8=
-github.com/bgentry/go-netrc v0.0.0-20140422174119-9fd32a8b3d3d/go.mod h1:6QX/PXZ00z/TKoufEY6K/a0k6AhaJrQKdFe6OfVXsa4=
+github.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=
+github.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=
 github.com/bgentry/speakeasy v0.1.0/go.mod h1:+zsyZBPWlz7T6j88CTgSN5bM796AkVf0kBD4zp0CCIs=
-github.com/blang/semver v3.1.0+incompatible/go.mod h1:kRBLl5iJ+tD4TcOOxsy/0fnwebNt5EWlYSAyrTnjyyk=
 github.com/blang/semver v3.5.0+incompatible/go.mod h1:kRBLl5iJ+tD4TcOOxsy/0fnwebNt5EWlYSAyrTnjyyk=
-github.com/blang/semver v3.5.1+incompatible h1:cQNTCjp13qL8KC3Nbxr/y2Bqb63oX6wdnnjpJbkM4JQ=
-github.com/blang/semver v3.5.1+incompatible/go.mod h1:kRBLl5iJ+tD4TcOOxsy/0fnwebNt5EWlYSAyrTnjyyk=
-github.com/bombsimon/wsl v1.2.5/go.mod h1:43lEF/i0kpXbLCeDXL9LMT8c92HyBywXb0AsgMHYngM=
 github.com/census-instrumentation/opencensus-proto v0.2.1/go.mod h1:f6KPmirojxKA12rnyqOA5BBL4O983OfeGPqjHWSTneU=
 github.com/cespare/xxhash v1.1.0 h1:a6HrQnmkObjyL+Gs60czilIUGqrzKutQD6XZog3p+ko=
 github.com/cespare/xxhash v1.1.0/go.mod h1:XrSqR1VqqWfGrhpAt58auRo0WTKS1nRRg3ghfAqPWnc=
-github.com/chai2010/gettext-go v0.0.0-20160711120539-c6fed771bfd5/go.mod h1:/iP1qXHoty45bqomnu2LM+VVyAEdWN+vtSHGlQgyxbw=
+github.com/cespare/xxhash/v2 v2.1.1 h1:6MnRN8NT7+YBpUIWxHtefFZOKTAPgGjpQSxqLNn0+qY=
+github.com/cespare/xxhash/v2 v2.1.1/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=
 github.com/chzyer/logex v1.1.10/go.mod h1:+Ywpsq7O8HXn0nuIou7OrIPyXbp3wmkHB+jjWRnGsAI=
 github.com/chzyer/readline v0.0.0-20180603132655-2972be24d48e/go.mod h1:nSuG5e5PlCu98SY8svDHJxuZscDgtXS6KTTbou5AhLI=
 github.com/chzyer/test v0.0.0-20180213035817-a1ea475d72b1/go.mod h1:Q3SI9o4m/ZMnBNeIyt5eFwwo7qiLfzFZmjNmxjkiQlU=
 github.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=
 github.com/cockroachdb/datadriven v0.0.0-20190809214429-80d97fb3cbaa/go.mod h1:zn76sxSg3SzpJ0PPJaLDCu+Bu0Lg3sKTORVIj19EIF8=
-github.com/containerd/cgroups v0.0.0-20190919134610-bf292b21730f/go.mod h1:OApqhQ4XNSNC13gXIwDjhOQxjWa/NxkwZXJ1EvqT0ko=
-github.com/containerd/console v0.0.0-20180822173158-c12b1e7919c1/go.mod h1:Tj/on1eG8kiEhd0+fhSDzsPAFESxzBBvdyEgyryXffw=
-github.com/containerd/containerd v1.3.0-beta.2.0.20190828155532-0293cbd26c69/go.mod h1:bC6axHOhabU15QhwfG7w5PipXdVtMXFTttgp+kVtyUA=
-github.com/containerd/containerd v1.3.2/go.mod h1:bC6axHOhabU15QhwfG7w5PipXdVtMXFTttgp+kVtyUA=
-github.com/containerd/continuity v0.0.0-20190426062206-aaeac12a7ffc/go.mod h1:GL3xCUCBDV3CZiTSEKksMWbLE66hEyuu9qyDOOqM47Y=
-github.com/containerd/continuity v0.0.0-20200107194136-26c1120b8d41/go.mod h1:Dq467ZllaHgAtVp4p1xUQWBrFXR9s/wyoTpG8zOJGkY=
-github.com/containerd/fifo v0.0.0-20190226154929-a9fb20d87448/go.mod h1:ODA38xgv3Kuk8dQz2ZQXpnv/UZZUHUCL7pnLehbXgQI=
-github.com/containerd/go-runc v0.0.0-20180907222934-5a6d9f37cfa3/go.mod h1:IV7qH3hrUgRmyYrtgEeGWJfWbgcHL9CSRruz2Vqcph0=
-github.com/containerd/ttrpc v0.0.0-20190828154514-0e0f228740de/go.mod h1:PvCDdDGpgqzQIzDW1TphrGLssLDZp2GuS+X5DkEJB8o=
-github.com/containerd/typeurl v0.0.0-20180627222232-a93fcdb778cd/go.mod h1:Cm3kwCdlkCfMSHURc+r6fwoGH6/F1hH3S4sg0rLFWPc=
 github.com/coreos/bbolt v1.3.2/go.mod h1:iRUV2dpdMOn7Bo10OQBFzIJO9kkE559Wcmn+qkEiiKk=
 github.com/coreos/etcd v3.3.10+incompatible/go.mod h1:uF7uidLiAD3TWHmW31ZFd/JWoc32PjwdhPthX9715RE=
-github.com/coreos/go-etcd v2.0.0+incompatible/go.mod h1:Jez6KQU2B/sWsbdaef3ED8NzMklzPG4d5KIOhIy30Tk=
 github.com/coreos/go-oidc v2.1.0+incompatible/go.mod h1:CgnwVTmzoESiwO9qyAFEMiHoZ1nMCKZlZ9V6mm3/LKc=
 github.com/coreos/go-semver v0.2.0/go.mod h1:nnelYz7RCh+5ahJtPPxZlU+153eP4D4r3EedlOD2RNk=
 github.com/coreos/go-semver v0.3.0/go.mod h1:nnelYz7RCh+5ahJtPPxZlU+153eP4D4r3EedlOD2RNk=
 github.com/coreos/go-systemd v0.0.0-20180511133405-39ca1b05acc7/go.mod h1:F5haX7vjVVG0kc13fIWeqUViNPyEJxv/OmvnBo0Yme4=
 github.com/coreos/go-systemd v0.0.0-20190321100706-95778dfbb74e/go.mod h1:F5haX7vjVVG0kc13fIWeqUViNPyEJxv/OmvnBo0Yme4=
 github.com/coreos/pkg v0.0.0-20160727233714-3ac0863d7acf/go.mod h1:E3G3o1h8I7cfcXa63jLwjI0eiQQMgzzUDFVpN/nH/eA=
-github.com/coreos/pkg v0.0.0-20180108230652-97fdf19511ea/go.mod h1:E3G3o1h8I7cfcXa63jLwjI0eiQQMgzzUDFVpN/nH/eA=
 github.com/coreos/pkg v0.0.0-20180928190104-399ea9e2e55f/go.mod h1:E3G3o1h8I7cfcXa63jLwjI0eiQQMgzzUDFVpN/nH/eA=
-github.com/cpuguy83/go-md2man v1.0.10/go.mod h1:SmD6nW6nTyfqj6ABTjUi3V3JVMnlJmwcJI5acqYI6dE=
 github.com/cpuguy83/go-md2man/v2 v2.0.0/go.mod h1:maD7wRr/U5Z6m/iR4s+kqSMx2CaBsrgA7czyZG/E6dU=
 github.com/creack/pty v1.1.7/go.mod h1:lj5s0c3V2DBrqTV7llrYr5NG6My20zk30Fl46Y7DoTY=
 github.com/creack/pty v1.1.9/go.mod h1:oKZEueFk5CKHvIhNR5MUki03XCEU+Q6VDXinZuGJ33E=
-github.com/cyphar/filepath-securejoin v0.2.2/go.mod h1:FpkQEhXnPnOthhzymB7CGsFk2G9VLXONKD9G7QGMM+4=
-github.com/davecgh/go-spew v0.0.0-20151105211317-5215b55f46b2/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
 github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
 github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=
 github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
-github.com/daviddengcn/go-colortext v0.0.0-20160507010035-511bcaf42ccd/go.mod h1:dv4zxwHi5C/8AeI+4gX4dCWOIvNi7I6JCSX0HvlKPgE=
-github.com/deislabs/oras v0.8.1/go.mod h1:Mx0rMSbBNaNfY9hjpccEnxkOqJL6KGjtxNHPLC4G4As=
 github.com/dgrijalva/jwt-go v3.2.0+incompatible/go.mod h1:E3ru+11k8xSBh+hMPgOLZmtrrCbhqsmaPHjLKYnJCaQ=
 github.com/dgryski/go-sip13 v0.0.0-20181026042036-e10d5fee7954/go.mod h1:vAd38F8PWV+bWy6jNmig1y/TA+kYO4g3RSRF0IAv0no=
-github.com/docker/cli v0.0.0-20200130152716-5d0cf8839492/go.mod h1:JLrzqnKDaYBop7H2jaqPtU4hHvMKP+vjCwu2uszcLI8=
-github.com/docker/distribution v2.7.1+incompatible/go.mod h1:J2gT2udsDAN96Uj4KfcMRqY0/ypR+oyYUYmja8H+y+w=
-github.com/docker/docker v0.7.3-0.20190327010347-be7ac8be2ae0/go.mod h1:eEKB0N0r5NX/I1kEveEz05bcu8tLC/8azJZsviup8Sk=
-github.com/docker/docker v1.4.2-0.20200203170920-46ec8731fbce/go.mod h1:eEKB0N0r5NX/I1kEveEz05bcu8tLC/8azJZsviup8Sk=
-github.com/docker/docker-credential-helpers v0.6.3/go.mod h1:WRaJzqw3CTB9bk10avuGsjVBZsD05qeibJ1/TYlvc0Y=
-github.com/docker/go-connections v0.4.0/go.mod h1:Gbd7IOopHjR8Iph03tsViu4nIes5XhDvyHbTtUxmeec=
 github.com/docker/go-units v0.3.3/go.mod h1:fgPhTUdO+D/Jk86RDLlptpiXQzgHJF7gydDDbaIK4Dk=
 github.com/docker/go-units v0.4.0/go.mod h1:fgPhTUdO+D/Jk86RDLlptpiXQzgHJF7gydDDbaIK4Dk=
 github.com/docker/spdystream v0.0.0-20160310174837-449fdfce4d96/go.mod h1:Qh8CwZgvJUkLughtfhJv5dyTYa91l1fOUCrgjqmcifM=
+github.com/docopt/docopt-go v0.0.0-20180111231733-ee0de3bc6815/go.mod h1:WwZ+bS3ebgob9U8Nd0kOddGdZWjyMGR8Wziv+TBNwSE=
 github.com/dustin/go-humanize v0.0.0-20171111073723-bb3d318650d4/go.mod h1:HtrtbFcZ19U5GC7JDqmcUSB87Iq5E25KnS6fMYU6eOk=
 github.com/dustin/go-humanize v1.0.0/go.mod h1:HtrtbFcZ19U5GC7JDqmcUSB87Iq5E25KnS6fMYU6eOk=
 github.com/dustmop/soup v1.1.2-0.20190516214245-38228baa104e/go.mod h1:CgNC6SGbT+Xb8wGGvzilttZL1mc5sQ/5KkcxsZttMIk=
-github.com/elazarl/goproxy v0.0.0-20170405201442-c4fc26588b6e/go.mod h1:/Zj4wYkgs4iZTTu3o/KG3Itv/qCCa8VVMlb3i9OVuzc=
 github.com/elazarl/goproxy v0.0.0-20180725130230-947c36da3153/go.mod h1:/Zj4wYkgs4iZTTu3o/KG3Itv/qCCa8VVMlb3i9OVuzc=
 github.com/emicklei/go-restful v0.0.0-20170410110728-ff4f55a20633 h1:H2pdYOb3KQ1/YsqVWoWNLQO+fusocsw354rqGTZtAgw=
 github.com/emicklei/go-restful v0.0.0-20170410110728-ff4f55a20633/go.mod h1:otzb+WCGbkyDHkqmQmT5YD2WR4BBwUdeQoFo8l/7tVs=
@@ -123,18 +104,15 @@ github.com/emirpasic/gods v1.12.0 h1:QAUIPSaCu4G+POclxeqb3F+WPpdKqFGlw36+yOzGlrg
 github.com/emirpasic/gods v1.12.0/go.mod h1:YfzfFFoVP/catgzJb4IKIqXjX78Ha8FMSDh3ymbK86o=
 github.com/envoyproxy/go-control-plane v0.9.1-0.20191026205805-5f8ba28d4473/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=
 github.com/envoyproxy/protoc-gen-validate v0.1.0/go.mod h1:iSmxcyjqTsJpI2R4NaDN7+kN2VEUnK/pcBlmesArF7c=
-github.com/evanphx/json-patch v4.2.0+incompatible/go.mod h1:50XU6AFN0ol/bzJsmQLiYLvXMP4fmwYFNcr97nuDLSk=
 github.com/evanphx/json-patch v4.5.0+incompatible h1:ouOWdg56aJriqS0huScTkVXPC5IcNrDCXZ6OoTAWu7M=
 github.com/evanphx/json-patch v4.5.0+incompatible/go.mod h1:50XU6AFN0ol/bzJsmQLiYLvXMP4fmwYFNcr97nuDLSk=
-github.com/exponent-io/jsonpath v0.0.0-20151013193312-d6023ce2651d/go.mod h1:ZZMPRZwes7CROmyNKgQzC3XPs6L/G2EJLHddWejkmf4=
-github.com/fatih/camelcase v1.0.0/go.mod h1:yN2Sb0lFhZJUdVvtELVWefmrXpuZESvPmqwoZc+/fpc=
+github.com/evanphx/json-patch v4.9.0+incompatible h1:kLcOMZeuLAJvL2BPWLMIj5oaZQobrkAqrL+WFZwQses=
+github.com/evanphx/json-patch v4.9.0+incompatible/go.mod h1:50XU6AFN0ol/bzJsmQLiYLvXMP4fmwYFNcr97nuDLSk=
 github.com/fatih/color v1.7.0/go.mod h1:Zm6kSWBoL9eyXnKyktHP6abPY2pDugNf5KwzbycvMj4=
-github.com/fluxcd/go-git-providers v0.0.2 h1:NGJeJl1TOJKbxtQkRL9JOk5lIopR1XNi6hGgZC5+8IE=
-github.com/fluxcd/go-git-providers v0.0.2/go.mod h1:2Fp9GDxIcllNR7pm5clXhInPyue4VggecaH83KhkpNw=
-github.com/fluxcd/kustomize-controller v0.0.1-beta.2/go.mod h1:mLeipvpQkyof6b5IHNtqeA8CmbjfVIf92UyKkpeBY98=
-github.com/fluxcd/source-controller v0.0.1-beta.2/go.mod h1:tmscNdCxEt7+Xt2g1+bI38hMPw2leYMFAaCn4UlMGuw=
-github.com/fluxcd/toolkit v0.0.1-beta.2 h1:JG80AUIGd936QJ6Vs/xZweoKcE6j7Loua5Wn6Q/pVh8=
-github.com/fluxcd/toolkit v0.0.1-beta.2/go.mod h1:NqDXj2aeVMbVkrCHeP/r0um+edXXyeGlG/9pKZLqGdM=
+github.com/fluxcd/go-git-providers v0.0.3 h1:pquQvTpd1a4V1efPyZWuVPeIKrTgV8QRoDY0VGH+qiw=
+github.com/fluxcd/go-git-providers v0.0.3/go.mod h1:iaXf3nEq8MB/LzxfbNcCl48sAtIReUU7jqjJ7CEnfFQ=
+github.com/fluxcd/pkg/ssh v0.0.5 h1:rnbFZ7voy2JBlUfMbfyqArX2FYaLNpDhccGFC3qW83A=
+github.com/fluxcd/pkg/ssh v0.0.5/go.mod h1:7jXPdXZpc0ttMNz2kD9QuMi3RNn/e0DOFbj0Tij/+Hs=
 github.com/flynn/go-shlex v0.0.0-20150515145356-3f9db97f8568 h1:BHsljHzVlRcyQhjrss6TZTdY2VfCqZPbv5k3iBFa2ZQ=
 github.com/flynn/go-shlex v0.0.0-20150515145356-3f9db97f8568/go.mod h1:xEzjJPgXI435gkrCt3MPfRiAkVrwSbHsst4LCFVfpJc=
 github.com/fsnotify/fsnotify v1.4.7 h1:IXs+QLmnXW2CcXuY+8Mzv/fWEsPGWxqefPtCP5CnV9I=
@@ -147,27 +125,28 @@ github.com/gliderlabs/ssh v0.2.2 h1:6zsha5zo/TWhRhwqCD3+EarCAgZ2yN28ipRnGPnwkI0=
 github.com/gliderlabs/ssh v0.2.2/go.mod h1:U7qILu1NlMHj9FlMhZLlkCdDnU1DBEAqr0aevW3Awn0=
 github.com/globalsign/mgo v0.0.0-20180905125535-1ca0a4f7cbcb/go.mod h1:xkRDCp4j0OGD1HRkm4kmhM+pmpv3AKq5SU7GMg4oO/Q=
 github.com/globalsign/mgo v0.0.0-20181015135952-eeefdecb41b8/go.mod h1:xkRDCp4j0OGD1HRkm4kmhM+pmpv3AKq5SU7GMg4oO/Q=
-github.com/go-critic/go-critic v0.3.5-0.20190904082202-d79a9f0c64db/go.mod h1:+sE8vrLDS2M0pZkBk0wy6+nLdKexVDrl/jBqQOTDThA=
 github.com/go-errors/errors v1.0.1 h1:LUHzmkK3GUKUrL/1gfBUxAHzcev3apQlezX/+O7ma6w=
 github.com/go-errors/errors v1.0.1/go.mod h1:f4zRHt4oKfwPJE5k8C9vpYG+aDHdBFUsgrm6/TyX73Q=
 github.com/go-git/gcfg v1.5.0 h1:Q5ViNfGF8zFgyJWPqYwA7qGFoMTEiBmdlkcfRmpIMa4=
 github.com/go-git/gcfg v1.5.0/go.mod h1:5m20vg6GwYabIxaOonVkTdrILxQMpEShl1xiMF4ua+E=
 github.com/go-git/go-billy/v5 v5.0.0 h1:7NQHvd9FVid8VL4qVUMm8XifBK+2xCoZ2lSk0agRrHM=
 github.com/go-git/go-billy/v5 v5.0.0/go.mod h1:pmpqyWchKfYfrkb/UVH4otLvyi/5gJlGI4Hb3ZqZ3W0=
-github.com/go-git/go-git-fixtures/v4 v4.0.1 h1:q+IFMfLx200Q3scvt2hN79JsEzy4AmBTp/pqnefH+Bc=
-github.com/go-git/go-git-fixtures/v4 v4.0.1/go.mod h1:m+ICp2rF3jDhFgEZ/8yziagdT1C+ZpZcrJjappBCDSw=
-github.com/go-git/go-git/v5 v5.0.0/go.mod h1:oYD8y9kWsGINPFJoLdaScGCN6dlKg23blmClfZwtUVA=
-github.com/go-git/go-git/v5 v5.1.0 h1:HxJn9g/E7eYvKW3Fm7Jt4ee8LXfPOm/H1cdDu8vEssk=
-github.com/go-git/go-git/v5 v5.1.0/go.mod h1:ZKfuPUoY1ZqIG4QG9BDBh3G4gLM5zvPuSJAozQrZuyM=
+github.com/go-git/go-git-fixtures/v4 v4.0.2-0.20200613231340-f56387b50c12 h1:PbKy9zOy4aAKrJ5pibIRpVO2BXnK1Tlcg+caKI7Ox5M=
+github.com/go-git/go-git-fixtures/v4 v4.0.2-0.20200613231340-f56387b50c12/go.mod h1:m+ICp2rF3jDhFgEZ/8yziagdT1C+ZpZcrJjappBCDSw=
+github.com/go-git/go-git/v5 v5.2.0 h1:YPBLG/3UK1we1ohRkncLjaXWLW+HKp5QNM/jTli2JgI=
+github.com/go-git/go-git/v5 v5.2.0/go.mod h1:kh02eMX+wdqqxgNMEyq8YgwlIOsDOa9homkUq1PoTMs=
+github.com/go-gl/glfw/v3.3/glfw v0.0.0-20191125211704-12ad95a8df72/go.mod h1:tQ2UAYgL5IevRw8kRxooKSPJfGvJ9fJQFa0TUsXzTg8=
 github.com/go-kit/kit v0.8.0/go.mod h1:xBxKIO96dXMWWy0MnWVtmwkA9/13aqxPnvrjFYMA2as=
-github.com/go-lintpack/lintpack v0.5.2/go.mod h1:NwZuYi2nUHho8XEIZ6SIxihrnPoqBTDqfpXvXAN0sXM=
+github.com/go-kit/kit v0.9.0/go.mod h1:xBxKIO96dXMWWy0MnWVtmwkA9/13aqxPnvrjFYMA2as=
 github.com/go-logfmt/logfmt v0.3.0/go.mod h1:Qt1PoO58o5twSAckw1HlFXLmHsOX5/0LbT9GBnD5lWE=
 github.com/go-logfmt/logfmt v0.4.0/go.mod h1:3RMwSq7FuexP4Kalkev3ejPJsZTpXXBr9+V4qmtdjCk=
 github.com/go-logr/logr v0.1.0 h1:M1Tv3VzNlEHg6uyACnRdtrploV2P7wZqH8BoQMtz0cg=
 github.com/go-logr/logr v0.1.0/go.mod h1:ixOQHD9gLJUVQQ2ZOR7zLEifBX6tGkNJF4QyIY7sIas=
-github.com/go-logr/zapr v0.1.0 h1:h+WVe9j6HAA01niTJPA/kKH0i7e0rLZBCwauQFcRE54=
-github.com/go-logr/zapr v0.1.0/go.mod h1:tabnROwaDl0UNxkVeFRbY8bwB37GwRv0P8lg6aAiEnk=
-github.com/go-ole/go-ole v1.2.1/go.mod h1:7FAglXiTm7HKlQRDeOQ6ZNUHidzCWXuZWq/1dTyBNF8=
+github.com/go-logr/logr v0.2.0/go.mod h1:z6/tIYblkpsD+a4lm/fGIIU9mZ+XfAiaFtq7xTgseGU=
+github.com/go-logr/logr v0.3.0 h1:q4c+kbcR0d5rSurhBR8dIgieOaYpXtsdTYfx22Cu6rs=
+github.com/go-logr/logr v0.3.0/go.mod h1:z6/tIYblkpsD+a4lm/fGIIU9mZ+XfAiaFtq7xTgseGU=
+github.com/go-logr/zapr v0.2.0 h1:v6Ji8yBW77pva6NkJKQdHLAJKrIJKRHz0RXwPqCHSR4=
+github.com/go-logr/zapr v0.2.0/go.mod h1:qhKdvif7YF5GI9NWEpyxTSSBdGmzkNguibrdCNVPunU=
 github.com/go-openapi/analysis v0.0.0-20180825180245-b006789cd277/go.mod h1:k70tL6pCuVxPJOHXQ+wIac1FUrvNkHolPie/cLEU6hI=
 github.com/go-openapi/analysis v0.17.0/go.mod h1:IowGgpVeD0vNm45So8nr+IcQ3pxVtpRoBWb8PVZO0ik=
 github.com/go-openapi/analysis v0.18.0/go.mod h1:IowGgpVeD0vNm45So8nr+IcQ3pxVtpRoBWb8PVZO0ik=
@@ -184,6 +163,8 @@ github.com/go-openapi/jsonpointer v0.19.2 h1:A9+F4Dc/MCNB5jibxf6rRvOvR/iFgQdyNx9
 github.com/go-openapi/jsonpointer v0.19.2/go.mod h1:3akKfEdA7DF1sugOqz1dVQHBcuDBPKZGEoHC/NkiQRg=
 github.com/go-openapi/jsonpointer v0.19.3 h1:gihV7YNZK1iK6Tgwwsxo2rJbD1GTbdm72325Bq8FI3w=
 github.com/go-openapi/jsonpointer v0.19.3/go.mod h1:Pl9vOtqEWErmShwVjC8pYs9cog34VGT37dQOVbmoatg=
+github.com/go-openapi/jsonpointer v0.19.5 h1:gZr+CIYByUqjcgeLXnQu2gHYQC9o73G2XUeOFYEICuY=
+github.com/go-openapi/jsonpointer v0.19.5/go.mod h1:Pl9vOtqEWErmShwVjC8pYs9cog34VGT37dQOVbmoatg=
 github.com/go-openapi/jsonreference v0.0.0-20160704190145-13c6e3589ad9 h1:tF+augKRWlWx0J0B7ZyyKSiTyV6E1zZe+7b3qQlcEf8=
 github.com/go-openapi/jsonreference v0.0.0-20160704190145-13c6e3589ad9/go.mod h1:W3Z9FmVs9qj+KR4zFKmDPGiLdk1D9Rlm7cyMvf57TTg=
 github.com/go-openapi/jsonreference v0.17.0/go.mod h1:g4xxGn04lDIRh0GJb5QlpE3HfopLOL6uZrK/VgnsK9I=
@@ -192,6 +173,8 @@ github.com/go-openapi/jsonreference v0.19.2 h1:o20suLFB4Ri0tuzpWtyHlh7E7HnkqTNLq
 github.com/go-openapi/jsonreference v0.19.2/go.mod h1:jMjeRr2HHw6nAVajTXJ4eiUwohSTlpa0o73RUL1owJc=
 github.com/go-openapi/jsonreference v0.19.3 h1:5cxNfTy0UVC3X8JL5ymxzyoUZmo8iZb+jeTWn7tUa8o=
 github.com/go-openapi/jsonreference v0.19.3/go.mod h1:rjx6GuL8TTa9VaixXglHmQmIL98+wF9xc8zWvFonSJ8=
+github.com/go-openapi/jsonreference v0.19.5 h1:1WJP/wi4OjB4iV8KVbH73rQaoialJrqv8gitZLxGLtM=
+github.com/go-openapi/jsonreference v0.19.5/go.mod h1:RdybgQwPxbL4UEjuAruzK1x3nE69AqPYEJeo/TWfEeg=
 github.com/go-openapi/loads v0.17.0/go.mod h1:72tmFy5wsWx89uEVddd0RjRWPZm92WRLhf7AC+0+OOU=
 github.com/go-openapi/loads v0.18.0/go.mod h1:72tmFy5wsWx89uEVddd0RjRWPZm92WRLhf7AC+0+OOU=
 github.com/go-openapi/loads v0.19.0/go.mod h1:72tmFy5wsWx89uEVddd0RjRWPZm92WRLhf7AC+0+OOU=
@@ -209,8 +192,8 @@ github.com/go-openapi/spec v0.19.3 h1:0XRyw8kguri6Yw4SxhsQA/atC88yqrk0+G4YhI2wab
 github.com/go-openapi/spec v0.19.3/go.mod h1:FpwSN1ksY1eteniUU7X0N/BgJ7a4WvBFVA8Lj9mJglo=
 github.com/go-openapi/spec v0.19.5 h1:Xm0Ao53uqnk9QE/LlYV5DEU09UAgpliA85QoT9LzqPw=
 github.com/go-openapi/spec v0.19.5/go.mod h1:Hm2Jr4jv8G1ciIAo+frC/Ft+rR2kQDh8JHKHb3gWUSk=
-github.com/go-openapi/spec v0.19.8 h1:qAdZLh1r6QF/hI/gTq+TJTvsQUodZsM7KLqkAJdiJNg=
-github.com/go-openapi/spec v0.19.8/go.mod h1:Hm2Jr4jv8G1ciIAo+frC/Ft+rR2kQDh8JHKHb3gWUSk=
+github.com/go-openapi/spec v0.20.0 h1:HGLc8AJ7ynOxwv0Lq4TsnwLsWMawHAYiJIFzbcML86I=
+github.com/go-openapi/spec v0.20.0/go.mod h1:+81FIL1JwC5P3/Iuuozq3pPE9dXdIEGxFutcFKaVbmU=
 github.com/go-openapi/strfmt v0.17.0/go.mod h1:P82hnJI0CXkErkXi8IKjPbNBM6lV6+5pLP5l494TcyU=
 github.com/go-openapi/strfmt v0.18.0/go.mod h1:P82hnJI0CXkErkXi8IKjPbNBM6lV6+5pLP5l494TcyU=
 github.com/go-openapi/strfmt v0.19.0/go.mod h1:+uW+93UVvGGq2qGaZxdDeJqSAqBqBdl+ZPMF/cC8nDY=
@@ -224,71 +207,42 @@ github.com/go-openapi/swag v0.19.2 h1:jvO6bCMBEilGwMfHhrd61zIID4oIFdwb76V17SM88d
 github.com/go-openapi/swag v0.19.2/go.mod h1:POnQmlKehdgb5mhVOsnJFsivZCEZ/vjK9gh66Z9tfKk=
 github.com/go-openapi/swag v0.19.5 h1:lTz6Ys4CmqqCQmZPBlbQENR1/GucA2bzYTE12Pw4tFY=
 github.com/go-openapi/swag v0.19.5/go.mod h1:POnQmlKehdgb5mhVOsnJFsivZCEZ/vjK9gh66Z9tfKk=
+github.com/go-openapi/swag v0.19.12 h1:Bc0bnY2c3AoF7Gc+IMIAQQsD8fLHjHpc19wXvYuayQI=
+github.com/go-openapi/swag v0.19.12/go.mod h1:eFdyEBkTdoAf/9RXBvj4cr1nH7GD8Kzo5HTt47gr72M=
 github.com/go-openapi/validate v0.18.0/go.mod h1:Uh4HdOzKt19xGIGm1qHf/ofbX1YQ4Y+MYsct2VUrAJ4=
 github.com/go-openapi/validate v0.19.2/go.mod h1:1tRCw7m3jtI8eNWEEliiAqUIcBztB2KDnRCRMUi7GTA=
 github.com/go-openapi/validate v0.19.5/go.mod h1:8DJv2CVJQ6kGNpFW6eV9N3JviE1C85nY1c2z52x1Gk4=
 github.com/go-openapi/validate v0.19.8/go.mod h1:8DJv2CVJQ6kGNpFW6eV9N3JviE1C85nY1c2z52x1Gk4=
 github.com/go-stack/stack v1.8.0/go.mod h1:v0f6uXyyMGvRgIKkXu+yp6POWl0qKG85gN/melR3HDY=
-github.com/go-toolsmith/astcast v1.0.0/go.mod h1:mt2OdQTeAQcY4DQgPSArJjHCcOwlX+Wl/kwN+LbLGQ4=
-github.com/go-toolsmith/astcopy v1.0.0/go.mod h1:vrgyG+5Bxrnz4MZWPF+pI4R8h3qKRjjyvV/DSez4WVQ=
-github.com/go-toolsmith/astequal v0.0.0-20180903214952-dcb477bfacd6/go.mod h1:H+xSiq0+LtiDC11+h1G32h7Of5O3CYFJ99GVbS5lDKY=
-github.com/go-toolsmith/astequal v1.0.0/go.mod h1:H+xSiq0+LtiDC11+h1G32h7Of5O3CYFJ99GVbS5lDKY=
-github.com/go-toolsmith/astfmt v0.0.0-20180903215011-8f8ee99c3086/go.mod h1:mP93XdblcopXwlyN4X4uodxXQhldPGZbcEJIimQHrkg=
-github.com/go-toolsmith/astfmt v1.0.0/go.mod h1:cnWmsOAuq4jJY6Ct5YWlVLmcmLMn1JUPuQIHCY7CJDw=
-github.com/go-toolsmith/astinfo v0.0.0-20180906194353-9809ff7efb21/go.mod h1:dDStQCHtmZpYOmjRP/8gHHnCCch3Zz3oEgCdZVdtweU=
-github.com/go-toolsmith/astp v0.0.0-20180903215135-0af7e3c24f30/go.mod h1:SV2ur98SGypH1UjcPpCatrV5hPazG6+IfNHbkDXBRrk=
-github.com/go-toolsmith/astp v1.0.0/go.mod h1:RSyrtpVlfTFGDYRbrjyWP1pYu//tSFcvdYrA8meBmLI=
-github.com/go-toolsmith/pkgload v0.0.0-20181119091011-e9e65178eee8/go.mod h1:WoMrjiy4zvdS+Bg6z9jZH82QXwkcgCBX6nOfnmdaHks=
-github.com/go-toolsmith/pkgload v1.0.0/go.mod h1:5eFArkbO80v7Z0kdngIxsRXRMTaX4Ilcwuh3clNrQJc=
-github.com/go-toolsmith/strparse v1.0.0/go.mod h1:YI2nUKP9YGZnL/L1/DLFBfixrcjslWct4wyljWhSRy8=
-github.com/go-toolsmith/typep v1.0.0/go.mod h1:JSQCQMUPdRlMZFswiq3TGpNp1GMktqkR2Ns5AIQkATU=
-github.com/gobwas/glob v0.2.3/go.mod h1:d3Ez4x06l9bZtSvzIay5+Yzi0fmZzPgnTbPcKjJAkT8=
-github.com/godbus/dbus v0.0.0-20190422162347-ade71ed3457e/go.mod h1:bBOAhwG1umN6/6ZUMtDFBMQR8jRg9O75tm9K00oMsK4=
-github.com/gofrs/flock v0.0.0-20190320160742-5135e617513b/go.mod h1:F1TvTiK9OcQqauNUHlbJvyl9Qa1QvF/gOUDKA14jxHU=
-github.com/gofrs/flock v0.7.1/go.mod h1:F1TvTiK9OcQqauNUHlbJvyl9Qa1QvF/gOUDKA14jxHU=
+github.com/gobuffalo/here v0.6.0/go.mod h1:wAG085dHOYqUpf+Ap+WOdrPTp5IYcDAs/x7PLa8Y5fM=
 github.com/gogo/protobuf v1.1.1/go.mod h1:r8qH/GZQm5c6nD/R0oafs1akxWv10x8SbQlK7atdtwQ=
 github.com/gogo/protobuf v1.2.1/go.mod h1:hp+jE20tsWTFYpLwKvXlhS1hjn+gTNwPg2I6zVXpSg4=
-github.com/gogo/protobuf v1.2.2-0.20190723190241-65acae22fc9d/go.mod h1:SlYgWuQ5SjCEi6WLHjHCa1yvBfUnHcTbrrZtXPKa29o=
 github.com/gogo/protobuf v1.3.1 h1:DqDEcV5aeaTmdFBePNpYsp3FlcVH/2ISVVM9Qf8PSls=
 github.com/gogo/protobuf v1.3.1/go.mod h1:SlYgWuQ5SjCEi6WLHjHCa1yvBfUnHcTbrrZtXPKa29o=
 github.com/golang/glog v0.0.0-20160126235308-23def4e6c14b/go.mod h1:SBH7ygxi8pfUlaOkMMuAQtPIUF8ecWP5IEl/CR7VP2Q=
 github.com/golang/groupcache v0.0.0-20160516000752-02826c3e7903/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=
-github.com/golang/groupcache v0.0.0-20180513044358-24b0969c4cb7/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=
 github.com/golang/groupcache v0.0.0-20190129154638-5b532d6fd5ef/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=
+github.com/golang/groupcache v0.0.0-20190702054246-869f871628b6/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=
+github.com/golang/groupcache v0.0.0-20191227052852-215e87163ea7 h1:5ZkaAPbicIKTF2I64qf5Fh8Aa83Q/dnOafMYV0OMwjA=
+github.com/golang/groupcache v0.0.0-20191227052852-215e87163ea7/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=
 github.com/golang/mock v1.1.1/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=
 github.com/golang/mock v1.2.0/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=
-github.com/golang/protobuf v0.0.0-20161109072736-4bd1920723d7/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=
+github.com/golang/mock v1.3.1/go.mod h1:sBzyDLLjw3U8JLTeZvSv8jJB+tU5PVekmnlKIyFUx0Y=
 github.com/golang/protobuf v1.0.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=
 github.com/golang/protobuf v1.2.0 h1:P3YflyNX/ehuJFLhxviNdFxQPkGK5cDcApsge1SqnvM=
 github.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=
 github.com/golang/protobuf v1.3.1/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=
 github.com/golang/protobuf v1.3.2 h1:6nsPYzhq5kReh6QImI3k5qWzO4PEbvbIW2cwSfR/6xs=
 github.com/golang/protobuf v1.3.2/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=
+github.com/golang/protobuf v1.3.3/go.mod h1:vzj43D7+SQXF/4pzW/hwtAqwc6iTitCiVSaWz5lYuqw=
 github.com/golang/protobuf v1.4.0-rc.1/go.mod h1:ceaxUfeHdC40wWswd/P6IGgMaK3YpKi5j83Wpe3EHw8=
 github.com/golang/protobuf v1.4.0-rc.1.0.20200221234624-67d41d38c208/go.mod h1:xKAWHe0F5eneWXFV3EuXVDTCmh+JuBKY0li0aMyXATA=
 github.com/golang/protobuf v1.4.0-rc.2/go.mod h1:LlEzMj4AhA7rCAGe4KMBDvJI+AwstrUpVNzEA03Pprs=
 github.com/golang/protobuf v1.4.0-rc.4.0.20200313231945-b860323f09d0/go.mod h1:WU3c8KckQ9AFe+yFwt9sWVRKCVIyN9cPHBJSNnbL67w=
 github.com/golang/protobuf v1.4.0/go.mod h1:jodUvKwWbYaEsadDk5Fwe5c77LiNKVO9IDvqG2KuDX0=
+github.com/golang/protobuf v1.4.1/go.mod h1:U8fpvMrcmy5pZrNK1lt4xCsGvpyWQ/VVv6QDs8UjoX8=
 github.com/golang/protobuf v1.4.2 h1:+Z5KGCizgyZCbGh1KZqA0fcLLkwbsjIzS4aV2v7wJX0=
 github.com/golang/protobuf v1.4.2/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=
-github.com/golangci/check v0.0.0-20180506172741-cfe4005ccda2/go.mod h1:k9Qvh+8juN+UKMCS/3jFtGICgW8O96FVaZsaxdzDkR4=
-github.com/golangci/dupl v0.0.0-20180902072040-3e9179ac440a/go.mod h1:ryS0uhF+x9jgbj/N71xsEqODy9BN81/GonCZiOzirOk=
-github.com/golangci/errcheck v0.0.0-20181223084120-ef45e06d44b6/go.mod h1:DbHgvLiFKX1Sh2T1w8Q/h4NAI8MHIpzCdnBUDTXU3I0=
-github.com/golangci/go-misc v0.0.0-20180628070357-927a3d87b613/go.mod h1:SyvUF2NxV+sN8upjjeVYr5W7tyxaT1JVtvhKhOn2ii8=
-github.com/golangci/goconst v0.0.0-20180610141641-041c5f2b40f3/go.mod h1:JXrF4TWy4tXYn62/9x8Wm/K/dm06p8tCKwFRDPZG/1o=
-github.com/golangci/gocyclo v0.0.0-20180528134321-2becd97e67ee/go.mod h1:ozx7R9SIwqmqf5pRP90DhR2Oay2UIjGuKheCBCNwAYU=
-github.com/golangci/gofmt v0.0.0-20190930125516-244bba706f1a/go.mod h1:9qCChq59u/eW8im404Q2WWTrnBUQKjpNYKMbU4M7EFU=
-github.com/golangci/golangci-lint v1.21.0/go.mod h1:phxpHK52q7SE+5KpPnti4oZTdFCEsn/tKN+nFvCKXfk=
-github.com/golangci/ineffassign v0.0.0-20190609212857-42439a7714cc/go.mod h1:e5tpTHCfVze+7EpLEozzMB3eafxo2KT5veNg1k6byQU=
-github.com/golangci/lint-1 v0.0.0-20191013205115-297bf364a8e0/go.mod h1:66R6K6P6VWk9I95jvqGxkqJxVWGFy9XlDwLwVz1RCFg=
-github.com/golangci/maligned v0.0.0-20180506175553-b1d89398deca/go.mod h1:tvlJhZqDe4LMs4ZHD0oMUlt9G2LWuDGoisJTBzLMV9o=
-github.com/golangci/misspell v0.0.0-20180809174111-950f5d19e770/go.mod h1:dEbvlSfYbMQDtrpRMQU675gSDLDNa8sCPPChZ7PhiVA=
-github.com/golangci/prealloc v0.0.0-20180630174525-215b22d4de21/go.mod h1:tf5+bzsHdTM0bsB7+8mt0GUMvjCgwLpTapNZHU8AajI=
-github.com/golangci/revgrep v0.0.0-20180526074752-d9c87f5ffaf0/go.mod h1:qOQCunEYvmd/TLamH+7LlVccLvUH5kZNhbCgTHoBbp4=
-github.com/golangci/unconvert v0.0.0-20180507085042-28b1c447d1f4/go.mod h1:Izgrg8RkN3rCIMLGE9CyYmU9pY2Jer6DgANEnZ/L/cQ=
-github.com/golangplus/bytes v0.0.0-20160111154220-45c989fe5450/go.mod h1:Bk6SMAONeMXrxql8uvOKuAZSu8aM5RUGv+1C6IJaEho=
-github.com/golangplus/fmt v0.0.0-20150411045040-2a5d6d7d2995/go.mod h1:lJgMEyOkYFkPcDKwRXegd+iM6E7matEszMG5HhwytU8=
-github.com/golangplus/testing v0.0.0-20180327235837-af21d9c3145e/go.mod h1:0AA//k/eakGydO4jKRoRL2j92ZKSzTgj9tclaCrvXHk=
 github.com/google/btree v0.0.0-20180813153112-4030bb1f1f0c/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=
 github.com/google/btree v1.0.0/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=
 github.com/google/go-cmp v0.2.0/go.mod h1:oXzfMopK8JAjlY9xF4vHSVASa0yLyX7SntLO5aqRK0M=
@@ -297,32 +251,31 @@ github.com/google/go-cmp v0.3.0/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMyw
 github.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=
 github.com/google/go-cmp v0.4.0 h1:xsAVV57WRhGj6kEIi8ReJzQlHHqcBYCElAvkovg3B/4=
 github.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=
-github.com/google/go-github/v32 v32.0.0 h1:q74KVb22spUq0U5HqZ9VCYqQz8YRuOtL/39ZnfwO+NM=
-github.com/google/go-github/v32 v32.0.0/go.mod h1:rIEpZD9CTDQwDK9GDrtMTycQNA4JU3qBsCizh3q2WCI=
+github.com/google/go-cmp v0.5.2 h1:X2ev0eStA3AbceY54o37/0PQ/UWqKEiiO2dKL5OPaFM=
+github.com/google/go-cmp v0.5.2/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=
 github.com/google/go-github/v32 v32.1.0 h1:GWkQOdXqviCPx7Q7Fj+KyPoGm4SwHRh8rheoPhd27II=
 github.com/google/go-github/v32 v32.1.0/go.mod h1:rIEpZD9CTDQwDK9GDrtMTycQNA4JU3qBsCizh3q2WCI=
 github.com/google/go-querystring v1.0.0 h1:Xkwi/a1rcvNg1PPYe5vI8GbeBY/jrVuDX5ASuANWTrk=
 github.com/google/go-querystring v1.0.0/go.mod h1:odCYkC5MyYFN7vkCjXpyrEuKhc/BUO6wN/zVPAxq5ck=
-github.com/google/gofuzz v0.0.0-20161122191042-44d81051d367/go.mod h1:HP5RmnzzSNb993RKQDq4+1A4ia9nllfqcQFTQJedwGI=
 github.com/google/gofuzz v1.0.0 h1:A8PeW59pxE9IoFRqBp37U+mSNaQoZ46F1f0f863XSXw=
 github.com/google/gofuzz v1.0.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=
 github.com/google/gofuzz v1.1.0 h1:Hsa8mG0dQ46ij8Sl2AYJDUv1oA9/d6Vk+3LG99Oe02g=
 github.com/google/gofuzz v1.1.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=
 github.com/google/martian v2.1.0+incompatible/go.mod h1:9I4somxYTbIHy5NJKHRl3wXiIaQGbYVAs8BPL6v8lEs=
 github.com/google/pprof v0.0.0-20181206194817-3ea8567a2e57/go.mod h1:zfwlbNMJ+OItoe0UupaVj+oy1omPYYDuagoSzA8v9mc=
+github.com/google/pprof v0.0.0-20190515194954-54271f7e092f/go.mod h1:zfwlbNMJ+OItoe0UupaVj+oy1omPYYDuagoSzA8v9mc=
+github.com/google/pprof v0.0.0-20191218002539-d4f498aebedc/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=
 github.com/google/renameio v0.1.0/go.mod h1:KWCgfxg9yswjAJkECMjeO8J8rahYeXnNhOm40UhjYkI=
-github.com/google/shlex v0.0.0-20191202100458-e7afc7fbc510/go.mod h1:pupxD2MaaD3pAXIBCelhxNneeOaAeabZDe5s4K6zSpQ=
 github.com/google/uuid v1.0.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=
 github.com/google/uuid v1.1.1 h1:Gkbcsh/GbpXz7lPftLA3P6TYMwjCLYm83jiFQZF/3gY=
 github.com/google/uuid v1.1.1/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=
 github.com/googleapis/gax-go/v2 v2.0.4/go.mod h1:0Wqv26UfaUD9n4G6kQubkQ+KchISgw+vpHVxEJEs9eg=
-github.com/googleapis/gnostic v0.3.0 h1:CcQijm0XKekKjP/YCz28LXVSpgguuB+nCxaSjCe09y0=
-github.com/googleapis/gnostic v0.3.0/go.mod h1:sJBsCZ4ayReDTBIg8b9dl28c5xFWyhBTVRp3pOg5EKY=
-github.com/gophercloud/gophercloud v0.1.0/go.mod h1:vxM41WHh5uqHVBMZHzuwNOHh8XEoIEcSTewFxm1c5g8=
+github.com/googleapis/gax-go/v2 v2.0.5/go.mod h1:DWXyrwAJ9X0FpwwEdw+IPEYBICEFu5mhpdKc/us6bOk=
+github.com/googleapis/gnostic v0.4.1/go.mod h1:LRhVm6pbyptWbWbuZ38d1eyptfvIytN3ir6b65WBswg=
+github.com/googleapis/gnostic v0.5.1 h1:A8Yhf6EtqTv9RMsU6MQTyrtV1TjWlR6xU9BsZIwuTCM=
+github.com/googleapis/gnostic v0.5.1/go.mod h1:6U4PtQXGIEt/Z3h5MAT7FNofLnw9vXk2cUuW7uA/OeU=
 github.com/gorilla/websocket v0.0.0-20170926233335-4201258b820c/go.mod h1:E7qHFY5m1UJ88s3WnNqhKjPHQ0heANvMoAMk2YaljkQ=
 github.com/gorilla/websocket v1.4.0/go.mod h1:E7qHFY5m1UJ88s3WnNqhKjPHQ0heANvMoAMk2YaljkQ=
-github.com/gostaticanalysis/analysisutil v0.0.0-20190318220348-4088753ea4d3/go.mod h1:eEOZF4jCKGi+aprrirO9e7WKB3beBRtWgqGunKl6pKE=
-github.com/gosuri/uitable v0.0.4/go.mod h1:tKR86bXuXPZazfOTG1FIzvjIdXzd0mo4Vtn16vt0PJo=
 github.com/gregjones/httpcache v0.0.0-20180305231024-9cad4c3443a7/go.mod h1:FecbI9+v66THATjSRHfNgh1IVFe/9kFxbXtjV0ctIMA=
 github.com/gregjones/httpcache v0.0.0-20190611155906-901d90724c79 h1:+ngKgrYPPJrOjhax5N+uePQ0Fh1Z7PheYoUI/0nzkPA=
 github.com/gregjones/httpcache v0.0.0-20190611155906-901d90724c79/go.mod h1:FecbI9+v66THATjSRHfNgh1IVFe/9kFxbXtjV0ctIMA=
@@ -331,38 +284,36 @@ github.com/grpc-ecosystem/go-grpc-middleware v1.0.1-0.20190118093823-f849b5445de
 github.com/grpc-ecosystem/go-grpc-prometheus v1.2.0/go.mod h1:8NvIoxWQoOIhqOTXgfV/d3M/q6VIi02HzZEHgUlZvzk=
 github.com/grpc-ecosystem/grpc-gateway v1.9.0/go.mod h1:vNeuVxBJEsws4ogUvrchl83t/GYV9WGTSLVdBhOQFDY=
 github.com/grpc-ecosystem/grpc-gateway v1.9.5/go.mod h1:vNeuVxBJEsws4ogUvrchl83t/GYV9WGTSLVdBhOQFDY=
-github.com/hashicorp/errwrap v0.0.0-20141028054710-7554cd9344ce/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=
-github.com/hashicorp/go-cleanhttp v0.5.0/go.mod h1:JpRdi6/HCYpAwUzNwuwqhbovhLtngrth3wmdIIUrZ80=
 github.com/hashicorp/go-cleanhttp v0.5.1/go.mod h1:JpRdi6/HCYpAwUzNwuwqhbovhLtngrth3wmdIIUrZ80=
 github.com/hashicorp/go-hclog v0.9.2/go.mod h1:5CU+agLiy3J7N7QjHK5d05KxGsuXiQLrjA0H7acj2lQ=
-github.com/hashicorp/go-multierror v0.0.0-20161216184304-ed905158d874/go.mod h1:JMRHfdO9jKNzS/+BTlxCjKNQHg/jZAft8U7LloJvN7I=
 github.com/hashicorp/go-retryablehttp v0.6.4/go.mod h1:vAew36LZh98gCBJNLH42IQ1ER/9wtLZZ8meHqQvEYWY=
-github.com/hashicorp/go-safetemp v1.0.0/go.mod h1:oaerMy3BhqiTbVye6QuFhFtIceqFoDHxNAB65b+Rj1I=
-github.com/hashicorp/go-version v1.1.0/go.mod h1:fltr4n8CU8Ke44wwGCBoEymUuxUHl09ZGVZPK5anwXA=
 github.com/hashicorp/golang-lru v0.5.0/go.mod h1:/m3WP610KZHVQ1SGc6re/UDhFvYD7pJ4Ao+sR/qLZy8=
 github.com/hashicorp/golang-lru v0.5.1 h1:0hERBMJE1eitiLkihrMvRVBYAkpHzc/J3QdDN+dAcgU=
 github.com/hashicorp/golang-lru v0.5.1/go.mod h1:/m3WP610KZHVQ1SGc6re/UDhFvYD7pJ4Ao+sR/qLZy8=
+github.com/hashicorp/golang-lru v0.5.4 h1:YDjusn29QI/Das2iO9M0BHnIbxPeyuCHsjMW+lJfyTc=
+github.com/hashicorp/golang-lru v0.5.4/go.mod h1:iADmTwqILo4mZ8BN3D2Q6+9jd8WM5uGBxy+E8yxSoD4=
 github.com/hashicorp/hcl v1.0.0/go.mod h1:E5yfLk+7swimpb2L/Alb/PJmXilQ/rhwaUYs4T20WEQ=
 github.com/hpcloud/tail v1.0.0 h1:nfCOvKYfkgYP8hkirhJocXT2+zOD8yUNjXaWfTlyFKI=
 github.com/hpcloud/tail v1.0.0/go.mod h1:ab1qPbhIpdTxEkNHXyeSf5vhxWSCs/tWer42PpOxQnU=
-github.com/huandu/xstrings v1.2.0/go.mod h1:DvyZB1rfVYsBIigL8HwpZgxHwXozlTgGqn63UyNX5k4=
+github.com/ianlancetaylor/demangle v0.0.0-20181102032728-5e5cf60278f6/go.mod h1:aSSvb/t6k1mPoxDqO4vJh6VOCGPwU4O0C2/Eqndh1Sc=
 github.com/imdario/mergo v0.3.5/go.mod h1:2EnlNZ0deacrJVfApfmtdGgDfMuh/nq6Ok1EcJh5FfA=
-github.com/imdario/mergo v0.3.6/go.mod h1:2EnlNZ0deacrJVfApfmtdGgDfMuh/nq6Ok1EcJh5FfA=
-github.com/imdario/mergo v0.3.7/go.mod h1:2EnlNZ0deacrJVfApfmtdGgDfMuh/nq6Ok1EcJh5FfA=
 github.com/imdario/mergo v0.3.9 h1:UauaLniWCFHWd+Jp9oCEkTBj8VO/9DKg3PV3VCNMDIg=
 github.com/imdario/mergo v0.3.9/go.mod h1:2EnlNZ0deacrJVfApfmtdGgDfMuh/nq6Ok1EcJh5FfA=
+github.com/imdario/mergo v0.3.10 h1:6q5mVkdH/vYmqngx7kZQTjJ5HRsx+ImorDIEQ+beJgc=
+github.com/imdario/mergo v0.3.10/go.mod h1:jmQim1M+e3UYxmgPu/WyfjB3N3VflVyUjjjwH0dnCYA=
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/jbenet/go-context v0.0.0-20150711004518-d14ea06fba99 h1:BQSFePA1RWJOlocH6Fxy8MmwDt+yVQYULKfN0RoTN8A=
 github.com/jbenet/go-context v0.0.0-20150711004518-d14ea06fba99/go.mod h1:1lJo3i6rXxKeerYnT8Nvf0QmHCRC1n8sfWVwXF2Frvo=
 github.com/jessevdk/go-flags v1.4.0/go.mod h1:4FA24M0QyGHXBuZZK/XkWh8h0e1EYbRYJSGM75WSRxI=
 github.com/jonboulle/clockwork v0.1.0/go.mod h1:Ii8DK3G1RaLaWxj9trq07+26W01tbo22gdxWY5EU2bo=
-github.com/json-iterator/go v0.0.0-20180612202835-f2b4162afba3/go.mod h1:+SdeFBvtyEkXs7REEP0seUULqWtbJapLOCVDaaPEHmU=
+github.com/josharian/intern v1.0.0 h1:vlS4z54oSdjm0bgjRigI+G1HpF+tI+9rE5LLzOg8HmY=
+github.com/josharian/intern v1.0.0/go.mod h1:5DoeVV0s6jJacbCEi61lwdGj/aVlrQvzHFFd8Hwg//Y=
 github.com/json-iterator/go v1.1.6/go.mod h1:+SdeFBvtyEkXs7REEP0seUULqWtbJapLOCVDaaPEHmU=
 github.com/json-iterator/go v1.1.7/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=
-github.com/json-iterator/go v1.1.8 h1:QiWkFLKq0T7mpzwOTu6BzNDbfTE8OLrYhVKYMLF46Ok=
-github.com/json-iterator/go v1.1.8/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=
+github.com/json-iterator/go v1.1.10 h1:Kz6Cvnvv2wGdaG/V8yMvfkmNiXq9Ya2KUv4rouJJr68=
+github.com/json-iterator/go v1.1.10/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=
 github.com/jstemmer/go-junit-report v0.0.0-20190106144839-af01ea7f8024/go.mod h1:6v2b51hI/fHJwM22ozAgKL4VKDeJcHhJFhtBdhmNjmU=
-github.com/juju/ansiterm v0.0.0-20180109212912-720a0952cc2a/go.mod h1:UJSiEoRfvx3hP73CvoARgeLjaIOjybY9vj8PUPPFGeU=
+github.com/jstemmer/go-junit-report v0.9.1/go.mod h1:Brl9GWCQeLvo8nXZwPNNblvFj/XSXhF0NWZEnDohbsk=
 github.com/julienschmidt/httprouter v1.2.0/go.mod h1:SYymIcj16QtmaHHD7aYtjjsJG7VTCxuUUipMqKk8s4w=
 github.com/k0kubun/colorstring v0.0.0-20150214042306-9440f1994b88/go.mod h1:3w7q1U84EfirKl04SVQ/s7nPm1ZPhiXd34z40TNz36k=
 github.com/k0kubun/pp v2.3.0+incompatible/go.mod h1:GWse8YhT0p8pT4ir3ZgBbfZild3tgzSScAn6HmfYukg=
@@ -371,10 +322,6 @@ github.com/kevinburke/ssh_config v0.0.0-20190725054713-01f96b0aa0cd/go.mod h1:CT
 github.com/kisielk/errcheck v1.1.0/go.mod h1:EZBBE59ingxPouuu3KfxchcWSUPOHkagtvWXihfKN4Q=
 github.com/kisielk/errcheck v1.2.0/go.mod h1:/BMXB+zMLi60iA8Vv6Ksmxu/1UDYcXs4uQLJ+jE2L00=
 github.com/kisielk/gotool v1.0.0/go.mod h1:XhKaO+MFFWcvkIS/tQcRk01m1F5IRFswLeQ+oQHNcck=
-github.com/klauspost/compress v1.4.0/go.mod h1:RyIbtBH6LamlWaDj8nUwkbUhJ87Yi3uG0guNDohfE1A=
-github.com/klauspost/compress v1.4.1/go.mod h1:RyIbtBH6LamlWaDj8nUwkbUhJ87Yi3uG0guNDohfE1A=
-github.com/klauspost/cpuid v0.0.0-20180405133222-e7e905edc00e/go.mod h1:Pj4uuM528wm8OyEC2QMXAi2YiTZ96dNQPGgoMS4s3ek=
-github.com/klauspost/cpuid v1.2.0/go.mod h1:Pj4uuM528wm8OyEC2QMXAi2YiTZ96dNQPGgoMS4s3ek=
 github.com/konsorten/go-windows-terminal-sequences v1.0.1 h1:mweAR1A6xJ3oS2pRaGiHgQ4OO8tzTaLawm8vnODuwDk=
 github.com/konsorten/go-windows-terminal-sequences v1.0.1/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=
 github.com/konsorten/go-windows-terminal-sequences v1.0.3 h1:CE8S1cTafDpPvMhIxNJKvHsGVBgn1xWYf1NbHQhywc8=
@@ -382,9 +329,9 @@ github.com/konsorten/go-windows-terminal-sequences v1.0.3/go.mod h1:T0+1ngSBFLxv
 github.com/kr/logfmt v0.0.0-20140226030751-b84e30acd515/go.mod h1:+0opPa2QZZtGFBFZlji/RkVcI2GknAs/DXo4wKdlNEc=
 github.com/kr/pretty v0.1.0 h1:L/CwN0zerZDmRFUapSPitk6f+Q3+0za1rQkzVuMiMFI=
 github.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=
+github.com/kr/pretty v0.2.0/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=
 github.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=
 github.com/kr/pty v1.1.5/go.mod h1:9r2w37qlBe7rQ6e1fg1S/9xpWHSnaqNdHD3WcMdbPDA=
-github.com/kr/pty v1.1.8/go.mod h1:O1sed60cT9XZ5uDucP5qwvh+TE3NnUj51EiZO/lmSfw=
 github.com/kr/text v0.1.0 h1:45sCR5RtlFHMR4UwH9sdQ5TC8v0qDQCHnXt+kaKSTVE=
 github.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=
 github.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=
@@ -394,11 +341,6 @@ github.com/labstack/echo v3.3.10+incompatible h1:pGRcYk231ExFAyoAjAfD85kQzRJCRI8
 github.com/labstack/echo v3.3.10+incompatible/go.mod h1:0INS7j/VjnFxD4E2wkz67b8cVwCLbBmJyDaka6Cmk1s=
 github.com/labstack/gommon v0.3.0 h1:JEeO0bvc78PKdyHxloTKiF8BD5iGrH8T6MSeGvSgob0=
 github.com/labstack/gommon v0.3.0/go.mod h1:MULnywXg0yavhxWKc+lOruYdAhDwPK9wf0OL7NoOu+k=
-github.com/lib/pq v1.2.0/go.mod h1:5WUZQaWbwv1U+lTReE5YruASi9Al49XbQIvNi/34Woo=
-github.com/liggitt/tabwriter v0.0.0-20181228230101-89fcab3d43de/go.mod h1:zAbeS9B/r2mtpb6U+EI2rYA5OAXxsYw6wTamcNW+zcE=
-github.com/lithammer/dedent v1.1.0/go.mod h1:jrXYCQtgg0nJiN+StA2KgR7w6CiQNv9Fd/Z9BP0jIOc=
-github.com/logrusorgru/aurora v0.0.0-20181002194514-a7b3b318ed4e/go.mod h1:7rIyQOR62GCctdiQpZ/zOJlFyk6y+94wXzv6RNZgaR4=
-github.com/lunixbochs/vtclean v0.0.0-20180621232353-2d01aacdc34a/go.mod h1:pHhQNgMf3btfWnGBVipUOjRYhoOsdGqdm/+2c2E2WMI=
 github.com/magiconair/properties v1.8.0/go.mod h1:PppfXfuXeibc/6YijjN8zIbojt8czPbwD3XqdrwzmxQ=
 github.com/mailru/easyjson v0.0.0-20160728113105-d5b7844b561a h1:TpvdAwDAt1K4ANVOfcihouRdvP+MgAfDWwBuct4l6ZY=
 github.com/mailru/easyjson v0.0.0-20160728113105-d5b7844b561a/go.mod h1:C1wdFJiN94OJF2b5HbByQZoLdCWB1Yqtg26g4irojpc=
@@ -409,13 +351,12 @@ github.com/mailru/easyjson v0.0.0-20190614124828-94de47d64c63/go.mod h1:C1wdFJiN
 github.com/mailru/easyjson v0.0.0-20190626092158-b2ccc519800e/go.mod h1:C1wdFJiN94OJF2b5HbByQZoLdCWB1Yqtg26g4irojpc=
 github.com/mailru/easyjson v0.7.0 h1:aizVhC/NAAcKWb+5QsU1iNOZb4Yws5UO2I+aIprQITM=
 github.com/mailru/easyjson v0.7.0/go.mod h1:KAzv3t3aY1NaHWoQz1+4F1ccyAH66Jk7yos7ldAVICs=
-github.com/manifoldco/promptui v0.7.0/go.mod h1:n4zTdgP0vr0S3w7/O/g98U+e0gwLScEXGwov2nIKuGQ=
-github.com/matoous/godox v0.0.0-20190911065817-5d6d842e92eb/go.mod h1:1BELzlh859Sh1c6+90blK8lbYy0kwQf1bYlBhBysy1s=
+github.com/mailru/easyjson v0.7.6 h1:8yTIVnZgCoiM1TgqoeTl+LfU5Jg6/xL3QhGQnimLYnA=
+github.com/mailru/easyjson v0.7.6/go.mod h1:xzfreul335JAWq5oZzymOObrkdz5UnU4kGfJJLY9Nlc=
+github.com/markbates/pkger v0.17.1/go.mod h1:0JoVlrol20BSywW79rN3kdFFsE5xYM+rSCQDXbLhiuI=
 github.com/mattn/go-colorable v0.0.9/go.mod h1:9vuHe8Xs5qXnSaW/c/ABM9alt+Vo+STaOChaDxuIBZU=
 github.com/mattn/go-colorable v0.1.2 h1:/bC9yWikZXAL9uJdulbSfyVNIR3n3trXl+v8+1sx8mU=
 github.com/mattn/go-colorable v0.1.2/go.mod h1:U0ppj6V5qS13XJ6of8GYAs25YV2eR4EVcfRqFIhoBtE=
-github.com/mattn/go-colorable v0.1.4 h1:snbPLB8fVfU9iwbbo30TPtbLRzwWu6aJS6Xh4eaaviA=
-github.com/mattn/go-colorable v0.1.4/go.mod h1:U0ppj6V5qS13XJ6of8GYAs25YV2eR4EVcfRqFIhoBtE=
 github.com/mattn/go-isatty v0.0.3/go.mod h1:M+lRXTBqGeGNdLjl/ufCoiOlB5xdOkqRJdNxMWT7Zi4=
 github.com/mattn/go-isatty v0.0.4/go.mod h1:M+lRXTBqGeGNdLjl/ufCoiOlB5xdOkqRJdNxMWT7Zi4=
 github.com/mattn/go-isatty v0.0.8 h1:HLtExJ+uU2HOZ+wI0Tt5DtUDrx8yhUqDcp7fYERX4CE=
@@ -425,35 +366,27 @@ github.com/mattn/go-isatty v0.0.9/go.mod h1:YNRxwqDuOph6SZLI9vUUz6OYw3QyUt7WiY2y
 github.com/mattn/go-isatty v0.0.12 h1:wuysRhFDzyxgEmMf5xjvJ2M9dZoWAXNNr5LSBS7uHXY=
 github.com/mattn/go-isatty v0.0.12/go.mod h1:cbi8OIDigv2wuxKPP5vlRcQ1OAZbq2CE4Kysco4FUpU=
 github.com/mattn/go-runewidth v0.0.2/go.mod h1:LwmH8dsx7+W8Uxz3IHJYH5QSwggIsqBzpuz5H//U1FU=
-github.com/mattn/go-shellwords v1.0.9/go.mod h1:EZzvwXDESEeg03EKmM+RmDnNOPKG4lLtQsUlTZDWQ8Y=
-github.com/mattn/goveralls v0.0.2/go.mod h1:8d1ZMHsd7fW6IRPKQh46F2WRpyib5/X4FOpevwGNQEw=
 github.com/matttproud/golang_protobuf_extensions v1.0.1 h1:4hp9jkHxhMHkqkrB3Ix0jegS5sx/RkqARlsWZ6pIwiU=
 github.com/matttproud/golang_protobuf_extensions v1.0.1/go.mod h1:D8He9yQNgCq6Z5Ld7szi9bcBfOoFv/3dc6xSMkL2PC0=
-github.com/mitchellh/copystructure v1.0.0/go.mod h1:SNtv71yrdKgLRyLFxmLdkAbkKEFWgYaq1OVrnRcwhnw=
-github.com/mitchellh/go-homedir v1.0.0/go.mod h1:SfyaCUpYCn1Vlf4IUYiD9fPX4A5wJrkLzIz1N1q0pr0=
+github.com/matttproud/golang_protobuf_extensions v1.0.2-0.20181231171920-c182affec369 h1:I0XW9+e1XWDxdcEniV4rQAIOPUGDq67JSCiRCgGCZLI=
+github.com/matttproud/golang_protobuf_extensions v1.0.2-0.20181231171920-c182affec369/go.mod h1:BSXmuO+STAnVfrANrmjBb36TMTDstsz7MSK+HVaYKv4=
 github.com/mitchellh/go-homedir v1.1.0 h1:lukF9ziXFxDFPkA1vsr5zpc1XuPDn/wFntq5mG+4E0Y=
 github.com/mitchellh/go-homedir v1.1.0/go.mod h1:SfyaCUpYCn1Vlf4IUYiD9fPX4A5wJrkLzIz1N1q0pr0=
-github.com/mitchellh/go-ps v0.0.0-20190716172923-621e5597135b/go.mod h1:r1VsdOzOPt1ZSrGZWFoNhsAedKnEd6r9Np1+5blZCWk=
-github.com/mitchellh/go-testing-interface v1.0.0/go.mod h1:kRemZodwjscx+RGhAo8eIhFbs2+BFgRtFPeD/KE+zxI=
-github.com/mitchellh/go-wordwrap v1.0.0/go.mod h1:ZXFpozHsX6DPmq2I0TCekCxypsnAUbP2oI0UX1GXzOo=
 github.com/mitchellh/mapstructure v0.0.0-20180220230111-00c29f56e238/go.mod h1:FVVH3fgwuzCH5S8UJGiWEs2h04kUh9fWfEaFds41c1Y=
 github.com/mitchellh/mapstructure v1.1.2/go.mod h1:FVVH3fgwuzCH5S8UJGiWEs2h04kUh9fWfEaFds41c1Y=
-github.com/mitchellh/reflectwalk v1.0.0/go.mod h1:mSTlrgnPZtwu0c4WaC2kGObEpuNDbx0jmZXqmk4esnw=
+github.com/moby/term v0.0.0-20200312100748-672ec06f55cd/go.mod h1:DdlQx2hp0Ss5/fLikoLlEeIYiATotOjgB//nb973jeo=
 github.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=
 github.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd h1:TRLaZ9cD/w8PVh93nsPXa1VrQ6jlwL5oN8l14QlcNfg=
 github.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=
-github.com/modern-go/reflect2 v0.0.0-20180320133207-05fbef0ca5da/go.mod h1:bx2lNnkwVCuqBIxFjflWJWanXIb3RllmbCylyMrvgv0=
 github.com/modern-go/reflect2 v0.0.0-20180701023420-4b7aa43c6742/go.mod h1:bx2lNnkwVCuqBIxFjflWJWanXIb3RllmbCylyMrvgv0=
 github.com/modern-go/reflect2 v1.0.1 h1:9f412s+6RmYXLWZSEzVVgPGK7C2PphHj5RJrvfx9AWI=
 github.com/modern-go/reflect2 v1.0.1/go.mod h1:bx2lNnkwVCuqBIxFjflWJWanXIb3RllmbCylyMrvgv0=
 github.com/mohae/deepcopy v0.0.0-20170929034955-c48cc78d4826/go.mod h1:TaXosZuwdSHYgviHp1DAtfrULt5eUgsSMsZf+YrPgl8=
-github.com/morikuni/aec v1.0.0/go.mod h1:BbKIizmSmc5MMPqRYbxO4ZU0S0+P200+tUnFx7PXmsc=
-github.com/mozilla/tls-observatory v0.0.0-20190404164649-a3c1b6cfecfd/go.mod h1:SrKMQvPiws7F7iqYp8/TX+IhxCYhzr6N/1yb8cwHsGk=
+github.com/monochromegane/go-gitignore v0.0.0-20200626010858-205db1a8cc00/go.mod h1:Pm3mSP3c5uWn86xMLZ5Sa7JB9GsEZySvHYXCTK4E9q4=
 github.com/munnerz/goautoneg v0.0.0-20120707110453-a547fc61f48d/go.mod h1:+n7T8mK8HuQTcFwEeznm/DIxMOiR9yIdICNftLE1DvQ=
 github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822/go.mod h1:+n7T8mK8HuQTcFwEeznm/DIxMOiR9yIdICNftLE1DvQ=
 github.com/mwitkow/go-conntrack v0.0.0-20161129095857-cc309e4a2223/go.mod h1:qRWi+5nqEBWmkhHvq77mSJWrCKwh8bxhgT7d/eI7P4U=
 github.com/mxk/go-flowrate v0.0.0-20140419014527-cca7078d478f/go.mod h1:ZdcZmHo+o7JKHSa8/e818NopupXU1YMK5fe1lsApnBw=
-github.com/nbutton23/zxcvbn-go v0.0.0-20180912185939-ae427f1e4c1d/go.mod h1:o96djdrsSGy3AWPyBgZMAGfxZNfgntdJG+11KU4QvbU=
 github.com/niemeyer/pretty v0.0.0-20200227124842-a10e7caefd8e h1:fD57ERR4JtEqsWbfPhv4DMiApHyliiK5xCTNVSPiaAs=
 github.com/niemeyer/pretty v0.0.0-20200227124842-a10e7caefd8e/go.mod h1:zD1mROLANZcx1PVRCS0qkT7pwLkGfwJo4zjcN/Tysno=
 github.com/nxadm/tail v1.4.4 h1:DQuhQpB1tVlglWS2hLQ5OV6B5r8aGxSrPc5Qo6uTN78=
@@ -463,44 +396,37 @@ github.com/olekukonko/tablewriter v0.0.0-20170122224234-a0225b3f23b5/go.mod h1:v
 github.com/onsi/ginkgo v0.0.0-20170829012221-11459a886d9c/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=
 github.com/onsi/ginkgo v1.6.0 h1:Ix8l273rp3QzYgXSR+c8d1fTG7UPgYkOSELPhiY/YGw=
 github.com/onsi/ginkgo v1.6.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=
-github.com/onsi/ginkgo v1.10.1/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=
 github.com/onsi/ginkgo v1.11.0 h1:JAKSXpt1YjtLA7YpPiqO9ss6sNXEsPfSGdwN0UHqzrw=
 github.com/onsi/ginkgo v1.11.0/go.mod h1:lLunBs/Ym6LB5Z9jYTR76FiuTmxDTDusOGeTQH+WWjE=
 github.com/onsi/ginkgo v1.12.1/go.mod h1:zj2OWP4+oCPe1qIXoGWkgMRwljMUYCdkwsT2108oapk=
 github.com/onsi/ginkgo v1.14.0 h1:2mOpI4JVVPBN+WQRa0WKH2eXR+Ey+uK4n7Zj0aYpIQA=
 github.com/onsi/ginkgo v1.14.0/go.mod h1:iSB4RoI2tjJc9BBv4NKIKWKya62Rps+oPG/Lv9klQyY=
+github.com/onsi/ginkgo v1.14.1 h1:jMU0WaQrP0a/YAEq8eJmJKjBoMs+pClEr1vDMlM/Do4=
+github.com/onsi/ginkgo v1.14.1/go.mod h1:iSB4RoI2tjJc9BBv4NKIKWKya62Rps+oPG/Lv9klQyY=
 github.com/onsi/gomega v0.0.0-20170829124025-dcabb60a477c/go.mod h1:C1qb7wdrVGGVU+Z6iS04AVkA3Q65CEZX59MT0QO5uiA=
 github.com/onsi/gomega v1.7.0/go.mod h1:ex+gbHU/CVuBBDIJjb2X0qEXbFg53c61hWP/1CpauHY=
 github.com/onsi/gomega v1.7.1/go.mod h1:XdKZgCCFLUoM/7CFJVPcG8C1xQ1AJ0vpAezJrB7JYyY=
-github.com/onsi/gomega v1.8.1 h1:C5Dqfs/LeauYDX0jJXIe2SWmwCbGzx9yF8C8xy3Lh34=
-github.com/onsi/gomega v1.8.1/go.mod h1:Ho0h+IUsWyvy1OpqCwxlQ/21gkhVunqlU8fDGcoTdcA=
 github.com/onsi/gomega v1.10.1 h1:o0+MgICZLuZ7xjH7Vx6zS/zcu93/BEp1VwkIW1mEXCE=
 github.com/onsi/gomega v1.10.1/go.mod h1:iN09h71vgCQne3DLsj+A5owkum+a2tYe+TOCB1ybHNo=
-github.com/opencontainers/go-digest v0.0.0-20180430190053-c9281466c8b2/go.mod h1:cMLVZDEM3+U2I4VmLI6N8jQYUd2OVphdqWwCJHrFt2s=
-github.com/opencontainers/go-digest v1.0.0-rc1/go.mod h1:cMLVZDEM3+U2I4VmLI6N8jQYUd2OVphdqWwCJHrFt2s=
-github.com/opencontainers/image-spec v1.0.1/go.mod h1:BtxoFyWECRxE4U/7sNtV5W15zMzWCbyJoFRP3s7yZA0=
-github.com/opencontainers/runc v0.0.0-20190115041553-12f6a991201f/go.mod h1:qT5XzbpPznkRYVz/mWwUaVBUv2rmF59PVA73FjuZG0U=
-github.com/opencontainers/runc v0.1.1/go.mod h1:qT5XzbpPznkRYVz/mWwUaVBUv2rmF59PVA73FjuZG0U=
-github.com/opencontainers/runtime-spec v0.1.2-0.20190507144316-5b71a03e2700/go.mod h1:jwyrGlmzljRJv/Fgzds9SsS/C5hL+LL3ko9hs6T5lQ0=
-github.com/opencontainers/runtime-tools v0.0.0-20181011054405-1d69bd0f9c39/go.mod h1:r3f7wjNzSs2extwzU3Y+6pKfobzPh+kKFJ3ofN+3nfs=
+github.com/onsi/gomega v1.10.2 h1:aY/nuoWlKJud2J6U0E3NWsjlg+0GtwXxgEqthRdzlcs=
+github.com/onsi/gomega v1.10.2/go.mod h1:iN09h71vgCQne3DLsj+A5owkum+a2tYe+TOCB1ybHNo=
 github.com/paulmach/orb v0.1.3/go.mod h1:VFlX/8C+IQ1p6FTRRKzKoOPJnvEtA5G0Veuqwbu//Vk=
 github.com/pborman/uuid v1.2.0/go.mod h1:X/NO0urCmaxf9VXbdlT7C2Yzkj2IKimNn4k+gtPdI/k=
 github.com/pelletier/go-toml v1.2.0/go.mod h1:5z9KED0ma1S8pY6P1sdut58dfprrGBbd/94hg7ilaic=
 github.com/peterbourgon/diskv v2.0.1+incompatible/go.mod h1:uqqh8zWWbv1HBMNONnaR/tNboyR3/BZd58JJSHlUSCU=
-github.com/phayes/freeport v0.0.0-20180830031419-95f893ade6f2/go.mod h1:iIss55rKnNBTvrwdmkUpLnDpZoAHvWaiq5+iMmen4AE=
 github.com/pkg/errors v0.8.0/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=
-github.com/pkg/errors v0.8.1-0.20171018195549-f15c970de5b7/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=
 github.com/pkg/errors v0.8.1 h1:iURUrRGxPUNPdy5/HRSm+Yj6okJ6UtLINN0Q9M4+h3I=
 github.com/pkg/errors v0.8.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=
 github.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=
 github.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=
-github.com/pmezard/go-difflib v0.0.0-20151028094244-d8ed2627bdf0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=
 github.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=
 github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=
 github.com/pquerna/cachecontrol v0.0.0-20171018203845-0dec1b30a021/go.mod h1:prYjPmNq4d1NPVmpShWobRqXY3q7Vp+80DqgxxUrUIA=
 github.com/prometheus/client_golang v0.9.1/go.mod h1:7SWBe2y4D6OKWSNQJUaRYU/AaXPKyh/dDVn+NZz0KFw=
 github.com/prometheus/client_golang v0.9.3/go.mod h1:/TN21ttK/J9q6uSwhBd54HahCDft0ttaMvbicHlPoso=
 github.com/prometheus/client_golang v1.0.0/go.mod h1:db9x61etRT2tGnBNRi70OPL5FsnadC4Ky3P0J6CfImo=
+github.com/prometheus/client_golang v1.7.1 h1:NTGy1Ja9pByO+xAeH/qiWnLrKtr3hJPNjaVUwnjpdpA=
+github.com/prometheus/client_golang v1.7.1/go.mod h1:PY5Wy2awLA44sXw4AOSfFBetzPP4j5+D6mVACh+pe2M=
 github.com/prometheus/client_model v0.0.0-20180712105110-5c3871d89910/go.mod h1:MbSGuTsp3dbXC40dX6PRTWyKYBIrTGTE9sqQNg2J8bo=
 github.com/prometheus/client_model v0.0.0-20190129233127-fd36f4220a90/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=
 github.com/prometheus/client_model v0.0.0-20190812154241-14fe0d1b01d4/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=
@@ -509,155 +435,150 @@ github.com/prometheus/client_model v0.2.0/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6T
 github.com/prometheus/common v0.0.0-20181113130724-41aa239b4cce/go.mod h1:daVV7qP5qjZbuso7PdcryaAu0sAZbrN9i7WWcTMWvro=
 github.com/prometheus/common v0.4.0/go.mod h1:TNfzLD0ON7rHzMJeJkieUDPYmFC7Snx/y86RQel1bk4=
 github.com/prometheus/common v0.4.1/go.mod h1:TNfzLD0ON7rHzMJeJkieUDPYmFC7Snx/y86RQel1bk4=
+github.com/prometheus/common v0.10.0 h1:RyRA7RzGXQZiW+tGMr7sxa85G1z0yOpM1qq5c8lNawc=
+github.com/prometheus/common v0.10.0/go.mod h1:Tlit/dnDKsSWFlCLTWaA1cyBgKHSMdTB80sz/V91rCo=
 github.com/prometheus/procfs v0.0.0-20181005140218-185b4288413d/go.mod h1:c3At6R/oaqEKCNdg8wHV1ftS6bRYblBhIjjI8uT2IGk=
 github.com/prometheus/procfs v0.0.0-20190507164030-5867b95ac084/go.mod h1:TjEm7ze935MbeOT/UhFTIMYKhuLP4wbCsTZCD3I8kEA=
 github.com/prometheus/procfs v0.0.2/go.mod h1:TjEm7ze935MbeOT/UhFTIMYKhuLP4wbCsTZCD3I8kEA=
-github.com/prometheus/procfs v0.0.5/go.mod h1:4A/X28fw3Fc593LaREMrKMqOKvUAntwMDaekg4FpcdQ=
+github.com/prometheus/procfs v0.1.3 h1:F0+tqvhOksq22sc6iCHF5WGlWjdwj92p0udFh1VFBS8=
+github.com/prometheus/procfs v0.1.3/go.mod h1:lV6e/gmhEcM9IjHGsFOCxxuZ+z1YqCvr4OA4YeYWdaU=
 github.com/prometheus/tsdb v0.7.1/go.mod h1:qhTCs0VvXwvX/y3TZrWD7rabWM+ijKTux40TwIPHuXU=
 github.com/qri-io/starlib v0.4.2-0.20200213133954-ff2e8cd5ef8d/go.mod h1:7DPO4domFU579Ga6E61sB9VFNaniPVwJP5C4bBCu3wA=
-github.com/quasilyte/go-consistent v0.0.0-20190521200055-c6f3937de18c/go.mod h1:5STLWrekHfjyYwxBRVRXNOSewLJ3PWfDJd1VyTS21fI=
-github.com/remyoudompheng/bigfft v0.0.0-20170806203942-52369c62f446/go.mod h1:uYEyJGbgTkfkS4+E/PavXkNJcbFIpEtjt2B0KDQ5+9M=
 github.com/rjeczalik/notify v0.9.2 h1:MiTWrPj55mNDHEiIX5YUSKefw/+lCQVoAFmD6oQm5w8=
 github.com/rjeczalik/notify v0.9.2/go.mod h1:aErll2f0sUX9PXZnVNyeiObbmTlk5jnMoCa4QEjJeqM=
 github.com/rogpeppe/fastuuid v0.0.0-20150106093220-6724a57986af/go.mod h1:XWv6SoW27p1b0cqNHllgS5HIMJraePCO15w5zCzIWYg=
 github.com/rogpeppe/go-internal v1.3.0/go.mod h1:M8bDsm7K2OlrFYOpmOWEs/qY81heoFRclV5y23lUDJ4=
-github.com/russross/blackfriday v1.5.2/go.mod h1:JO/DiYxRf+HjHt06OyowR9PTA263kcR/rfWxYHBV53g=
 github.com/russross/blackfriday/v2 v2.0.1/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=
-github.com/securego/gosec v0.0.0-20191002120514-e680875ea14d/go.mod h1:w5+eXa0mYznDkHaMCXA4XYffjlH+cy1oyKbfzJXa2Do=
 github.com/sergi/go-diff v1.0.0/go.mod h1:0CfEIISq7TuYL3j771MWULgwwjU+GofnZX9QAmXWZgo=
 github.com/sergi/go-diff v1.1.0 h1:we8PVUC3FE2uYfodKH/nBHMSetSfHDR6scGdBi+erh0=
 github.com/sergi/go-diff v1.1.0/go.mod h1:STckp+ISIX8hZLjrqAeVduY0gWCT9IjLuqbuNXdaHfM=
-github.com/shirou/gopsutil v0.0.0-20190901111213-e4ec7b275ada/go.mod h1:WWnYX4lzhCH5h/3YBfyVA3VbLYjlMZZAQcW9ojMexNc=
-github.com/shirou/w32 v0.0.0-20160930032740-bb4de0191aa4/go.mod h1:qsXQc7+bwAM3Q1u/4XEfrquwF8Lw7D7y5cD8CuHnfIc=
-github.com/shurcooL/go v0.0.0-20180423040247-9e1955d9fb6e/go.mod h1:TDJrrUr11Vxrven61rcy3hJMUqaf/CLWYhHNPmT14Lk=
-github.com/shurcooL/go-goon v0.0.0-20170922171312-37c2f522c041/go.mod h1:N5mDOmsrJOB+vfqUK+7DmDyjhSLIIBnXo9lvZJj3MWQ=
 github.com/shurcooL/sanitized_anchor_name v1.0.0/go.mod h1:1NzhyTcUVG4SuEtjjoZeVRXNmyL/1OwPU0+IJeTBvfc=
-github.com/sirupsen/logrus v1.0.4-0.20170822132746-89742aefa4b2/go.mod h1:pMByvHTf9Beacp5x1UXfOR9xyW/9antXMhjMPG0dEzc=
 github.com/sirupsen/logrus v1.2.0/go.mod h1:LxeOpSwHxABJmUn/MG1IvRgCAasNZTLOkJPxbbu5VWo=
-github.com/sirupsen/logrus v1.4.1/go.mod h1:ni0Sbl8bgC9z8RoU9G6nDWqqs/fq4eDPysMBDgk/93Q=
 github.com/sirupsen/logrus v1.4.2 h1:SPIRibHv4MatM3XXNO2BJeFLZwZ2LvZgfQ5+UNI2im4=
 github.com/sirupsen/logrus v1.4.2/go.mod h1:tLMulIdttU9McNUspp0xgXVQah82FyeX6MwdIuYE2rE=
 github.com/sirupsen/logrus v1.6.0 h1:UBcNElsrwanuuMsnGSlYmtmgbb23qDR5dG+6X6Oo89I=
 github.com/sirupsen/logrus v1.6.0/go.mod h1:7uNnSEd1DgxDLC74fIahvMZmmYsHGZGEOFrfsX/uA88=
+github.com/sirupsen/logrus v1.7.0 h1:ShrD1U9pZB12TX0cVy0DtePoCH97K8EtX+mg7ZARUtM=
+github.com/sirupsen/logrus v1.7.0/go.mod h1:yWOB1SBYBC5VeMP7gHvWumXLIWorT60ONWic61uBYv0=
 github.com/soheilhy/cmux v0.1.4/go.mod h1:IM3LyeVVIOuxMH7sFAkER9+bJ4dT7Ms6E4xg4kGIyLM=
-github.com/sosedoff/gitkit v0.2.1-0.20191202022816-7182d43c6254/go.mod h1:A+o6ZazfVJwetlcHz3ah6th66XcBdsyzLo+aBt/AsK4=
-github.com/sourcegraph/go-diff v0.5.1/go.mod h1:j2dHj3m8aZgQO8lMTcTnBcXkRRRqi34cd2MNlA9u1mE=
 github.com/spaolacci/murmur3 v0.0.0-20180118202830-f09979ecbc72/go.mod h1:JwIasOWyU6f++ZhiEuf87xNszmSA2myDM2Kzu9HwQUA=
 github.com/spf13/afero v1.1.2/go.mod h1:j4pytiNVoe2o6bmDsKpLACNPDBIoEAkihy7loJ1B0CQ=
+github.com/spf13/afero v1.2.2 h1:5jhuqJyZCZf2JRofRvN/nIFgIWNzPa3/Vz8mYylgbWc=
 github.com/spf13/afero v1.2.2/go.mod h1:9ZxEEn6pIJ8Rxe320qSDBk6AsU0r9pR7Q4OcevTdifk=
 github.com/spf13/cast v1.3.0/go.mod h1:Qx5cxh0v+4UWYiBimWS+eyWzqEqokIECu5etghLkUJE=
-github.com/spf13/cobra v0.0.2-0.20171109065643-2da4a54c5cee/go.mod h1:1l0Ry5zgKvJasoi3XT1TypsSe7PqH0Sj9dhYf7v3XqQ=
 github.com/spf13/cobra v0.0.3/go.mod h1:1l0Ry5zgKvJasoi3XT1TypsSe7PqH0Sj9dhYf7v3XqQ=
-github.com/spf13/cobra v0.0.5/go.mod h1:3K3wKZymM7VvHMDS9+Akkh4K60UwM26emMESw8tLCHU=
 github.com/spf13/cobra v1.0.0/go.mod h1:/6GTrnGXV9HjY+aR4k0oJ5tcvakLuG6EuKReYlHNrgE=
 github.com/spf13/jwalterweatherman v1.0.0/go.mod h1:cQK4TGJAtQXfYWX+Ddv3mKDzgVb68N+wFjFa4jdeBTo=
 github.com/spf13/pflag v0.0.0-20170130214245-9ff6c6923cff/go.mod h1:DYY7MBk1bdzusC3SYhjObp+wFpr4gzcvqqNjLnInEg4=
-github.com/spf13/pflag v1.0.1-0.20171106142849-4c012f6dcd95/go.mod h1:DYY7MBk1bdzusC3SYhjObp+wFpr4gzcvqqNjLnInEg4=
 github.com/spf13/pflag v1.0.1/go.mod h1:DYY7MBk1bdzusC3SYhjObp+wFpr4gzcvqqNjLnInEg4=
 github.com/spf13/pflag v1.0.3/go.mod h1:DYY7MBk1bdzusC3SYhjObp+wFpr4gzcvqqNjLnInEg4=
 github.com/spf13/pflag v1.0.5 h1:iy+VFUOCP1a+8yFto/drg2CJ5u0yRoB7fZw3DKv/JXA=
 github.com/spf13/pflag v1.0.5/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=
-github.com/spf13/viper v1.3.2/go.mod h1:ZiWeW+zYFKm7srdB9IoDzzZXaJaI5eL9QjNiN/DMA2s=
 github.com/spf13/viper v1.4.0/go.mod h1:PTJ7Z/lr49W6bUbkmS1V3by4uWynFiR9p7+dSq/yZzE=
+github.com/stoewer/go-strcase v1.2.0/go.mod h1:IBiWB2sKIp3wVVQ3Y035++gc+knqhUQag1KpM8ahLw8=
 github.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=
 github.com/stretchr/objx v0.1.1/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=
 github.com/stretchr/objx v0.2.0 h1:Hbg2NidpLE8veEBkEZTL3CvlkUIVzuU9jDplZO54c48=
 github.com/stretchr/objx v0.2.0/go.mod h1:qt09Ya8vawLte6SNmTgCsAVtYtaKzEcn8ATUoHMkEqE=
-github.com/stretchr/testify v0.0.0-20151208002404-e3a8ff8ce365/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=
 github.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=
 github.com/stretchr/testify v1.2.3-0.20181224173747-660f15d67dbb/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=
 github.com/stretchr/testify v1.3.0 h1:TivCn/peBQ7UY8ooIcPgZFpTNSz0Q2U6UrFlUfqbe0Q=
 github.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=
 github.com/stretchr/testify v1.4.0 h1:2E4SXV/wtOkTonXsotYi4li6zVWxYlZuYNCXe9XRJyk=
 github.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=
+github.com/stretchr/testify v1.5.1/go.mod h1:5W2xD1RspED5o8YsWQXVCued0rvSQ+mT+I5cxcmMvtA=
 github.com/stretchr/testify v1.6.1 h1:hDPOHmpOpP40lSULcqw7IrRb/u7w6RpDC9399XyoNd0=
 github.com/stretchr/testify v1.6.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=
-github.com/syndtr/gocapability v0.0.0-20170704070218-db04d3cc01c8/go.mod h1:hkRG7XYTFWNJGYcbNJQlaLq0fg1yr4J4t/NcTQtrfww=
 github.com/tidwall/pretty v1.0.0/go.mod h1:XNkn88O1ChpSDQmQeStsy+sBenx6DDtFZJxhVysOjyk=
-github.com/timakin/bodyclose v0.0.0-20190930140734-f7f2e9bca95e/go.mod h1:Qimiffbc6q9tBWlVV6x0P9sat/ao1xEkREYPPj9hphk=
 github.com/tmc/grpc-websocket-proxy v0.0.0-20170815181823-89b8d40f7ca8/go.mod h1:ncp9v5uamzpCO7NfCPTXjqaC+bZgJeR0sMTm6dMHP7U=
 github.com/tmc/grpc-websocket-proxy v0.0.0-20190109142713-0ad062ec5ee5/go.mod h1:ncp9v5uamzpCO7NfCPTXjqaC+bZgJeR0sMTm6dMHP7U=
 github.com/ugorji/go v1.1.4/go.mod h1:uQMGLiO92mf5W77hV/PUCpI3pbzQx3CRekS0kk+RGrc=
-github.com/ugorji/go/codec v0.0.0-20181204163529-d75b2dcb6bc8/go.mod h1:VFNgLljTbGfSG7qAOspJ7OScBnGdDN/yBr0sguwnwf0=
-github.com/ulikunitz/xz v0.5.5/go.mod h1:2bypXElzHzzJZwzH67Y6wb67pO62Rzfn7BSiF4ABRW8=
-github.com/ultraware/funlen v0.0.2/go.mod h1:Dp4UiAus7Wdb9KUZsYWZEWiRzGuM2kXM1lPbfaF6xhA=
-github.com/ultraware/whitespace v0.0.4/go.mod h1:aVMh/gQve5Maj9hQ/hg+F75lr/X5A89uZnzAmWSineA=
-github.com/urfave/cli v0.0.0-20171014202726-7bc6a0acffa5/go.mod h1:70zkFmudgCuE/ngEzBv17Jvp/497gISqfk5gWijbERA=
 github.com/urfave/cli v1.20.0/go.mod h1:70zkFmudgCuE/ngEzBv17Jvp/497gISqfk5gWijbERA=
-github.com/uudashr/gocognit v0.0.0-20190926065955-1655d0de0517/go.mod h1:j44Ayx2KW4+oB6SWMv8KsmHzZrOInQav7D3cQMJ5JUM=
 github.com/valyala/bytebufferpool v1.0.0 h1:GqA5TC/0021Y/b9FG4Oi9Mr3q7XYx6KllzawFIhcdPw=
 github.com/valyala/bytebufferpool v1.0.0/go.mod h1:6bBcMArwyJ5K/AmCkWv1jt77kVWyCJ6HpOuEn7z0Csc=
-github.com/valyala/fasthttp v1.2.0/go.mod h1:4vX61m6KN+xDduDNwXrhIAVZaZaZiQ1luJk8LWSxF3s=
 github.com/valyala/fasttemplate v1.0.1 h1:tY9CJiPnMXf1ERmG2EyK7gNUd+c6RKGD0IfU8WdUSz8=
 github.com/valyala/fasttemplate v1.0.1/go.mod h1:UQGH1tvbgY+Nz5t2n7tXsz52dQxojPUpymEIMZ47gx8=
-github.com/valyala/quicktemplate v1.2.0/go.mod h1:EH+4AkTd43SvgIbQHYu59/cJyxDoOVRUAfrukLPuGJ4=
-github.com/valyala/tcplisten v0.0.0-20161114210144-ceec8f93295a/go.mod h1:v3UYOV9WzVtRmSR+PDvWpU/qWl4Wa5LApYYX4ZtKbio=
 github.com/vektah/gqlparser v1.1.2/go.mod h1:1ycwN7Ij5njmMkPPAOaRFY4rET2Enx7IkVv3vaXspKw=
 github.com/xanzy/go-gitlab v0.33.0/go.mod h1:sPLojNBn68fMUWSxIJtdVVIP8uSBYqesTfDUseX11Ug=
 github.com/xanzy/ssh-agent v0.2.1 h1:TCbipTQL2JiiCprBWx9frJ2eJlCYT00NmctrHxVAr70=
 github.com/xanzy/ssh-agent v0.2.1/go.mod h1:mLlQY/MoOhWBj+gOGMQkOeiEvkx+8pJSI+0Bx9h2kr4=
-github.com/xeipuuv/gojsonpointer v0.0.0-20180127040702-4e3ac2762d5f/go.mod h1:N2zxlSyiKSe5eX1tZViRH5QA0qijqEDrYZiPEAiq3wU=
-github.com/xeipuuv/gojsonreference v0.0.0-20180127040603-bd5ef7bd5415/go.mod h1:GwrjFmJcFw6At/Gs6z4yjiIwzuJ1/+UwLxMQDVQXShQ=
-github.com/xeipuuv/gojsonschema v0.0.0-20180618132009-1d523034197f/go.mod h1:5yf86TLmAcydyeJq5YvxkGPE2fm/u4myDekKRoLuqhs=
-github.com/xeipuuv/gojsonschema v1.1.0/go.mod h1:5yf86TLmAcydyeJq5YvxkGPE2fm/u4myDekKRoLuqhs=
 github.com/xiang90/probing v0.0.0-20190116061207-43a291ad63a2/go.mod h1:UETIi67q53MR2AWcXfiuqkDkRtnGDLqkBTpCHuJHxtU=
-github.com/xlab/handysort v0.0.0-20150421192137-fb3537ed64a1/go.mod h1:QcJo0QPSfTONNIgpN5RA8prR7fF8nkF6cTWTcNerRO8=
 github.com/xlab/treeprint v0.0.0-20181112141820-a009c3971eca/go.mod h1:ce1O1j6UtZfjr22oyGxGLbauSBp2YVXpARAosm7dHBg=
 github.com/xordataexchange/crypt v0.0.3-0.20170626215501-b2862e3d0a77/go.mod h1:aYKd//L2LvnjZzWKhF00oedf4jCCReLcmhLdhm1A27Q=
-github.com/yujunz/go-getter v1.4.1-lite/go.mod h1:sbmqxXjyLunH1PkF3n7zSlnVeMvmYUuIl9ZVs/7NyCc=
+github.com/yuin/goldmark v1.1.27/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=
 go.etcd.io/bbolt v1.3.2/go.mod h1:IbVyRI1SCnLcuJnV2u8VeU0CEYM7e686BmAb1XKL+uU=
 go.etcd.io/bbolt v1.3.3/go.mod h1:IbVyRI1SCnLcuJnV2u8VeU0CEYM7e686BmAb1XKL+uU=
-go.etcd.io/etcd v0.0.0-20191023171146-3cf2f69b5738/go.mod h1:dnLIgRNXwCJa5e+c6mIZCrds/GIG4ncV9HhK5PX7jPg=
+go.etcd.io/bbolt v1.3.5/go.mod h1:G5EMThwa9y8QZGBClrRx5EY+Yw9kAhnjy3bSjsnlVTQ=
+go.etcd.io/etcd v0.5.0-alpha.5.0.20200819165624-17cef6e3e9d5/go.mod h1:skWido08r9w6Lq/w70DO5XYIKMu4QFu1+4VsqLQuJy8=
 go.mongodb.org/mongo-driver v1.0.3/go.mod h1:u7ryQJ+DOzQmeO7zB6MHyr8jkEQvC8vH7qLUO4lqsUM=
 go.mongodb.org/mongo-driver v1.1.1/go.mod h1:u7ryQJ+DOzQmeO7zB6MHyr8jkEQvC8vH7qLUO4lqsUM=
 go.mongodb.org/mongo-driver v1.1.2/go.mod h1:u7ryQJ+DOzQmeO7zB6MHyr8jkEQvC8vH7qLUO4lqsUM=
 go.opencensus.io v0.21.0/go.mod h1:mSImk1erAIZhrmZN+AvHh14ztQfjbGwt4TtuofqLduU=
 go.opencensus.io v0.22.0/go.mod h1:+kGneAE2xo2IficOXnaByMWTGM9T73dGwxeWcUqIpI8=
+go.opencensus.io v0.22.2/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=
 go.starlark.net v0.0.0-20190528202925-30ae18b8564f/go.mod h1:c1/X6cHgvdXj6pUlmWKMkuqRnW4K8x2vwt6JAaaircg=
 go.starlark.net v0.0.0-20200306205701-8dd3e2ee1dd5/go.mod h1:nmDLcffg48OtT/PSW0Hg7FvpRQsQh5OSqIylirxKC7o=
 go.uber.org/atomic v1.3.2/go.mod h1:gD2HeocX3+yG+ygLZcrzQJaqmWj9AIm7n08wl/qW/PE=
 go.uber.org/atomic v1.4.0 h1:cxzIVoETapQEqDhQu3QfnvXAV4AlzcvUCxkVUFw3+EU=
 go.uber.org/atomic v1.4.0/go.mod h1:gD2HeocX3+yG+ygLZcrzQJaqmWj9AIm7n08wl/qW/PE=
+go.uber.org/atomic v1.6.0 h1:Ezj3JGmsOnG1MoRWQkPBsKLe9DwWD9QeXzTRzzldNVk=
+go.uber.org/atomic v1.6.0/go.mod h1:sABNBOSYdrvTF6hTgEIbc7YasKWGhgEQZyfxyTvoXHQ=
+go.uber.org/goleak v1.1.10 h1:z+mqJhf6ss6BSfSM671tgKyZBFPTTJM+HLxnhPC3wu0=
+go.uber.org/goleak v1.1.10/go.mod h1:8a7PlsEVH3e/a/GLqe5IIrQx6GzcnRmZEufDUTk4A7A=
 go.uber.org/multierr v1.1.0 h1:HoEmRHQPVSqub6w2z2d2EOVs2fjyFRGyofhKuyDq0QI=
 go.uber.org/multierr v1.1.0/go.mod h1:wR5kodmAFQ0UK8QlbwjlSNy0Z68gJhDJUG5sjR94q/0=
+go.uber.org/multierr v1.5.0 h1:KCa4XfM8CWFCpxXRGok+Q0SS/0XBhMDbHHGABQLvD2A=
+go.uber.org/multierr v1.5.0/go.mod h1:FeouvMocqHpRaaGuG9EjoKcStLC43Zu/fmqdUMPcKYU=
+go.uber.org/tools v0.0.0-20190618225709-2cfd321de3ee h1:0mgffUl7nfd+FpvXMVz4IDEaUSmT1ysygQC7qYo7sG4=
+go.uber.org/tools v0.0.0-20190618225709-2cfd321de3ee/go.mod h1:vJERXedbb3MVM5f9Ejo0C68/HhF8uaILCdgjnY+goOA=
+go.uber.org/zap v1.8.0/go.mod h1:vwi/ZaCAaUcBkycHslxD9B2zi4UTXhF60s6SWpuDF0Q=
 go.uber.org/zap v1.10.0 h1:ORx85nbTijNz8ljznvCMR1ZBIPKFn3jQrag10X2AsuM=
 go.uber.org/zap v1.10.0/go.mod h1:vwi/ZaCAaUcBkycHslxD9B2zi4UTXhF60s6SWpuDF0Q=
-golang.org/x/crypto v0.0.0-20171113213409-9f005a07e0d3/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=
+go.uber.org/zap v1.15.0 h1:ZZCA22JRF2gQE5FoNmhmrf7jeJJ2uhqDUNRYKm8dvmM=
+go.uber.org/zap v1.15.0/go.mod h1:Mb2vm2krFEG5DV0W9qcHBYFtp/Wku1cvYaqPsS/WYfc=
 golang.org/x/crypto v0.0.0-20180904163835-0709b304e793/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=
-golang.org/x/crypto v0.0.0-20181203042331-505ab145d0a9/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=
-golang.org/x/crypto v0.0.0-20190211182817-74369b46fc67/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=
 golang.org/x/crypto v0.0.0-20190219172222-a4c6cb3142f2/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=
 golang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=
 golang.org/x/crypto v0.0.0-20190320223903-b7391e95e576/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=
 golang.org/x/crypto v0.0.0-20190510104115-cbcb75029529/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=
+golang.org/x/crypto v0.0.0-20190605123033-f99c8df09eb5/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=
 golang.org/x/crypto v0.0.0-20190611184440-5c40567a22f8 h1:1wopBVtVdWnn03fZelqdXTqk7U7zPQCb+T4rbU9ZEoU=
 golang.org/x/crypto v0.0.0-20190611184440-5c40567a22f8/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=
 golang.org/x/crypto v0.0.0-20190617133340-57b3e21c3d56/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=
-golang.org/x/crypto v0.0.0-20190820162420-60c769a6c586/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=
-golang.org/x/crypto v0.0.0-20190911031432-227b76d455e7/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=
-golang.org/x/crypto v0.0.0-20190923035154-9ee001bba392/go.mod h1:/lpIB1dKB+9EgE3H3cr1v9wB50oz8l4C4h62xy7jSTY=
-golang.org/x/crypto v0.0.0-20200128174031-69ecbb4d6d5d/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=
-golang.org/x/crypto v0.0.0-20200220183623-bac4c82f6975/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=
+golang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=
+golang.org/x/crypto v0.0.0-20191206172530-e9b2fee46413/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=
 golang.org/x/crypto v0.0.0-20200302210943-78000ba7a073 h1:xMPOj6Pz6UipU1wXLkrtqpHbR0AVFnyPEQq/wRWz9lM=
 golang.org/x/crypto v0.0.0-20200302210943-78000ba7a073/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=
 golang.org/x/crypto v0.0.0-20200622213623-75b288015ac9 h1:psW17arqaxU48Z5kZ0CQnkZWQJsqcURM6tKiBApRjXI=
 golang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=
 golang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=
-golang.org/x/exp v0.0.0-20190125153040-c74c464bbbf2/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=
-golang.org/x/exp v0.0.0-20190312203227-4b39c73a6495/go.mod h1:ZjyILWgesfNpC6sMxTJOJm9Kp84zZh5NQWvqDGG3Qr8=
+golang.org/x/exp v0.0.0-20190306152737-a1d7652674e8/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=
+golang.org/x/exp v0.0.0-20190510132918-efd6b22b2522/go.mod h1:ZjyILWgesfNpC6sMxTJOJm9Kp84zZh5NQWvqDGG3Qr8=
+golang.org/x/exp v0.0.0-20190829153037-c13cbed26979/go.mod h1:86+5VVa7VpoJ4kLfm080zCjGlMRFzhUhsZKEZO7MGek=
+golang.org/x/exp v0.0.0-20191227195350-da58074b4299/go.mod h1:2RIsYlXP63K8oxa1u096TMicItID8zy7Y6sNkU49FU4=
 golang.org/x/image v0.0.0-20190227222117-0694c2d4d067/go.mod h1:kZ7UVZpmo3dzQBMxlp+ypCbDeSB+sBbTgSJuh5dn5js=
+golang.org/x/image v0.0.0-20190802002840-cff245a6509b/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=
 golang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=
 golang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=
 golang.org/x/lint v0.0.0-20190301231843-5614ed5bae6f/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=
 golang.org/x/lint v0.0.0-20190313153728-d0100b6bd8b3/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=
+golang.org/x/lint v0.0.0-20190409202823-959b441ac422/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=
+golang.org/x/lint v0.0.0-20190909230951-414d861bb4ac/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=
+golang.org/x/lint v0.0.0-20190930215403-16217165b5de/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=
+golang.org/x/lint v0.0.0-20191125180803-fdd1cda4f05f h1:J5lckAjkw6qYlOZNj90mLYNTEKDvWeuc1yieZ8qUzUE=
+golang.org/x/lint v0.0.0-20191125180803-fdd1cda4f05f/go.mod h1:5qLYkcX4OjUUV8bRuDixDT3tpyyb+LUpUlRWLxfhWrs=
 golang.org/x/mobile v0.0.0-20190312151609-d3739f865fa6/go.mod h1:z+o9i4GpDbdi3rU15maQ/Ox0txvL9dWGYEHz965HBQE=
+golang.org/x/mobile v0.0.0-20190719004257-d2bd2a29d028/go.mod h1:E/iHnbuqvinMTCcRqshq8CkpyQDoeVncDDYHnLhea+o=
 golang.org/x/mod v0.0.0-20190513183733-4bf6d317e70e/go.mod h1:mXi4GBBbnImb6dmsKGUJ2LatrhH/nqhxcFungHvyanc=
-golang.org/x/net v0.0.0-20170114055629-f2499483f923/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=
+golang.org/x/mod v0.1.0/go.mod h1:0QHyrYULN0/3qlju5TqG8bIK38QM8yzMo5ekMj3DlcY=
+golang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=
+golang.org/x/mod v0.2.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=
+golang.org/x/mod v0.3.0 h1:RM4zey1++hCTbCVQfnWeKs9/IEsaBLA8vTkd0WVtmH4=
+golang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=
 golang.org/x/net v0.0.0-20180218175443-cbe0f9307d01/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=
 golang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=
 golang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=
 golang.org/x/net v0.0.0-20180906233101-161cd47e91fd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=
-golang.org/x/net v0.0.0-20180911220305-26e67e76b6c3/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=
 golang.org/x/net v0.0.0-20181005035420-146acd28ed58/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=
 golang.org/x/net v0.0.0-20181108082009-03003ca0c849/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=
 golang.org/x/net v0.0.0-20181114220301-adae6a3d119a/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=
@@ -669,26 +590,32 @@ golang.org/x/net v0.0.0-20190320064053-1272bf9dcd53/go.mod h1:t9HGtf8HONx5eT2rtn
 golang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3 h1:0GoQqolDA55aaLxZyTzK/Y2ePZzZTUrRacwib7cNsYQ=
 golang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=
 golang.org/x/net v0.0.0-20190501004415-9ce7a6920f09/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=
+golang.org/x/net v0.0.0-20190503192946-f4e77d36d62c/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=
 golang.org/x/net v0.0.0-20190522155817-f3200d17e092/go.mod h1:HSz+uSET+XFnRR8LxR5pz3Of3rY3CfYBVs4xY44aLks=
+golang.org/x/net v0.0.0-20190603091049-60506f45cf65/go.mod h1:HSz+uSET+XFnRR8LxR5pz3Of3rY3CfYBVs4xY44aLks=
 golang.org/x/net v0.0.0-20190613194153-d28f0bde5980 h1:dfGZHvZk057jK2MCeWus/TowKpJ8y4AmooUzdBSR9GU=
 golang.org/x/net v0.0.0-20190613194153-d28f0bde5980/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=
 golang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=
 golang.org/x/net v0.0.0-20190813141303-74dc4d7220e7/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=
 golang.org/x/net v0.0.0-20190827160401-ba9fcec4b297/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=
-golang.org/x/net v0.0.0-20190923162816-aa69164e4478/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=
 golang.org/x/net v0.0.0-20191004110552-13f9640d40b9/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=
+golang.org/x/net v0.0.0-20191209160850-c0dbc17a3553/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=
 golang.org/x/net v0.0.0-20200226121028-0de0cce0169b/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=
 golang.org/x/net v0.0.0-20200301022130-244492dfa37a h1:GuSPYbZzB5/dcLNCwLQLsg3obCJtX9IJhpXkvY7kzk0=
 golang.org/x/net v0.0.0-20200301022130-244492dfa37a/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=
+golang.org/x/net v0.0.0-20200324143707-d3edc9973b7e/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=
 golang.org/x/net v0.0.0-20200520004742-59133d7f0dd7/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=
-golang.org/x/net v0.0.0-20200625001655-4c5254603344 h1:vGXIOMxbNfDTk/aXCmfdLgkrSV+Z2tcbze+pEc3v5W4=
-golang.org/x/net v0.0.0-20200625001655-4c5254603344/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=
+golang.org/x/net v0.0.0-20200707034311-ab3426394381/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=
+golang.org/x/net v0.0.0-20201110031124-69a78807bb2b h1:uwuIcX0g4Yl1NC5XAz37xsr2lTtcqevgzYNVt49waME=
+golang.org/x/net v0.0.0-20201110031124-69a78807bb2b/go.mod h1:sp8m0HH+o8qH0wwXwYZr8TS3Oi6o0r6Gce1SSxlDquU=
 golang.org/x/oauth2 v0.0.0-20180227000427-d7d64896b5ff/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=
 golang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=
 golang.org/x/oauth2 v0.0.0-20181106182150-f42d05182288/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=
 golang.org/x/oauth2 v0.0.0-20190226205417-e64efc72b421/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=
 golang.org/x/oauth2 v0.0.0-20190604053449-0f29369cfe45 h1:SVwTIAaPC2U/AvvLNZ2a7OVsmBpC8L5BlwK1whH3hm0=
 golang.org/x/oauth2 v0.0.0-20190604053449-0f29369cfe45/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=
+golang.org/x/oauth2 v0.0.0-20191202225959-858c2ad4c8b6 h1:pE8b58s1HRDMi8RDc79m0HISf9D4TzseP40cEA6IGfs=
+golang.org/x/oauth2 v0.0.0-20191202225959-858c2ad4c8b6/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=
 golang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
 golang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
 golang.org/x/sync v0.0.0-20181221193216-37e7f081c4d4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
@@ -696,7 +623,6 @@ golang.org/x/sync v0.0.0-20190227155943-e225da77a7e6/go.mod h1:RxMgew5VJxzue5/jJ
 golang.org/x/sync v0.0.0-20190423024810-112230192c58 h1:8gQV6CLnAEikrhgkHFbMAEhagSSnXWGV915qUMm9mrU=
 golang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
 golang.org/x/sync v0.0.0-20190911185100-cd5d95a43a6e/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
-golang.org/x/sys v0.0.0-20170830134202-bb24a47a89ea/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
 golang.org/x/sys v0.0.0-20180224232135-f6cff0780e54/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
 golang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
 golang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
@@ -704,9 +630,6 @@ golang.org/x/sys v0.0.0-20180909124046-d0be0721c37e/go.mod h1:STP8DvDyc/dI5b8T5h
 golang.org/x/sys v0.0.0-20180926160741-c2ed4eda69e7/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
 golang.org/x/sys v0.0.0-20181107165924-66b7b1311ac8/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
 golang.org/x/sys v0.0.0-20181116152217-5ac8a444bdc5/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
-golang.org/x/sys v0.0.0-20181122145206-62eef0e2fa9b/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
-golang.org/x/sys v0.0.0-20181205085412-a5c9d58dba9a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
-golang.org/x/sys v0.0.0-20190209173611-3b5209105503/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
 golang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
 golang.org/x/sys v0.0.0-20190221075227-b4e8571b14e0/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
 golang.org/x/sys v0.0.0-20190222072716-a9d3bda3a223/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=
@@ -716,88 +639,116 @@ golang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7w
 golang.org/x/sys v0.0.0-20190422165155-953cdadca894 h1:Cz4ceDQGXuKRnVBDTS23GTn/pU5OE2C0WrNTOYK1Uuc=
 golang.org/x/sys v0.0.0-20190422165155-953cdadca894/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20190502145724-3ef323f4f1fd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
-golang.org/x/sys v0.0.0-20190514135907-3a4b5fb9f71f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20190507160741-ecd444e8653b/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20190606165138-5da285871e9c/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20190616124812-15dcb6c0061f h1:25KHgbfyiSm6vwQLbM3zZIe1v9p/3ea4Rz+nnM5K/i4=
 golang.org/x/sys v0.0.0-20190616124812-15dcb6c0061f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20190624142023-c5567b49c5d0/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20190813064441-fde4db37ae7a/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20190826190057-c7b8b68b1456/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20190904154756-749cb33beabd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
-golang.org/x/sys v0.0.0-20190916202348-b4ddaad3f8a3/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
-golang.org/x/sys v0.0.0-20190922100055-0a153f010e69/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20191002063906-3421d5a6bb1c/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20191005200804-aed5e4c7ecf9/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
-golang.org/x/sys v0.0.0-20191022100944-742c48ecaeb7/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20191026070338-33540a1f6037/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20191120155948-bd437916bb0e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20191204072324-ce4227a45e2e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20191228213918-04cbcbbfeed8/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20200106162015-b016eb3dc98e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20200116001909-b77594299b42/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20200202164722-d101bd2416d5/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20200302150141-5c8b2ff67527/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20200323222414-85ca7c5b95cd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/sys v0.0.0-20200519105757-fe76b779f299/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
-golang.org/x/sys v0.0.0-20200812155832-6a926be9bd1d h1:QQrM/CCYEzTs91GZylDCQjGHudbPTxF/1fvXdVh5lMo=
-golang.org/x/sys v0.0.0-20200812155832-6a926be9bd1d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
-golang.org/x/text v0.0.0-20160726164857-2910a502d2bf/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=
+golang.org/x/sys v0.0.0-20200615200032-f1bc736245b1/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20200622214017-ed371f2e16b4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20200930185726-fdedc70b468f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20201112073958-5cba982894dd h1:5CtCZbICpIOFdgO940moixOPjc0178IU44m4EjOO5IY=
+golang.org/x/sys v0.0.0-20201112073958-5cba982894dd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
+golang.org/x/sys v0.0.0-20210108172913-0df2131ae363 h1:wHn06sgWHMO1VsQ8F+KzDJx/JzqfsNLnc+oEi07qD7s=
+golang.org/x/sys v0.0.0-20210108172913-0df2131ae363/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
 golang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=
 golang.org/x/text v0.3.1-0.20180807135948-17ff2d5776d2/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=
 golang.org/x/text v0.3.2 h1:tW2bmiBqwgJj/UpqtC8EpXEZVYOwU0yG4iWbprSVAcs=
 golang.org/x/text v0.3.2/go.mod h1:bEr9sfX3Q8Zfm5fL9x+3itogRgK3+ptLWKqgva+5dAk=
+golang.org/x/text v0.3.3 h1:cokOdA+Jmi5PJGXLlLllQSgYigAEfHXJAERHVMaCc2k=
+golang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=
+golang.org/x/text v0.3.4 h1:0YWbFKbhXG/wIiuHDSKpS0Iy7FSA+u45VtBMfQcFTTc=
+golang.org/x/text v0.3.4/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=
 golang.org/x/time v0.0.0-20180412165947-fbb02b2291d2/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=
 golang.org/x/time v0.0.0-20181108054448-85acf8d2951c/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=
 golang.org/x/time v0.0.0-20190308202827-9d24e82272b4 h1:SvFZT6jyqRaOeXpc5h/JSfZenJ2O330aBsf7JfSUXmQ=
 golang.org/x/time v0.0.0-20190308202827-9d24e82272b4/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=
+golang.org/x/time v0.0.0-20191024005414-555d28b269f0 h1:/5xXl8Y5W96D+TtHSlonuFqGHIWVuyCkGJLwGh9JJFs=
 golang.org/x/time v0.0.0-20191024005414-555d28b269f0/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=
+golang.org/x/time v0.0.0-20200630173020-3af7569d3a1e h1:EHBhcS0mlXEAVwNyO2dLfjToGsyY4j24pTs2ScHnX7s=
+golang.org/x/time v0.0.0-20200630173020-3af7569d3a1e/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=
 golang.org/x/tools v0.0.0-20180221164845-07fd8470d635/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
-golang.org/x/tools v0.0.0-20180525024113-a5b4c53f6e8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
 golang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
 golang.org/x/tools v0.0.0-20181011042414-1f849cf54d09/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
 golang.org/x/tools v0.0.0-20181030221726-6c7e314b6563/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
-golang.org/x/tools v0.0.0-20181117154741-2ddaf7f79a09/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
-golang.org/x/tools v0.0.0-20190110163146-51295c7ec13a/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
 golang.org/x/tools v0.0.0-20190114222345-bf090417da8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
 golang.org/x/tools v0.0.0-20190125232054-d66bd3c5d5a6/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
-golang.org/x/tools v0.0.0-20190206041539-40960b6deb8e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
 golang.org/x/tools v0.0.0-20190226205152-f727befe758c/go.mod h1:9Yl7xja0Znq3iFh3HoIrodX9oNMXvdceNzlUR8zjMvY=
 golang.org/x/tools v0.0.0-20190311212946-11955173bddd/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=
-golang.org/x/tools v0.0.0-20190311215038-5c2858a9cfe5/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=
 golang.org/x/tools v0.0.0-20190312151545-0bb0c0a6e846/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=
 golang.org/x/tools v0.0.0-20190312170243-e65039ee4138/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=
-golang.org/x/tools v0.0.0-20190322203728-c1a832b0ad89/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=
-golang.org/x/tools v0.0.0-20190521203540-521d6ed310dd/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=
+golang.org/x/tools v0.0.0-20190425150028-36563e24a262/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=
+golang.org/x/tools v0.0.0-20190506145303-2d16b83fe98c/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=
 golang.org/x/tools v0.0.0-20190524140312-2c0ae7006135/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=
+golang.org/x/tools v0.0.0-20190606124116-d0a3d012864b/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=
 golang.org/x/tools v0.0.0-20190614205625-5aca471b1d59 h1:QjA/9ArTfVTLfEhClDCG7SGrZkZixxWpwNCDiwJfh88=
 golang.org/x/tools v0.0.0-20190614205625-5aca471b1d59/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=
 golang.org/x/tools v0.0.0-20190617190820-da514acc4774/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=
 golang.org/x/tools v0.0.0-20190621195816-6e04913cbbac/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=
-golang.org/x/tools v0.0.0-20190719005602-e377ae9d6386/go.mod h1:jcCCGcm9btYwXyDqrUWc6MKQKKGJCWEQ3AfLSRIbEuI=
-golang.org/x/tools v0.0.0-20190910044552-dd2b5c81c578/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
-golang.org/x/tools v0.0.0-20190920225731-5eefd052ad72/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
-golang.org/x/tools v0.0.0-20190930201159-7c411dea38b0/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
-golang.org/x/tools v0.0.0-20191010075000-0337d82405ff h1:XdBG6es/oFDr1HwaxkxgVve7NB281QhxgK/i4voubFs=
-golang.org/x/tools v0.0.0-20191010075000-0337d82405ff/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
+golang.org/x/tools v0.0.0-20190624222133-a101b041ded4/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=
+golang.org/x/tools v0.0.0-20190628153133-6cdbf07be9d0/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=
+golang.org/x/tools v0.0.0-20190816200558-6889da9d5479/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
+golang.org/x/tools v0.0.0-20190911174233-4f2ddba30aff/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
+golang.org/x/tools v0.0.0-20191012152004-8de300cfc20a/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
+golang.org/x/tools v0.0.0-20191029041327-9cc4af7d6b2c/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
+golang.org/x/tools v0.0.0-20191029190741-b9c20aec41a5/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
+golang.org/x/tools v0.0.0-20191108193012-7d206e10da11/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
+golang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
+golang.org/x/tools v0.0.0-20191125144606-a911d9008d1f/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
+golang.org/x/tools v0.0.0-20191227053925-7b8e75db28f4/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=
+golang.org/x/tools v0.0.0-20200616133436-c1934b75d054 h1:HHeAlu5H9b71C+Fx0K+1dGgVFN1DM1/wz4aoGOA5qS8=
+golang.org/x/tools v0.0.0-20200616133436-c1934b75d054/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=
 golang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
+golang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
 golang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543 h1:E7g+9GITq07hpfrRu66IVDexMakfv52eLZ2CXBWiKr4=
 golang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
-gomodules.xyz/jsonpatch/v2 v2.0.1 h1:xyiBuvkD2g5n7cYzx6u2sxQvsAy4QJsZFCzGVdzOXZ0=
-gomodules.xyz/jsonpatch/v2 v2.0.1/go.mod h1:IhYNNY4jnS53ZnfE4PAmpKtDpTCj1JFXc+3mwe7XcUU=
-gonum.org/v1/gonum v0.0.0-20190331200053-3d26580ed485/go.mod h1:2ltnJ7xHfj0zHS40VVPYEAAMTa3ZGguvHGBSJeRWqE0=
-gonum.org/v1/netlib v0.0.0-20190313105609-8cb42192e0e0/go.mod h1:wa6Ws7BG/ESfp6dHfk7C6KdzKA7wR7u/rKwOGE66zvw=
-gonum.org/v1/netlib v0.0.0-20190331212654-76723241ea4e/go.mod h1:kS+toOQn6AQKjmKJ7gzohV1XkqsFehRA2FbsbkopSuQ=
+gomodules.xyz/jsonpatch/v2 v2.1.0 h1:Phva6wqu+xR//Njw6iorylFFgn/z547tw5Ne3HZPQ+k=
+gomodules.xyz/jsonpatch/v2 v2.1.0/go.mod h1:IhYNNY4jnS53ZnfE4PAmpKtDpTCj1JFXc+3mwe7XcUU=
 google.golang.org/api v0.4.0/go.mod h1:8k5glujaEP+g9n7WNsDg8QP6cUVNI86fCNMcbazEtwE=
+google.golang.org/api v0.7.0/go.mod h1:WtwebWUNSVBH/HAw79HIFXZNqEvBhG+Ra+ax0hx3E3M=
+google.golang.org/api v0.8.0/go.mod h1:o4eAsZoiT+ibD93RtjEohWalFOjRDx6CVaqeizhEnKg=
+google.golang.org/api v0.9.0/go.mod h1:o4eAsZoiT+ibD93RtjEohWalFOjRDx6CVaqeizhEnKg=
+google.golang.org/api v0.15.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=
 google.golang.org/appengine v1.0.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=
 google.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=
 google.golang.org/appengine v1.3.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=
 google.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=
 google.golang.org/appengine v1.5.0 h1:KxkO13IPW4Lslp2bz+KHP2E3gtFlrIGNThxkZQ3g+4c=
 google.golang.org/appengine v1.5.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=
+google.golang.org/appengine v1.6.1/go.mod h1:i06prIuMbXzDqacNJfV5OdTW448YApPu5ww/cMBSeb0=
+google.golang.org/appengine v1.6.5/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=
+google.golang.org/appengine v1.6.6 h1:lMO5rYAqUxkmaj76jAkRUvt5JZgFymx/+Q5Mzfivuhc=
+google.golang.org/appengine v1.6.6/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=
 google.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=
 google.golang.org/genproto v0.0.0-20190307195333-5fe7a883aa19/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=
 google.golang.org/genproto v0.0.0-20190418145605-e7d98fc518a7/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=
 google.golang.org/genproto v0.0.0-20190425155659-357c62f0e4bb/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=
 google.golang.org/genproto v0.0.0-20190502173448-54afdca5d873/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=
+google.golang.org/genproto v0.0.0-20190801165951-fa694d86fc64/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=
 google.golang.org/genproto v0.0.0-20190819201941-24fa4b261c55/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=
+google.golang.org/genproto v0.0.0-20190911173649-1774047e7e51/go.mod h1:IbNlFCBrqXvoKpeg0TB2l7cyZUmoaFKYIwrEpbDKLA8=
+google.golang.org/genproto v0.0.0-20191230161307-f3c370f40bfb/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=
+google.golang.org/genproto v0.0.0-20200526211855-cb27e3aa2013/go.mod h1:NbSheEEYHJ7i3ixzK3sjbqSGDJWnxyFXZblF3eUsNvo=
 google.golang.org/grpc v1.19.0/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=
 google.golang.org/grpc v1.20.1/go.mod h1:10oTOabMzJvdu6/UiuZezV6QK5dSlG84ov/aaiqXj38=
 google.golang.org/grpc v1.21.0/go.mod h1:oYelfM1adQP15Ek0mdvEgi9Df8B9CZIaU1084ijfRaM=
+google.golang.org/grpc v1.21.1/go.mod h1:oYelfM1adQP15Ek0mdvEgi9Df8B9CZIaU1084ijfRaM=
 google.golang.org/grpc v1.23.0/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=
-google.golang.org/grpc v1.23.1/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=
 google.golang.org/grpc v1.26.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=
 google.golang.org/grpc v1.27.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=
 google.golang.org/protobuf v0.0.0-20200109180630-ec00e32a8dfd/go.mod h1:DFci5gLYBciE7Vtevhsrf46CRTquxDuWsQurQQe4oz8=
@@ -805,9 +756,12 @@ google.golang.org/protobuf v0.0.0-20200221191635-4d8936d0db64/go.mod h1:kwYJMbMJ
 google.golang.org/protobuf v0.0.0-20200228230310-ab0ca4ff8a60/go.mod h1:cfTl7dwQJ+fmap5saPgwCLgHXTUD7jkjRqWcaiX5VyM=
 google.golang.org/protobuf v1.20.1-0.20200309200217-e05f789c0967/go.mod h1:A+miEFZTKqfCUM6K7xSMQL9OKL/b6hQv+e19PK+JZNE=
 google.golang.org/protobuf v1.21.0/go.mod h1:47Nbq4nVaFHyn7ilMalzfO3qCViNmqZ2kzikPIcrTAo=
+google.golang.org/protobuf v1.22.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=
 google.golang.org/protobuf v1.23.0 h1:4MY060fB1DLGMB/7MBTLnwQUY6+F09GEiz6SsrNqyzM=
 google.golang.org/protobuf v1.23.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=
-gopkg.in/airbrake/gobrake.v2 v2.0.9/go.mod h1:/h5ZAUhDkGaJfjzjKLSjv6zCL6O0LLBxU4K+aSYdM/U=
+google.golang.org/protobuf v1.23.1-0.20200526195155-81db48ad09cc/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=
+google.golang.org/protobuf v1.24.0 h1:UhZDfRO8JRQru4/+LlLE0BRKGF8L+PICnvYZmx/fEGA=
+google.golang.org/protobuf v1.24.0/go.mod h1:r/3tXBNzIEhYS9I1OUVjXDlt8tc493IdKGjtUeSXeh4=
 gopkg.in/alecthomas/kingpin.v2 v2.2.6/go.mod h1:FMv+mEhP44yOT+4EoQTLFTRgOQ1FBLkstjWtayDeSgw=
 gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
 gopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127 h1:qIbj1fsPNlZgppZ+VLlY7N33q108Sa+fhmuc+sWQYwY=
@@ -820,7 +774,6 @@ gopkg.in/cheggaaa/pb.v1 v1.0.25/go.mod h1:V/YB90LKu/1FcN3WVnfiiE5oMCibMjukxqG/qS
 gopkg.in/errgo.v2 v2.1.0/go.mod h1:hNsd1EY+bozCKY1Ytp96fpM3vjJbqLJn88ws8XvfDNI=
 gopkg.in/fsnotify.v1 v1.4.7 h1:xOHLXZwVvI9hhs+cLKq5+I5onOuwQLhQwiu63xxlHs4=
 gopkg.in/fsnotify.v1 v1.4.7/go.mod h1:Tz8NjZHkW78fSQdbUxIjBTcgA1z1m8ZHf0WmKUhAMys=
-gopkg.in/gemnasium/logrus-airbrake-hook.v2 v2.1.2/go.mod h1:Xk6kEKp8OKb+X14hQBKWaSkCsqBpgog8nAV2xsGOxlo=
 gopkg.in/inf.v0 v0.9.1 h1:73M5CoZyi3ZLMOyDlQh031Cx6N9NDJ2Vvfl76EDAgDc=
 gopkg.in/inf.v0 v0.9.1/go.mod h1:cWUDdTG/fYaXco+Dcufb5Vnc6Gp2YChqWtbxRZE0mXw=
 gopkg.in/natefinch/lumberjack.v2 v2.0.0/go.mod h1:l0ndWWf7gzL7RNwBG7wST/UCcT4T24xpD6X8LsfU/+k=
@@ -835,93 +788,58 @@ gopkg.in/yaml.v2 v2.2.1/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=
 gopkg.in/yaml.v2 v2.2.2 h1:ZCJp+EgiOT7lHqUV2J862kp8Qj64Jo6az82+3Td9dZw=
 gopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=
 gopkg.in/yaml.v2 v2.2.4/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=
+gopkg.in/yaml.v2 v2.2.5/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=
 gopkg.in/yaml.v2 v2.2.7/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=
 gopkg.in/yaml.v2 v2.2.8 h1:obN1ZagJSUGI0Ek/LBmuj4SNLPfIny3KsKFopxRdj10=
 gopkg.in/yaml.v2 v2.2.8/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=
 gopkg.in/yaml.v2 v2.3.0 h1:clyUAQHOM3G0M3f5vQj7LuJrETvjVot3Z5el9nffUtU=
 gopkg.in/yaml.v2 v2.3.0/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=
-gopkg.in/yaml.v3 v3.0.0-20191120175047-4206685974f2 h1:XZx7nhd5GMaZpmDaEHFVafUZC7ya0fuo7cSJ3UCKYmM=
-gopkg.in/yaml.v3 v3.0.0-20191120175047-4206685974f2/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
+gopkg.in/yaml.v2 v2.4.0 h1:D8xgwECY7CYvx+Y2n4sBz93Jn9JRvxdiyyo8CTfuKaY=
+gopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=
 gopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c h1:dUUwHk2QECo/6vqA44rthZ8ie2QXMNeKRTHCNY2nXvo=
 gopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
+gopkg.in/yaml.v3 v3.0.0-20200615113413-eeeca48fe776 h1:tQIYjPdBoyREyB9XMu+nnTclpTYkz2zFM+lzLJFO4gQ=
+gopkg.in/yaml.v3 v3.0.0-20200615113413-eeeca48fe776/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
 gotest.tools v2.2.0+incompatible/go.mod h1:DsYFclhRJ6vuDpmuTbkuFWG+y2sxOXAzmJt81HFBacw=
-helm.sh/helm/v3 v3.1.2/go.mod h1:WYsFJuMASa/4XUqLyv54s0U/f3mlAaRErGmyy4z921g=
+gotest.tools/v3 v3.0.2/go.mod h1:3SzNCllyD9/Y+b5r9JIKQ474KzkZyqLqEfYqMsX94Bk=
 honnef.co/go/tools v0.0.0-20190102054323-c2f93a96b099/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=
 honnef.co/go/tools v0.0.0-20190106161140-3f1c8253044a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=
+honnef.co/go/tools v0.0.0-20190418001031-e561f6794a2a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=
 honnef.co/go/tools v0.0.0-20190523083050-ea95bdfd59fc/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=
+honnef.co/go/tools v0.0.1-2019.2.3 h1:3JgtbtFHMiCmsznwGVTUWbgGov+pVqnlf1dEJTNAXeM=
 honnef.co/go/tools v0.0.1-2019.2.3/go.mod h1:a3bituU0lyd329TUQxRnasdCoJDkEUEAqEt0JzvZhAg=
-k8s.io/api v0.17.0/go.mod h1:npsyOePkeP0CPwyGfXDHxvypiYMJxBWAMpQxCaJ4ZxI=
-k8s.io/api v0.17.2/go.mod h1:BS9fjjLc4CMuqfSO8vgbHPKMt5+SF0ET6u/RVDihTo4=
-k8s.io/api v0.18.2 h1:wG5g5ZmSVgm5B+eHMIbI9EGATS2L8Z72rda19RIEgY8=
-k8s.io/api v0.18.2/go.mod h1:SJCWI7OLzhZSvbY7U8zwNl9UA4o1fizoug34OV/2r78=
-k8s.io/apiextensions-apiserver v0.17.2/go.mod h1:4KdMpjkEjjDI2pPfBA15OscyNldHWdBCfsWMDWAmSTs=
-k8s.io/apiextensions-apiserver v0.18.2 h1:I4v3/jAuQC+89L3Z7dDgAiN4EOjN6sbm6iBqQwHTah8=
-k8s.io/apiextensions-apiserver v0.18.2/go.mod h1:q3faSnRGmYimiocj6cHQ1I3WpLqmDgJFlKL37fC4ZvY=
-k8s.io/apimachinery v0.17.0/go.mod h1:b9qmWdKlLuU9EBh+06BtLcSf/Mu89rWL33naRxs1uZg=
-k8s.io/apimachinery v0.17.2/go.mod h1:b9qmWdKlLuU9EBh+06BtLcSf/Mu89rWL33naRxs1uZg=
-k8s.io/apimachinery v0.18.2 h1:44CmtbmkzVDAhCpRVSiP2R5PPrC2RtlIv/MoB8xpdRA=
-k8s.io/apimachinery v0.18.2/go.mod h1:9SnR/e11v5IbyPCGbvJViimtJ0SwHG4nfZFjU77ftcA=
-k8s.io/apimachinery v0.18.6 h1:RtFHnfGNfd1N0LeSrKCUznz5xtUP1elRGvHJbL3Ntag=
-k8s.io/apimachinery v0.18.6/go.mod h1:OaXp26zu/5J7p0f92ASynJa1pZo06YlV9fG7BoWbCko=
-k8s.io/apiserver v0.17.2/go.mod h1:lBmw/TtQdtxvrTk0e2cgtOxHizXI+d0mmGQURIHQZlo=
-k8s.io/apiserver v0.18.2/go.mod h1:Xbh066NqrZO8cbsoenCwyDJ1OSi8Ag8I2lezeHxzwzw=
-k8s.io/cli-runtime v0.17.2/go.mod h1:aa8t9ziyQdbkuizkNLAw3qe3srSyWh9zlSB7zTqRNPI=
-k8s.io/client-go v0.17.0/go.mod h1:TYgR6EUHs6k45hb6KWjVD6jFZvJV4gHDikv/It0xz+k=
-k8s.io/client-go v0.17.2/go.mod h1:QAzRgsa0C2xl4/eVpeVAZMvikCn8Nm81yqVx3Kk9XYI=
-k8s.io/client-go v0.18.2 h1:aLB0iaD4nmwh7arT2wIn+lMnAq7OswjaejkQ8p9bBYE=
-k8s.io/client-go v0.18.2/go.mod h1:Xcm5wVGXX9HAA2JJ2sSBUn3tCJ+4SVlCbl2MNNv+CIU=
-k8s.io/code-generator v0.17.2/go.mod h1:DVmfPQgxQENqDIzVR2ddLXMH34qeszkKSdH/N+s+38s=
-k8s.io/code-generator v0.18.2 h1:C1Nn2JiMf244CvBDKVPX0W2mZFJkVBg54T8OV7/Imso=
-k8s.io/code-generator v0.18.2/go.mod h1:+UHX5rSbxmR8kzS+FAv7um6dtYrZokQvjHpDSYRVkTc=
-k8s.io/component-base v0.17.2/go.mod h1:zMPW3g5aH7cHJpKYQ/ZsGMcgbsA/VyhEugF3QT1awLs=
-k8s.io/component-base v0.18.2 h1:SJweNZAGcUvsypLGNPNGeJ9UgPZQ6+bW+gEHe8uyh/Y=
-k8s.io/component-base v0.18.2/go.mod h1:kqLlMuhJNHQ9lz8Z7V5bxUUtjFZnrypArGl58gmDfUM=
-k8s.io/gengo v0.0.0-20190128074634-0689ccc1d7d6/go.mod h1:ezvh/TsK7cY6rbqRK0oQQ8IAqLxYwwyPxAX1Pzy0ii0=
-k8s.io/gengo v0.0.0-20190822140433-26a664648505/go.mod h1:ezvh/TsK7cY6rbqRK0oQQ8IAqLxYwwyPxAX1Pzy0ii0=
-k8s.io/gengo v0.0.0-20200114144118-36b2048a9120 h1:RPscN6KhmG54S33L+lr3GS+oD1jmchIU0ll519K6FA4=
-k8s.io/gengo v0.0.0-20200114144118-36b2048a9120/go.mod h1:ezvh/TsK7cY6rbqRK0oQQ8IAqLxYwwyPxAX1Pzy0ii0=
-k8s.io/klog v0.0.0-20181102134211-b9b56d5dfc92/go.mod h1:Gq+BEi5rUBO/HRz0bTSXDUcqjScdoY3a9IHpCEIOOfk=
-k8s.io/klog v0.3.0/go.mod h1:Gq+BEi5rUBO/HRz0bTSXDUcqjScdoY3a9IHpCEIOOfk=
-k8s.io/klog v1.0.0 h1:Pt+yjF5aB1xDSVbau4VsWe+dQNzA0qv1LlXdC2dF6Q8=
-k8s.io/klog v1.0.0/go.mod h1:4Bi6QPql/J/LkTDqv7R/cd3hPo4k2DG6Ptcz060Ez5I=
-k8s.io/kube-openapi v0.0.0-20191107075043-30be4d16710a/go.mod h1:1TqjTSzOxsLGIKfj0lK8EeCP7K1iUG65v09OM0/WG5E=
-k8s.io/kube-openapi v0.0.0-20200121204235-bf4fb3bd569c h1:/KUFqjjqAcY4Us6luF5RDNZ16KJtb49HfR3ZHB9qYXM=
-k8s.io/kube-openapi v0.0.0-20200121204235-bf4fb3bd569c/go.mod h1:GRQhZsXIAJ1xR0C9bd8UpWHZ5plfAS9fzPjJuQ6JL3E=
-k8s.io/kube-openapi v0.0.0-20200410145947-61e04a5be9a6 h1:Oh3Mzx5pJ+yIumsAD0MOECPVeXsVot0UkiaCGVyfGQY=
-k8s.io/kube-openapi v0.0.0-20200410145947-61e04a5be9a6/go.mod h1:GRQhZsXIAJ1xR0C9bd8UpWHZ5plfAS9fzPjJuQ6JL3E=
-k8s.io/kubectl v0.17.2/go.mod h1:y4rfLV0n6aPmvbRCqZQjvOp3ezxsFgpqL+zF5jH/lxk=
-k8s.io/kubernetes v1.13.0/go.mod h1:ocZa8+6APFNC2tX1DZASIbocyYT5jHzqFVsY5aoB7Jk=
-k8s.io/metrics v0.17.2/go.mod h1:3TkNHET4ROd+NfzNxkjoVfQ0Ob4iZnaHmSEA4vYpwLw=
-k8s.io/utils v0.0.0-20191114184206-e782cd3c129f/go.mod h1:sZAwmy6armz5eXlNoLmJcl4F1QuKu7sr+mFQ0byX7Ew=
-k8s.io/utils v0.0.0-20200324210504-a9aa75ae1b89 h1:d4vVOjXm687F1iLSP2q3lyPPuyvTUt3aVoBpi2DqRsU=
-k8s.io/utils v0.0.0-20200324210504-a9aa75ae1b89/go.mod h1:sZAwmy6armz5eXlNoLmJcl4F1QuKu7sr+mFQ0byX7Ew=
-modernc.org/cc v1.0.0/go.mod h1:1Sk4//wdnYJiUIxnW8ddKpaOJCF37yAdqYnkxUpaYxw=
-modernc.org/golex v1.0.0/go.mod h1:b/QX9oBD/LhixY6NDh+IdGv17hgB+51fET1i2kPSmvk=
-modernc.org/mathutil v1.0.0/go.mod h1:wU0vUrJsVWBZ4P6e7xtFJEhFSNsfRLJ8H458uRjg03k=
-modernc.org/strutil v1.0.0/go.mod h1:lstksw84oURvj9y3tn8lGvRxyRC1S2+g5uuIzNfIOBs=
-modernc.org/xc v1.0.0/go.mod h1:mRNCo0bvLjGhHO9WsyuKVU4q0ceiDDDoEeWDJHrNx8I=
-mvdan.cc/interfacer v0.0.0-20180901003855-c20040233aed/go.mod h1:Xkxe497xwlCKkIaQYRfC7CSLworTXY9RMqwhhCm+8Nc=
-mvdan.cc/lint v0.0.0-20170908181259-adc824a0674b/go.mod h1:2odslEg/xrtNQqCYg2/jCoyKnw3vv5biOc3JnIcYfL4=
-mvdan.cc/unparam v0.0.0-20190720180237-d51796306d8f/go.mod h1:4G1h5nDURzA3bwVMZIVpwbkw+04kSxk3rAtzlimaUJw=
-rsc.io/letsencrypt v0.0.3/go.mod h1:buyQKZ6IXrRnB7TdkHP0RyEybLx18HHyOSoTyoOLqNY=
-sigs.k8s.io/apiserver-network-proxy/konnectivity-client v0.0.7/go.mod h1:PHgbrJT7lCHcxMU+mDHEm+nx46H4zuuHZkDP6icnhu0=
-sigs.k8s.io/controller-runtime v0.5.0/go.mod h1:REiJzC7Y00U+2YkMbT8wxgrsX5USpXKGhb2sCtAXiT8=
-sigs.k8s.io/controller-runtime v0.6.0 h1:Fzna3DY7c4BIP6KwfSlrfnj20DJ+SeMBK8HSFvOk9NM=
-sigs.k8s.io/controller-runtime v0.6.0/go.mod h1:CpYf5pdNY/B352A1TFLAS2JVSlnGQ5O2cftPHndTroo=
-sigs.k8s.io/kustomize v2.0.3+incompatible h1:JUufWFNlI44MdtnjUqVnvh29rR37PQFzPbLXqhyOyX0=
-sigs.k8s.io/kustomize v2.0.3+incompatible/go.mod h1:MkjgH3RdOWrievjo6c9T245dYlB5QeXV4WCbnt/PEpU=
-sigs.k8s.io/kustomize/api v0.4.1/go.mod h1:NqxqT+wbYHrD0P19Uu4dXiMsVwI1IwQs+MJHlLhmPqQ=
-sigs.k8s.io/kustomize/kyaml v0.1.11 h1:/VvWxVIgH5gG1K4A7trgbyLgO3tRBiAWNhLFVU1HEmo=
-sigs.k8s.io/kustomize/kyaml v0.1.11/go.mod h1:72/rLkSi+L/pHM1oCjwrf3ClU+tH5kZQvvdLSqIHwWU=
-sigs.k8s.io/structured-merge-diff v0.0.0-20190525122527-15d366b2352e/go.mod h1:wWxsB5ozmmv/SG7nM11ayaAW51xMvak/t1r0CSlcokI=
-sigs.k8s.io/structured-merge-diff v1.0.1-0.20191108220359-b1b620dd3f06 h1:zD2IemQ4LmOcAumeiyDWXKUI2SO0NYDe3H6QGvPOVgU=
-sigs.k8s.io/structured-merge-diff v1.0.1-0.20191108220359-b1b620dd3f06/go.mod h1:/ULNhyfzRopfcjskuui0cTITekDduZ7ycKN3oUT9R18=
-sigs.k8s.io/structured-merge-diff/v3 v3.0.0-20200116222232-67a7b8c61874/go.mod h1:PlARxl6Hbt/+BC80dRLi1qAmnMqwqDg62YvvVkZjemw=
-sigs.k8s.io/structured-merge-diff/v3 v3.0.0 h1:dOmIZBMfhcHS09XZkMyUgkq5trg3/jRyJYFZUiaOp8E=
-sigs.k8s.io/structured-merge-diff/v3 v3.0.0/go.mod h1:PlARxl6Hbt/+BC80dRLi1qAmnMqwqDg62YvvVkZjemw=
+k8s.io/api v0.19.2 h1:q+/krnHWKsL7OBZg/rxnycsl9569Pud76UJ77MvKXms=
+k8s.io/api v0.19.2/go.mod h1:IQpK0zFQ1xc5iNIQPqzgoOwuFugaYHK4iCknlAQP9nI=
+k8s.io/apiextensions-apiserver v0.19.2 h1:oG84UwiDsVDu7dlsGQs5GySmQHCzMhknfhFExJMz9tA=
+k8s.io/apiextensions-apiserver v0.19.2/go.mod h1:EYNjpqIAvNZe+svXVx9j4uBaVhTB4C94HkY3w058qcg=
+k8s.io/apimachinery v0.19.2/go.mod h1:DnPGDnARWFvYa3pMHgSxtbZb7gpzzAZ1pTfaUNDVlmA=
+k8s.io/apimachinery v0.19.6 h1:kBLzSGuDdY1NdSV2uFzI+FwZ9wtkmG+X3ZVcWXSqNgA=
+k8s.io/apimachinery v0.19.6/go.mod h1:6sRbGRAVY5DOCuZwB5XkqguBqpqLU6q/kOaOdk29z6Q=
+k8s.io/apiserver v0.19.2/go.mod h1:FreAq0bJ2vtZFj9Ago/X0oNGC51GfubKK/ViOKfVAOA=
+k8s.io/client-go v0.19.2 h1:gMJuU3xJZs86L1oQ99R4EViAADUPMHHtS9jFshasHSc=
+k8s.io/client-go v0.19.2/go.mod h1:S5wPhCqyDNAlzM9CnEdgTGV4OqhsW3jGO1UM1epwfJA=
+k8s.io/code-generator v0.19.2/go.mod h1:moqLn7w0t9cMs4+5CQyxnfA/HV8MF6aAVENF+WZZhgk=
+k8s.io/component-base v0.19.2 h1:jW5Y9RcZTb79liEhW3XDVTW7MuvEGP0tQZnfSX6/+gs=
+k8s.io/component-base v0.19.2/go.mod h1:g5LrsiTiabMLZ40AR6Hl45f088DevyGY+cCE2agEIVo=
+k8s.io/gengo v0.0.0-20200413195148-3a45101e95ac/go.mod h1:ezvh/TsK7cY6rbqRK0oQQ8IAqLxYwwyPxAX1Pzy0ii0=
+k8s.io/gengo v0.0.0-20200428234225-8167cfdcfc14/go.mod h1:ezvh/TsK7cY6rbqRK0oQQ8IAqLxYwwyPxAX1Pzy0ii0=
+k8s.io/klog/v2 v2.0.0/go.mod h1:PBfzABfn139FHAV07az/IF9Wp1bkk3vpT2XSJ76fSDE=
+k8s.io/klog/v2 v2.2.0 h1:XRvcwJozkgZ1UQJmfMGpvRthQHOvihEhYtDfAaxMz/A=
+k8s.io/klog/v2 v2.2.0/go.mod h1:Od+F08eJP+W3HUb4pSrPpgp9DGU4GzlpG/TmITuYh/Y=
+k8s.io/kube-openapi v0.0.0-20200805222855-6aeccd4b50c6 h1:+WnxoVtG8TMiudHBSEtrVL1egv36TkkJm+bA8AxicmQ=
+k8s.io/kube-openapi v0.0.0-20200805222855-6aeccd4b50c6/go.mod h1:UuqjUnNftUyPE5H64/qeyjQoUZhGpeFDVdxjTeEVN2o=
+k8s.io/utils v0.0.0-20200729134348-d5654de09c73/go.mod h1:jPW/WVKK9YHAvNhRxK0md/EJ228hCsBRufyofKtW8HA=
+k8s.io/utils v0.0.0-20200912215256-4140de9c8800 h1:9ZNvfPvVIEsp/T1ez4GQuzCcCTEQWhovSofhqR73A6g=
+k8s.io/utils v0.0.0-20200912215256-4140de9c8800/go.mod h1:jPW/WVKK9YHAvNhRxK0md/EJ228hCsBRufyofKtW8HA=
+rsc.io/binaryregexp v0.2.0/go.mod h1:qTv7/COck+e2FymRvadv62gMdZztPaShugOCi3I+8D8=
+sigs.k8s.io/apiserver-network-proxy/konnectivity-client v0.0.9/go.mod h1:dzAXnQbTRyDlZPJX2SUPEqvnB+j7AJjtlox7PEwigU0=
+sigs.k8s.io/controller-runtime v0.7.0 h1:bU20IBBEPccWz5+zXpLnpVsgBYxqclaHu1pVDl/gEt8=
+sigs.k8s.io/controller-runtime v0.7.0/go.mod h1:pJ3YBrJiAqMAZKi6UVGuE98ZrroV1p+pIhoHsMm9wdU=
+sigs.k8s.io/kustomize/kyaml v0.10.5 h1:PbJcsZsEM7O3hHtUWTR+4WkHVbQRW9crSy75or1gRbI=
+sigs.k8s.io/kustomize/kyaml v0.10.5/go.mod h1:P6Oy/ah/GZMKzJMIJA2a3/bc8YrBkuL5kJji13PSIzY=
+sigs.k8s.io/structured-merge-diff/v4 v4.0.1 h1:YXTMot5Qz/X1iBRJhAt+vI+HVttY0WkSqqhKxQ0xVbA=
+sigs.k8s.io/structured-merge-diff/v4 v4.0.1/go.mod h1:bJZC9H9iH24zzfZ/41RGcq60oK1F7G282QMXDPYydCw=
 sigs.k8s.io/yaml v1.1.0 h1:4A07+ZFc2wgJwo8YNlQpr1rVlgUDlxXHhPJciaPY5gs=
 sigs.k8s.io/yaml v1.1.0/go.mod h1:UJmg0vDUVViEyp3mgSv9WPwZCDxu4rQW1olrI1uml+o=
 sigs.k8s.io/yaml v1.2.0 h1:kr/MCeFWJWTwyaHoR9c8EjH9OumOmoF9YGiZd7lFm/Q=
 sigs.k8s.io/yaml v1.2.0/go.mod h1:yfXDCHCao9+ENCvLSE62v9VSji2MKu5jeNfTrofGhJc=
-sourcegraph.com/sqs/pbtypes v0.0.0-20180604144634-d3ebe8f20ae4/go.mod h1:ketZ/q3QxT9HOBeFhu6RdvsftgpsbFHBF5Cas6cDKZ0=
-vbom.ml/util v0.0.0-20160121211510-db5cfe13f5cc/go.mod h1:so/NYdZXCz+E3ZpW0uAoCj6uzU2+8OWDFv/HxUSs7kI=
diff --git a/hack/generate-client.sh b/hack/generate-client.sh
deleted file mode 100755
index b7e5853..0000000
--- a/hack/generate-client.sh
+++ /dev/null
@@ -1,16 +0,0 @@
-#!/bin/bash
-
-SCRIPT_DIR=$( dirname "${BASH_SOURCE[0]}" )
-cd ${SCRIPT_DIR}/..
-
-RESOURCES="Car Motorcycle"
-CLIENT_NAME=SampleInternal
-OUT_DIR=cmd/sample-app/client
-API_DIR="github.com/weaveworks/libgitops/cmd/sample-app/apis/sample"
-mkdir -p ${OUT_DIR}
-for Resource in ${RESOURCES}; do
-    resource=$(echo "${Resource}" | awk '{print tolower($0)}')
-    sed -e "s|Resource|${Resource}|g;s|resource|${resource}|g;/build ignore/d;s|API_DIR|${API_DIR}|g;s|*Client|*${CLIENT_NAME}Client|g" \
-        pkg/client/client_resource_template.go > \
-        ${OUT_DIR}/zz_generated.client_${resource}.go
-done
diff --git a/pkg/client/client_dynamic.go b/pkg/client/client_dynamic.go
deleted file mode 100644
index 5f3ac2a..0000000
--- a/pkg/client/client_dynamic.go
+++ /dev/null
@@ -1,97 +0,0 @@
-// +build ignore
-
-package client
-
-import (
-	"fmt"
-
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/storage"
-	"github.com/weaveworks/libgitops/pkg/storage/filterer"
-	"k8s.io/apimachinery/pkg/runtime/schema"
-)
-
-// DynamicClient is an interface for accessing API types generically
-type DynamicClient interface {
-	// New returns a new Object of its kind
-	New() runtime.Object
-	// Get returns an Object matching the UID from the storage
-	Get(runtime.UID) (runtime.Object, error)
-	// Set saves an Object into the persistent storage
-	Set(runtime.Object) error
-	// Patch performs a strategic merge patch on the object with
-	// the given UID, using the byte-encoded patch given
-	Patch(runtime.UID, []byte) error
-	// Find returns an Object based on the given filter, filters can
-	// match e.g. the Object's Name, UID or a specific property
-	Find(filter filterer.BaseFilter) (runtime.Object, error)
-	// FindAll returns multiple Objects based on the given filter, filters can
-	// match e.g. the Object's Name, UID or a specific property
-	FindAll(filter filterer.BaseFilter) ([]runtime.Object, error)
-	// Delete deletes an Object from the storage
-	Delete(uid runtime.UID) error
-	// List returns a list of all Objects available
-	List() ([]runtime.Object, error)
-}
-
-// dynamicClient is a struct implementing the DynamicClient interface
-// It uses a shared storage instance passed from the Client together with its own Filterer
-type dynamicClient struct {
-	storage  storage.Storage
-	gvk      schema.GroupVersionKind
-	filterer *filterer.Filterer
-}
-
-// NewDynamicClient builds the dynamicClient struct using the storage implementation and a new Filterer
-func NewDynamicClient(s storage.Storage, gvk schema.GroupVersionKind) DynamicClient {
-	return &dynamicClient{
-		storage:  s,
-		gvk:      gvk,
-		filterer: filterer.NewFilterer(s),
-	}
-}
-
-// New returns a new Object of its kind
-func (c *dynamicClient) New() runtime.Object {
-	obj, err := c.storage.New(c.gvk)
-	if err != nil {
-		panic(fmt.Sprintf("Client.New must not return an error: %v", err))
-	}
-	return obj
-}
-
-// Get returns an Object based the given UID
-func (c *dynamicClient) Get(uid runtime.UID) (runtime.Object, error) {
-	return c.storage.Get(c.gvk, uid)
-}
-
-// Set saves an Object into the persistent storage
-func (c *dynamicClient) Set(resource runtime.Object) error {
-	return c.storage.Set(c.gvk, resource)
-}
-
-// Patch performs a strategic merge patch on the object with
-// the given UID, using the byte-encoded patch given
-func (c *dynamicClient) Patch(uid runtime.UID, patch []byte) error {
-	return c.storage.Patch(c.gvk, uid, patch)
-}
-
-// Find returns an Object based on a given Filter
-func (c *dynamicClient) Find(filter filterer.BaseFilter) (runtime.Object, error) {
-	return c.filterer.Find(c.gvk, filter)
-}
-
-// FindAll returns multiple Objects based on a given Filter
-func (c *dynamicClient) FindAll(filter filterer.BaseFilter) ([]runtime.Object, error) {
-	return c.filterer.FindAll(c.gvk, filter)
-}
-
-// Delete deletes the Object from the storage
-func (c *dynamicClient) Delete(uid runtime.UID) error {
-	return c.storage.Delete(c.gvk, uid)
-}
-
-// List returns a list of all Objects available
-func (c *dynamicClient) List() ([]runtime.Object, error) {
-	return c.storage.List(c.gvk)
-}
diff --git a/pkg/client/client_resource_template.go b/pkg/client/client_resource_template.go
deleted file mode 100644
index 53bc874..0000000
--- a/pkg/client/client_resource_template.go
+++ /dev/null
@@ -1,152 +0,0 @@
-// +build ignore
-
-/*
-	Note: This file is autogenerated! Do not edit it manually!
-	Edit client_resource_template.go instead, and run
-	hack/generate-client.sh afterwards.
-*/
-
-package client
-
-import (
-	"fmt"
-
-	api "API_DIR"
-
-	log "github.com/sirupsen/logrus"
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/storage"
-	"github.com/weaveworks/libgitops/pkg/storage/filterer"
-	"k8s.io/apimachinery/pkg/runtime/schema"
-)
-
-// ResourceClient is an interface for accessing Resource-specific API objects
-type ResourceClient interface {
-	// New returns a new Resource
-	New() *api.Resource
-	// Get returns the Resource matching given UID from the storage
-	Get(runtime.UID) (*api.Resource, error)
-	// Set saves the given Resource into persistent storage
-	Set(*api.Resource) error
-	// Patch performs a strategic merge patch on the object with
-	// the given UID, using the byte-encoded patch given
-	Patch(runtime.UID, []byte) error
-	// Find returns the Resource matching the given filter, filters can
-	// match e.g. the Object's Name, UID or a specific property
-	Find(filter filterer.BaseFilter) (*api.Resource, error)
-	// FindAll returns multiple Resources matching the given filter, filters can
-	// match e.g. the Object's Name, UID or a specific property
-	FindAll(filter filterer.BaseFilter) ([]*api.Resource, error)
-	// Delete deletes the Resource with the given UID from the storage
-	Delete(uid runtime.UID) error
-	// List returns a list of all Resources available
-	List() ([]*api.Resource, error)
-}
-
-// Resources returns the ResourceClient for the Client object
-func (c *Client) Resources() ResourceClient {
-	if c.resourceClient == nil {
-		c.resourceClient = newResourceClient(c.storage, c.gv)
-	}
-
-	return c.resourceClient
-}
-
-// resourceClient is a struct implementing the ResourceClient interface
-// It uses a shared storage instance passed from the Client together with its own Filterer
-type resourceClient struct {
-	storage  storage.Storage
-	filterer *filterer.Filterer
-	gvk      schema.GroupVersionKind
-}
-
-// newResourceClient builds the resourceClient struct using the storage implementation and a new Filterer
-func newResourceClient(s storage.Storage, gv schema.GroupVersion) ResourceClient {
-	return &resourceClient{
-		storage:  s,
-		filterer: filterer.NewFilterer(s),
-		gvk:      gv.WithKind(api.KindResource.Title()),
-	}
-}
-
-// New returns a new Object of its kind
-func (c *resourceClient) New() *api.Resource {
-	log.Tracef("Client.New; GVK: %v", c.gvk)
-	obj, err := c.storage.New(c.gvk)
-	if err != nil {
-		panic(fmt.Sprintf("Client.New must not return an error: %v", err))
-	}
-	return obj.(*api.Resource)
-}
-
-// Find returns a single Resource based on the given Filter
-func (c *resourceClient) Find(filter filterer.BaseFilter) (*api.Resource, error) {
-	log.Tracef("Client.Find; GVK: %v", c.gvk)
-	object, err := c.filterer.Find(c.gvk, filter)
-	if err != nil {
-		return nil, err
-	}
-
-	return object.(*api.Resource), nil
-}
-
-// FindAll returns multiple Resources based on the given Filter
-func (c *resourceClient) FindAll(filter filterer.BaseFilter) ([]*api.Resource, error) {
-	log.Tracef("Client.FindAll; GVK: %v", c.gvk)
-	matches, err := c.filterer.FindAll(c.gvk, filter)
-	if err != nil {
-		return nil, err
-	}
-
-	results := make([]*api.Resource, 0, len(matches))
-	for _, item := range matches {
-		results = append(results, item.(*api.Resource))
-	}
-
-	return results, nil
-}
-
-// Get returns the Resource matching given UID from the storage
-func (c *resourceClient) Get(uid runtime.UID) (*api.Resource, error) {
-	log.Tracef("Client.Get; UID: %q, GVK: %v", uid, c.gvk)
-	object, err := c.storage.Get(c.gvk, uid)
-	if err != nil {
-		return nil, err
-	}
-
-	return object.(*api.Resource), nil
-}
-
-// Set saves the given Resource into the persistent storage
-func (c *resourceClient) Set(resource *api.Resource) error {
-	log.Tracef("Client.Set; UID: %q, GVK: %v", resource.GetUID(), c.gvk)
-	return c.storage.Set(c.gvk, resource)
-}
-
-// Patch performs a strategic merge patch on the object with
-// the given UID, using the byte-encoded patch given
-func (c *resourceClient) Patch(uid runtime.UID, patch []byte) error {
-	return c.storage.Patch(c.gvk, uid, patch)
-}
-
-// Delete deletes the Resource from the storage
-func (c *resourceClient) Delete(uid runtime.UID) error {
-	log.Tracef("Client.Delete; UID: %q, GVK: %v", uid, c.gvk)
-	return c.storage.Delete(c.gvk, uid)
-}
-
-// List returns a list of all Resources available
-func (c *resourceClient) List() ([]*api.Resource, error) {
-	log.Tracef("Client.List; GVK: %v", c.gvk)
-	list, err := c.storage.List(c.gvk)
-	if err != nil {
-		return nil, err
-	}
-
-	results := make([]*api.Resource, 0, len(list))
-	for _, item := range list {
-		results = append(results, item.(*api.Resource))
-	}
-
-	return results, nil
-}
diff --git a/pkg/filter/interfaces.go b/pkg/filter/interfaces.go
index 62d3cd3..a097112 100644
--- a/pkg/filter/interfaces.go
+++ b/pkg/filter/interfaces.go
@@ -1,48 +1,20 @@
 package filter
 
-import "github.com/weaveworks/libgitops/pkg/runtime"
+import (
+	"errors"
 
-// ListFilter is an interface for pipe-like list filtering behavior.
-type ListFilter interface {
-	// Filter walks through all objects in obj, assesses whether the object
-	// matches the filter parameters, and conditionally adds it to the return
-	// slice or not. This method can be thought of like an UNIX pipe.
-	Filter(objs ...runtime.Object) ([]runtime.Object, error)
-}
+	"sigs.k8s.io/controller-runtime/pkg/client"
+)
+
+var (
+	// ErrInvalidFilterParams describes an error where invalid parameters were given
+	// to a filter.
+	ErrInvalidFilterParams = errors.New("invalid parameters given to filter")
+)
 
 // ObjectFilter is an interface for filtering objects one-by-one.
 type ObjectFilter interface {
-	// Filter takes in one object (at once, per invocation), and returns a
+	// Match takes in one object (at once, per invocation), and returns a
 	// boolean whether the object matches the filter parameters, or not.
-	Filter(obj runtime.Object) (bool, error)
-}
-
-// ObjectToListFilter transforms an ObjectFilter into a ListFilter. If of is nil,
-// this function panics.
-func ObjectToListFilter(of ObjectFilter) ListFilter {
-	if of == nil {
-		panic("programmer error: of ObjectFilter must not be nil in ObjectToListFilter")
-	}
-	return &objectToListFilter{of}
-}
-
-type objectToListFilter struct {
-	of ObjectFilter
-}
-
-// Filter implements ListFilter, but uses an ObjectFilter for the underlying logic.
-func (f objectToListFilter) Filter(objs ...runtime.Object) (retarr []runtime.Object, err error) {
-	// Walk through all objects
-	for _, obj := range objs {
-		// Match them one-by-one against the ObjectFilter
-		match, err := f.of.Filter(obj)
-		if err != nil {
-			return nil, err
-		}
-		// If the object matches, include it in the return array
-		if match {
-			retarr = append(retarr, obj)
-		}
-	}
-	return
+	Match(obj client.Object) (bool, error)
 }
diff --git a/pkg/filter/labels.go b/pkg/filter/labels.go
new file mode 100644
index 0000000..24ef9f1
--- /dev/null
+++ b/pkg/filter/labels.go
@@ -0,0 +1,46 @@
+package filter
+
+import (
+	"fmt"
+
+	"k8s.io/apimachinery/pkg/labels"
+	"sigs.k8s.io/controller-runtime/pkg/client"
+)
+
+// LabelsFilter implements ObjectFilter and FilterOption.
+// It also implements client.{List,DeleteAllOf}Option so
+// it can be passed into client.Client.{List,DeleteAllOf}
+// as a way to conveniently filter those lists.
+var _ ObjectFilter = LabelsFilter{}
+var _ FilterOption = LabelsFilter{}
+var _ client.ListOption = LabelsFilter{}
+var _ client.DeleteAllOfOption = LabelsFilter{}
+
+// LabelsFilter is an ObjectFilter that compares metav1.Object.GetLabels()
+// to the LabelSelector field.
+type LabelsFilter struct {
+	// LabelSelector filters results by label.  Use SetLabelSelector to
+	// set from raw string form.
+	// +required
+	LabelSelector labels.Selector
+}
+
+// Match implements ObjectFilter
+func (f LabelsFilter) Match(obj client.Object) (bool, error) {
+	// Require f.Namespace to always be set.
+	if f.LabelSelector == nil {
+		return false, fmt.Errorf("the LabelsFilter.LabelSelector field must not be nil: %w", ErrInvalidFilterParams)
+	}
+
+	return f.LabelSelector.Matches(labels.Set(obj.GetLabels())), nil
+}
+
+// ApplyToList implements client.ListOption, but is just a "dummy" implementation in order to implement
+// the interface, so that this struct can be passed to client.Reader.List()
+func (f LabelsFilter) ApplyToList(_ *client.ListOptions)               {}
+func (f LabelsFilter) ApplyToDeleteAllOf(_ *client.DeleteAllOfOptions) {}
+
+// ApplyToFilterOptions implements FilterOption
+func (f LabelsFilter) ApplyToFilterOptions(target *FilterOptions) {
+	target.ObjectFilters = append(target.ObjectFilters, f)
+}
diff --git a/pkg/filter/name.go b/pkg/filter/name.go
index 42e516c..ade3d99 100644
--- a/pkg/filter/name.go
+++ b/pkg/filter/name.go
@@ -4,40 +4,36 @@ import (
 	"fmt"
 	"strings"
 
-	"github.com/weaveworks/libgitops/pkg/runtime"
+	"sigs.k8s.io/controller-runtime/pkg/client"
 )
 
-// NameFilter implements ObjectFilter and ListOption.
+// NameFilter implements ObjectFilter and FilterOption.
+// It also implements client.{List,DeleteAllOf}Option so
+// it can be passed into client.Client.{List,DeleteAllOf}
+// as a way to conveniently filter those lists.
 var _ ObjectFilter = NameFilter{}
-var _ ListOption = NameFilter{}
+var _ FilterOption = NameFilter{}
+var _ client.ListOption = NameFilter{}
+var _ client.DeleteAllOfOption = NameFilter{}
 
-// NameFilter is an ObjectFilter that compares runtime.Object.GetName()
+// NameFilter is an ObjectFilter that compares Object.GetName()
 // to the Name field by either equality or prefix.
 type NameFilter struct {
 	// Name matches the object by .metadata.name.
 	// +required
 	Name string
-	// Namespace matches the object by .metadata.namespace. If left as
-	// an empty string, it is ignored when filtering.
-	// +optional
-	Namespace string
-	// MatchPrefix whether the name (not namespace) matching should be exact, or prefix-based.
+	// MatchPrefix whether the name matching should be exact, or prefix-based.
 	// +optional
 	MatchPrefix bool
 }
 
-// Filter implements ObjectFilter
-func (f NameFilter) Filter(obj runtime.Object) (bool, error) {
+// Match implements ObjectFilter
+func (f NameFilter) Match(obj client.Object) (bool, error) {
 	// Require f.Name to always be set.
 	if len(f.Name) == 0 {
 		return false, fmt.Errorf("the NameFilter.Name field must not be empty: %w", ErrInvalidFilterParams)
 	}
 
-	// If f.Namespace is set, and it does not match the object, return false
-	if len(f.Namespace) > 0 && f.Namespace != obj.GetNamespace() {
-		return false, nil
-	}
-
 	// If the Name should be matched by the prefix, use strings.HasPrefix
 	if f.MatchPrefix {
 		return strings.HasPrefix(obj.GetName(), f.Name), nil
@@ -46,9 +42,12 @@ func (f NameFilter) Filter(obj runtime.Object) (bool, error) {
 	return f.Name == obj.GetName(), nil
 }
 
-// ApplyToListOptions implements ListOption, and adds itself converted to
-// a ListFilter to ListOptions.Filters.
-func (f NameFilter) ApplyToListOptions(target *ListOptions) error {
-	target.Filters = append(target.Filters, ObjectToListFilter(f))
-	return nil
+// ApplyToList implements client.ListOption, but is just a "dummy" implementation in order to implement
+// the interface, so that this struct can be passed to client.Reader.List()
+func (f NameFilter) ApplyToList(_ *client.ListOptions)               {}
+func (f NameFilter) ApplyToDeleteAllOf(_ *client.DeleteAllOfOptions) {}
+
+// ApplyToFilterOptions implements FilterOption
+func (f NameFilter) ApplyToFilterOptions(target *FilterOptions) {
+	target.ObjectFilters = append(target.ObjectFilters, f)
 }
diff --git a/pkg/filter/namespace.go b/pkg/filter/namespace.go
new file mode 100644
index 0000000..ae1c884
--- /dev/null
+++ b/pkg/filter/namespace.go
@@ -0,0 +1,45 @@
+package filter
+
+import (
+	"fmt"
+
+	"sigs.k8s.io/controller-runtime/pkg/client"
+)
+
+// NamespaceFilter implements ObjectFilter and FilterOption.
+// It also implements client.{List,DeleteAllOf}Option so
+// it can be passed into client.Client.{List,DeleteAllOf}
+// as a way to conveniently filter those lists.
+var _ ObjectFilter = NamespaceFilter{}
+var _ FilterOption = NamespaceFilter{}
+var _ client.ListOption = NamespaceFilter{}
+var _ client.DeleteAllOfOption = NamespaceFilter{}
+
+// NamespaceFilter is an ObjectFilter that compares Object.GetNamespace()
+// to the Namespace field.
+type NamespaceFilter struct {
+	// Namespace matches the object by .metadata.namespace. If left as
+	// an empty string, it is ignored when filtering.
+	// +required
+	Namespace string
+}
+
+// Match implements ObjectFilter
+func (f NamespaceFilter) Match(obj client.Object) (bool, error) {
+	// Require f.Namespace to always be set.
+	if len(f.Namespace) == 0 {
+		return false, fmt.Errorf("the NamespaceFilter.Namespace field must not be empty: %w", ErrInvalidFilterParams)
+	}
+	// Otherwise, just use an equality check
+	return f.Namespace == obj.GetNamespace(), nil
+}
+
+// ApplyToList implements client.ListOption, but is just a "dummy" implementation in order to implement
+// the interface, so that this struct can be passed to client.Reader.List()
+func (f NamespaceFilter) ApplyToList(_ *client.ListOptions)               {}
+func (f NamespaceFilter) ApplyToDeleteAllOf(_ *client.DeleteAllOfOptions) {}
+
+// ApplyToFilterOptions implements FilterOption
+func (f NamespaceFilter) ApplyToFilterOptions(target *FilterOptions) {
+	target.ObjectFilters = append(target.ObjectFilters, f)
+}
diff --git a/pkg/filter/options.go b/pkg/filter/options.go
index 4a831dd..6608da3 100644
--- a/pkg/filter/options.go
+++ b/pkg/filter/options.go
@@ -1,27 +1,56 @@
 package filter
 
-// ListOptions is a generic struct for listing options.
-type ListOptions struct {
-	// Filters contains a chain of ListFilters, which will be processed in order and pipe the
-	// available objects through before returning.
-	Filters []ListFilter
+import "sigs.k8s.io/controller-runtime/pkg/client"
+
+// FilterOption is an interface for implementations that know how to
+// mutate FilterOptions.
+type FilterOption interface {
+	// ApplyToFilterOptions applies the configuration of the current object into a target FilterOptions struct.
+	ApplyToFilterOptions(target *FilterOptions)
 }
 
-// ListOption is an interface which can be passed into e.g. List() methods as a variadic-length
-// argument list.
-type ListOption interface {
-	// ApplyToListOptions applies the configuration of the current object into a target ListOptions struct.
-	ApplyToListOptions(target *ListOptions) error
+// FilterOptions is a set of options for filtering. It implements the ObjectFilter interface
+// itself, so it can be used kind of as a multi-ObjectFilter.
+type FilterOptions struct {
+	// ObjectFilters contains a set of filters for a single object. All of the filters must return
+	// true an a nil error for Match(obj) to return (true, nil).
+	ObjectFilters []ObjectFilter
 }
 
-// MakeListOptions makes a completed ListOptions struct from a list of ListOption implementations.
-func MakeListOptions(opts ...ListOption) (*ListOptions, error) {
-	o := &ListOptions{}
-	for _, opt := range opts {
-		// For every option, apply it into o, and check if there's an error
-		if err := opt.ApplyToListOptions(o); err != nil {
-			return nil, err
+// Match matches the object against all the ObjectFilters.
+func (o *FilterOptions) Match(obj client.Object) (bool, error) {
+	for _, filter := range o.ObjectFilters {
+		matched, err := filter.Match(obj)
+		if err != nil {
+			return false, err
+		}
+		if !matched {
+			return false, nil
 		}
 	}
-	return o, nil
+	return true, nil
+}
+
+// ApplyToFilterOptions implements FilterOption
+func (o *FilterOptions) ApplyToFilterOptions(target *FilterOptions) {
+	target.ObjectFilters = append(target.ObjectFilters, o.ObjectFilters...)
+}
+
+// ApplyOptions applies the given FilterOptions to itself and returns itself.
+func (o *FilterOptions) ApplyOptions(opts []FilterOption) *FilterOptions {
+	for _, opt := range opts {
+		opt.ApplyToFilterOptions(o)
+	}
+	return o
+}
+
+// ApplyOption applies one option that aims to implement FilterOption,
+// but at compile-time maybe does not for sure. This can be used for
+// lists of other Options that possibly implement FilterOption in the
+// following way: for _, opt := range opts { filterOpts.ApplyOption(opt) }
+func (o *FilterOptions) ApplyOption(opt interface{}) *FilterOptions {
+	if fOpt, ok := opt.(FilterOption); ok {
+		fOpt.ApplyToFilterOptions(o)
+	}
+	return o
 }
diff --git a/pkg/filter/uid.go b/pkg/filter/uid.go
index eea48ff..1aedab3 100644
--- a/pkg/filter/uid.go
+++ b/pkg/filter/uid.go
@@ -1,25 +1,23 @@
 package filter
 
 import (
-	"errors"
 	"fmt"
 	"strings"
 
-	"github.com/weaveworks/libgitops/pkg/runtime"
 	"k8s.io/apimachinery/pkg/types"
+	"sigs.k8s.io/controller-runtime/pkg/client"
 )
 
-var (
-	// ErrInvalidFilterParams describes an error where invalid parameters were given
-	// to a filter.
-	ErrInvalidFilterParams = errors.New("invalid parameters given to filter")
-)
-
-// UIDFilter implements ObjectFilter and ListOption.
+// UIDFilter implements ObjectFilter and FilterOption.
+// It also implements client.{List,DeleteAllOf}Option so
+// it can be passed into client.Client.{List,DeleteAllOf}
+// as a way to conveniently filter those lists.
 var _ ObjectFilter = UIDFilter{}
-var _ ListOption = UIDFilter{}
+var _ FilterOption = UIDFilter{}
+var _ client.ListOption = UIDFilter{}
+var _ client.DeleteAllOfOption = UIDFilter{}
 
-// UIDFilter is an ObjectFilter that compares runtime.Object.GetUID() to
+// UIDFilter is an ObjectFilter that compares Object.GetUID() to
 // the UID field by either equality or prefix. The UID field is required,
 // otherwise ErrInvalidFilterParams is returned.
 type UIDFilter struct {
@@ -31,8 +29,8 @@ type UIDFilter struct {
 	MatchPrefix bool
 }
 
-// Filter implements ObjectFilter
-func (f UIDFilter) Filter(obj runtime.Object) (bool, error) {
+// Match implements ObjectFilter
+func (f UIDFilter) Match(obj client.Object) (bool, error) {
 	// Require f.UID to always be set.
 	if len(f.UID) == 0 {
 		return false, fmt.Errorf("the UIDFilter.UID field must not be empty: %w", ErrInvalidFilterParams)
@@ -45,9 +43,12 @@ func (f UIDFilter) Filter(obj runtime.Object) (bool, error) {
 	return f.UID == obj.GetUID(), nil
 }
 
-// ApplyToListOptions implements ListOption, and adds itself converted to
-// a ListFilter to ListOptions.Filters.
-func (f UIDFilter) ApplyToListOptions(target *ListOptions) error {
-	target.Filters = append(target.Filters, ObjectToListFilter(f))
-	return nil
+// ApplyToList implements client.ListOption, but is just a "dummy" implementation in order to implement
+// the interface, so that this struct can be passed to client.Reader.List()
+func (f UIDFilter) ApplyToList(_ *client.ListOptions)               {}
+func (f UIDFilter) ApplyToDeleteAllOf(_ *client.DeleteAllOfOptions) {}
+
+// ApplyToFilterOptions implements FilterOption
+func (f UIDFilter) ApplyToFilterOptions(target *FilterOptions) {
+	target.ObjectFilters = append(target.ObjectFilters, f)
 }
diff --git a/pkg/gitdir/gitdir.go b/pkg/gitdir/gitdir.go
deleted file mode 100644
index a9eb0b7..0000000
--- a/pkg/gitdir/gitdir.go
+++ /dev/null
@@ -1,474 +0,0 @@
-package gitdir
-
-import (
-	"context"
-	"errors"
-	"fmt"
-	"io/ioutil"
-	"os"
-	"sync"
-	"time"
-
-	"github.com/fluxcd/go-git-providers/gitprovider"
-	git "github.com/go-git/go-git/v5"
-	"github.com/go-git/go-git/v5/plumbing"
-	"github.com/go-git/go-git/v5/plumbing/object"
-	log "github.com/sirupsen/logrus"
-	"k8s.io/apimachinery/pkg/util/wait"
-)
-
-var (
-	// ErrNotStarted happens if you try to operate on the gitDirectory before you have started
-	// it with StartCheckoutLoop.
-	ErrNotStarted = errors.New("the gitDirectory hasn't been started (and hence, cloned) yet")
-	// ErrCannotWriteToReadOnly happens if you try to do a write operation for a non-authenticated Git repo.
-	ErrCannotWriteToReadOnly = errors.New("the gitDirectory is read-only, cannot write")
-)
-
-const (
-	defaultBranch   = "master"
-	defaultRemote   = "origin"
-	defaultInterval = 30 * time.Second
-	defaultTimeout  = 1 * time.Minute
-)
-
-// GitDirectoryOptions provides options for the gitDirectory.
-// TODO: Refactor this into the controller-runtime Options factory pattern.
-type GitDirectoryOptions struct {
-	// Options
-	Branch   string        // default "master"
-	Interval time.Duration // default 30s
-	Timeout  time.Duration // default 1m
-	// TODO: Support folder prefixes
-
-	// Authentication
-	AuthMethod AuthMethod
-}
-
-func (o *GitDirectoryOptions) Default() {
-	if o.Branch == "" {
-		o.Branch = defaultBranch
-	}
-	if o.Interval == 0 {
-		o.Interval = defaultInterval
-	}
-	if o.Timeout == 0 {
-		o.Timeout = defaultTimeout
-	}
-}
-
-// GitDirectory is an abstraction layer for a temporary Git clone. It pulls
-// and checks out new changes periodically in the background. It also allows
-// high-level access to write operations, like creating a new branch, committing,
-// and pushing.
-type GitDirectory interface {
-	// Dir returns the backing temporary directory of the git clone.
-	Dir() string
-	// MainBranch returns the configured main branch.
-	MainBranch() string
-	// RepositoryRef returns the repository reference.
-	RepositoryRef() gitprovider.RepositoryRef
-
-	// StartCheckoutLoop clones the repo synchronously, and then starts the checkout loop non-blocking.
-	// If the checkout loop has been started already, this is a no-op.
-	StartCheckoutLoop() error
-	// Suspend waits for any pending transactions or operations, and then locks the internal mutex so that
-	// no other operations can start. This means the periodic background checkout loop will momentarily stop.
-	Suspend()
-	// Resume unlocks the mutex locked in Suspend(), so that other Git operations, like the background checkout
-	// loop can resume its operation.
-	Resume()
-
-	// Pull performs a pull & checkout to the latest revision.
-	// ErrNotStarted is returned if the repo hasn't been cloned yet.
-	Pull(ctx context.Context) error
-
-	// CheckoutNewBranch creates a new branch and checks out to it.
-	// ErrNotStarted is returned if the repo hasn't been cloned yet.
-	CheckoutNewBranch(branchName string) error
-	// CheckoutMainBranch goes back to the main branch.
-	// ErrNotStarted is returned if the repo hasn't been cloned yet.
-	CheckoutMainBranch() error
-
-	// Commit creates a commit of all changes in the current worktree with the given parameters.
-	// It also automatically pushes the branch after the commit.
-	// ErrNotStarted is returned if the repo hasn't been cloned yet.
-	// ErrCannotWriteToReadOnly is returned if opts.AuthMethod wasn't provided.
-	Commit(ctx context.Context, authorName, authorEmail, msg string) error
-	// CommitChannel is a channel to where new observed Git SHAs are written.
-	CommitChannel() chan string
-
-	// Cleanup terminates any pending operations, and removes the temporary directory.
-	Cleanup() error
-}
-
-// Create a new GitDirectory implementation. In order to start using this, run StartCheckoutLoop().
-func NewGitDirectory(repoRef gitprovider.RepositoryRef, opts GitDirectoryOptions) (GitDirectory, error) {
-	log.Info("Initializing the Git repo...")
-
-	// Default the options
-	opts.Default()
-
-	// Create a temporary directory for the clone
-	tmpDir, err := ioutil.TempDir("", "libgitops")
-	if err != nil {
-		return nil, err
-	}
-	log.Debugf("Created temporary directory for the git clone at %q", tmpDir)
-
-	d := &gitDirectory{
-		repoRef:             repoRef,
-		GitDirectoryOptions: opts,
-		cloneDir:            tmpDir,
-		// TODO: This needs to be large, otherwise it can start blocking unnecessarily if nobody reads it
-		commitChan: make(chan string, 1024),
-		lock:       &sync.Mutex{},
-	}
-	// Set up the parent context for this class. d.cancel() is called only at Cleanup()
-	d.ctx, d.cancel = context.WithCancel(context.Background())
-
-	log.Trace("URL endpoint parsed and authentication method chosen")
-
-	if d.canWrite() {
-		log.Infof("Running in read-write mode, will commit back current status to the repo")
-	} else {
-		log.Infof("Running in read-only mode, won't write status back to the repo")
-	}
-
-	return d, nil
-}
-
-// gitDirectory is an implementation which keeps a directory
-type gitDirectory struct {
-	// user-specified options
-	repoRef gitprovider.RepositoryRef
-	GitDirectoryOptions
-
-	// the temporary directory used for the clone
-	cloneDir string
-
-	// go-git objects. wt is the worktree of the repo, persistent during the lifetime of repo.
-	repo *git.Repository
-	wt   *git.Worktree
-
-	// latest known commit to the system
-	lastCommit string
-	// events channel from new commits
-	commitChan chan string
-
-	// the context and its cancel function for the lifetime of this struct (until Cleanup())
-	ctx    context.Context
-	cancel context.CancelFunc
-	// the lock for git operations (so pushing and pulling aren't done simultaneously)
-	lock *sync.Mutex
-}
-
-func (d *gitDirectory) Dir() string {
-	return d.cloneDir
-}
-
-func (d *gitDirectory) MainBranch() string {
-	return d.Branch
-}
-
-func (d *gitDirectory) RepositoryRef() gitprovider.RepositoryRef {
-	return d.repoRef
-}
-
-// StartCheckoutLoop clones the repo synchronously, and then starts the checkout loop non-blocking.
-// If the checkout loop has been started already, this is a no-op.
-func (d *gitDirectory) StartCheckoutLoop() error {
-	if d.wt != nil {
-		return nil // already initialized
-	}
-	// First, clone the repo
-	if err := d.clone(); err != nil {
-		return err
-	}
-	go d.checkoutLoop()
-	return nil
-}
-
-func (d *gitDirectory) Suspend() {
-	d.lock.Lock()
-}
-
-func (d *gitDirectory) Resume() {
-	d.lock.Unlock()
-}
-
-func (d *gitDirectory) CommitChannel() chan string {
-	return d.commitChan
-}
-
-func (d *gitDirectory) checkoutLoop() {
-	log.Info("Starting the checkout loop...")
-
-	wait.NonSlidingUntilWithContext(d.ctx, func(_ context.Context) {
-
-		log.Trace("checkoutLoop: Will perform pull operation")
-		// Perform a pull & checkout of the new revision
-		if err := d.Pull(d.ctx); err != nil {
-			log.Errorf("checkoutLoop: git pull failed with error: %v", err)
-			return
-		}
-
-	}, d.Interval)
-	log.Info("Exiting the checkout loop...")
-}
-
-func (d *gitDirectory) cloneURL() string {
-	return d.repoRef.GetCloneURL(d.AuthMethod.TransportType())
-}
-
-func (d *gitDirectory) canWrite() bool {
-	return d.AuthMethod != nil
-}
-
-// verifyRead makes sure it's ok to start a read-something-from-git process
-func (d *gitDirectory) verifyRead() error {
-	// Safeguard against not starting yet
-	if d.wt == nil {
-		return fmt.Errorf("cannot pull: %w", ErrNotStarted)
-	}
-	return nil
-}
-
-// verifyWrite makes sure it's ok to start a write-something-to-git process
-func (d *gitDirectory) verifyWrite() error {
-	// We need all read privileges first
-	if err := d.verifyRead(); err != nil {
-		return err
-	}
-	// Make sure we don't write to a possibly read-only repo
-	if !d.canWrite() {
-		return ErrCannotWriteToReadOnly
-	}
-	return nil
-}
-
-func (d *gitDirectory) clone() error {
-	// Lock the mutex now that we're starting, and unlock it when exiting
-	d.lock.Lock()
-	defer d.lock.Unlock()
-
-	log.Infof("Starting to clone the repository %s with timeout %s", d.repoRef, d.Timeout)
-	// Do a clone operation to the temporary directory, with a timeout
-	err := d.contextWithTimeout(d.ctx, func(ctx context.Context) error {
-		var err error
-		d.repo, err = git.PlainCloneContext(ctx, d.Dir(), false, &git.CloneOptions{
-			URL:           d.cloneURL(),
-			Auth:          d.AuthMethod,
-			RemoteName:    defaultRemote,
-			ReferenceName: plumbing.NewBranchReferenceName(d.Branch),
-			SingleBranch:  true,
-			NoCheckout:    false,
-			//Depth:             1, // ref: https://github.com/src-d/go-git/issues/1143
-			RecurseSubmodules: 0,
-			Progress:          nil,
-			Tags:              git.NoTags,
-		})
-		return err
-	})
-	// Handle errors
-	switch err {
-	case nil:
-		// no-op, just continue.
-	case context.DeadlineExceeded:
-		return fmt.Errorf("git clone operation took longer than deadline %s", d.Timeout)
-	case context.Canceled:
-		log.Tracef("context was cancelled")
-		return nil // if Cleanup() was called, just exit the goroutine
-	default:
-		return fmt.Errorf("git clone error: %v", err)
-	}
-
-	// Populate the worktree pointer
-	d.wt, err = d.repo.Worktree()
-	if err != nil {
-		return fmt.Errorf("git get worktree error: %v", err)
-	}
-
-	// Get the latest HEAD commit and report it to the user
-	ref, err := d.repo.Head()
-	if err != nil {
-		return err
-	}
-
-	d.observeCommit(ref.Hash())
-	return nil
-}
-
-func (d *gitDirectory) Pull(ctx context.Context) error {
-	// Lock the mutex now that we're starting, and unlock it when exiting
-	d.lock.Lock()
-	defer d.lock.Unlock()
-
-	// Make sure it's okay to read
-	if err := d.verifyRead(); err != nil {
-		return err
-	}
-
-	// Perform the git pull operation using the timeout
-	err := d.contextWithTimeout(ctx, func(innerCtx context.Context) error {
-		log.Trace("checkoutLoop: Starting pull operation")
-		return d.wt.PullContext(innerCtx, &git.PullOptions{
-			Auth:         d.AuthMethod,
-			SingleBranch: true,
-		})
-	})
-	// Handle errors
-	switch err {
-	case nil, git.NoErrAlreadyUpToDate:
-		// no-op, just continue. Allow the git.NoErrAlreadyUpToDate error
-	case context.DeadlineExceeded:
-		return fmt.Errorf("git pull operation took longer than deadline %s", d.Timeout)
-	case context.Canceled:
-		log.Tracef("context was cancelled")
-		return nil // if Cleanup() was called, just exit the goroutine
-	default:
-		return fmt.Errorf("failed to pull: %v", err)
-	}
-
-	log.Trace("checkoutLoop: Pulled successfully")
-
-	// get current head
-	ref, err := d.repo.Head()
-	if err != nil {
-		return err
-	}
-
-	// check if we changed commits
-	if d.lastCommit != ref.Hash().String() {
-		// Notify upstream that we now have a new commit, and allow writing again
-		d.observeCommit(ref.Hash())
-	}
-
-	return nil
-}
-
-func (d *gitDirectory) CheckoutNewBranch(branchName string) error {
-	// Make sure it's okay to write
-	if err := d.verifyWrite(); err != nil {
-		return err
-	}
-
-	return d.wt.Checkout(&git.CheckoutOptions{
-		Branch: plumbing.NewBranchReferenceName(branchName),
-		Create: true,
-	})
-}
-
-func (d *gitDirectory) CheckoutMainBranch() error {
-	// Make sure it's okay to write
-	if err := d.verifyWrite(); err != nil {
-		return err
-	}
-
-	// Best-effort clean
-	_ = d.wt.Clean(&git.CleanOptions{
-		Dir: true,
-	})
-	// Force-checkout the main branch
-	return d.wt.Checkout(&git.CheckoutOptions{
-		Branch: plumbing.NewBranchReferenceName(d.Branch),
-		Force:  true,
-	})
-}
-
-// observeCommit sets the lastCommit variable so that we know the latest state
-func (d *gitDirectory) observeCommit(commit plumbing.Hash) {
-	d.lastCommit = commit.String()
-	d.commitChan <- commit.String()
-	log.Infof("New commit observed on branch %q: %s", d.Branch, commit)
-}
-
-// Commit creates a commit of all changes in the current worktree with the given parameters.
-// It also automatically pushes the branch after the commit.
-// ErrNotStarted is returned if the repo hasn't been cloned yet.
-// ErrCannotWriteToReadOnly is returned if opts.AuthMethod wasn't provided.
-func (d *gitDirectory) Commit(ctx context.Context, authorName, authorEmail, msg string) error {
-	// Make sure it's okay to write
-	if err := d.verifyWrite(); err != nil {
-		return err
-	}
-
-	s, err := d.wt.Status()
-	if err != nil {
-		return fmt.Errorf("git status failed: %v", err)
-	}
-	if s.IsClean() {
-		log.Debugf("No changed files in git repo, nothing to commit...")
-		return nil
-	}
-
-	// Do a commit and push
-	log.Debug("commitLoop: Committing all local changes")
-	hash, err := d.wt.Commit(msg, &git.CommitOptions{
-		All: true,
-		Author: &object.Signature{
-			Name:  authorName,
-			Email: authorEmail,
-			When:  time.Now(),
-		},
-	})
-	if err != nil {
-		return fmt.Errorf("git commit error: %v", err)
-	}
-
-	// Perform the git push operation using the timeout
-	err = d.contextWithTimeout(ctx, func(innerCtx context.Context) error {
-		log.Debug("commitLoop: Will push with timeout")
-		return d.repo.PushContext(innerCtx, &git.PushOptions{
-			Auth: d.AuthMethod,
-		})
-	})
-	// Handle errors
-	switch err {
-	case nil, git.NoErrAlreadyUpToDate:
-		// no-op, just continue. Allow the git.NoErrAlreadyUpToDate error
-	case context.DeadlineExceeded:
-		return fmt.Errorf("git push operation took longer than deadline %s", d.Timeout)
-	case context.Canceled:
-		log.Tracef("context was cancelled")
-		return nil // if Cleanup() was called, just exit the goroutine
-	default:
-		return fmt.Errorf("failed to push: %v", err)
-	}
-
-	// Notify upstream that we now have a new commit, and allow writing again
-	log.Infof("A new commit with the actual state has been created and pushed to the origin: %q", hash)
-	d.observeCommit(hash)
-	return nil
-}
-
-func (d *gitDirectory) contextWithTimeout(ctx context.Context, fn func(context.Context) error) error {
-	// Create a new context with a timeout. The push operation either succeeds in time, times out,
-	// or is cancelled by Cleanup(). In case of a successful run, the context is always cancelled afterwards.
-	ctx, cancel := context.WithTimeout(ctx, d.Timeout)
-	defer cancel()
-
-	// Run the function using the context and cancel directly afterwards
-	fnErr := fn(ctx)
-
-	// Return the context error, if any, first so deadline/cancel signals can propagate.
-	// Otherwise passthrough the error returned from the function.
-	if ctx.Err() != nil {
-		log.Debugf("operation context yielded error %v to be returned. Function error was: %v", ctx.Err(), fnErr)
-		return ctx.Err()
-	}
-	return fnErr
-}
-
-// Cleanup cancels running goroutines and operations, and removes the temporary clone directory
-func (d *gitDirectory) Cleanup() error {
-	// Cancel the context for the two running goroutines, and any possible long-running operations
-	d.cancel()
-
-	// Remove the temporary directory
-	if err := os.RemoveAll(d.Dir()); err != nil {
-		log.Errorf("Failed to clean up temp git directory: %v", err)
-		return err
-	}
-	return nil
-}
diff --git a/pkg/runtime/doc.go b/pkg/runtime/doc.go
deleted file mode 100644
index 4eb2a1e..0000000
--- a/pkg/runtime/doc.go
+++ /dev/null
@@ -1,2 +0,0 @@
-// +k8s:deepcopy-gen=package
-package runtime
diff --git a/pkg/runtime/identifiers.go b/pkg/runtime/identifiers.go
deleted file mode 100644
index 87bc00e..0000000
--- a/pkg/runtime/identifiers.go
+++ /dev/null
@@ -1,63 +0,0 @@
-package runtime
-
-import (
-	"fmt"
-
-	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
-)
-
-// DefaultNamespace describes the default namespace name used for the system.
-const DefaultNamespace = "default"
-
-// Identifyable is an object which can be identified
-type Identifyable interface {
-	// GetIdentifier can return e.g. a "namespace/name" combination, which is not guaranteed
-	// to be unique world-wide, or alternatively a random SHA for instance
-	GetIdentifier() string
-}
-
-type identifier string
-
-func (i identifier) GetIdentifier() string { return string(i) }
-
-type Metav1NameIdentifierFactory struct{}
-
-func (id Metav1NameIdentifierFactory) Identify(o interface{}) (Identifyable, bool) {
-	switch obj := o.(type) {
-	case metav1.Object:
-		if len(obj.GetNamespace()) == 0 || len(obj.GetName()) == 0 {
-			return nil, false
-		}
-		return NewIdentifier(fmt.Sprintf("%s/%s", obj.GetNamespace(), obj.GetName())), true
-	}
-	return nil, false
-}
-
-type ObjectUIDIdentifierFactory struct{}
-
-func (id ObjectUIDIdentifierFactory) Identify(o interface{}) (Identifyable, bool) {
-	switch obj := o.(type) {
-	case Object:
-		if len(obj.GetUID()) == 0 {
-			return nil, false
-		}
-		// TODO: Make sure that runtime.APIType works with this
-		return NewIdentifier(string(obj.GetUID())), true
-	}
-	return nil, false
-}
-
-var (
-	// Metav1Identifier identifies an object using its metav1.ObjectMeta Name and Namespace
-	Metav1NameIdentifier IdentifierFactory = Metav1NameIdentifierFactory{}
-	// ObjectUIDIdentifier identifies an object using its libgitops/pkg/runtime.ObjectMeta UID field
-	ObjectUIDIdentifier IdentifierFactory = ObjectUIDIdentifierFactory{}
-)
-
-func NewIdentifier(str string) Identifyable {
-	return identifier(str)
-}
-
-type IdentifierFactory interface {
-	Identify(o interface{}) (id Identifyable, ok bool)
-}
diff --git a/pkg/runtime/meta.go b/pkg/runtime/meta.go
deleted file mode 100644
index 32930e1..0000000
--- a/pkg/runtime/meta.go
+++ /dev/null
@@ -1,52 +0,0 @@
-package runtime
-
-import (
-	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
-	"k8s.io/apimachinery/pkg/runtime"
-	"sigs.k8s.io/yaml"
-)
-
-// PartialObjectImpl is a struct implementing PartialObject, used for
-// unmarshalling unknown objects into this intermediate type
-// where .Name, .UID, .Kind and .APIVersion become easily available
-// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
-type PartialObjectImpl struct {
-	metav1.TypeMeta   `json:",inline"`
-	metav1.ObjectMeta `json:"metadata"`
-}
-
-func (po *PartialObjectImpl) IsPartialObject() {}
-
-// This constructor ensures the PartialObjectImpl fields are not nil.
-// TODO: Make this multi-document-aware?
-func NewPartialObject(frame []byte) (PartialObject, error) {
-	obj := &PartialObjectImpl{}
-
-	// The yaml package supports both YAML and JSON. Don't use the serializer, as the APIType
-	// wrapper is not registered in any scheme.
-	if err := yaml.Unmarshal(frame, obj); err != nil {
-		return nil, err
-	}
-
-	return obj, nil
-}
-
-var _ Object = &PartialObjectImpl{}
-var _ PartialObject = &PartialObjectImpl{}
-
-// Object is an union of the Object interfaces that are accessible for a
-// type that embeds both metav1.TypeMeta and metav1.ObjectMeta.
-type Object interface {
-	runtime.Object
-	metav1.ObjectMetaAccessor
-	metav1.Object
-}
-
-// PartialObject is a partially-decoded object, where only metadata has been loaded.
-type PartialObject interface {
-	Object
-
-	// IsPartialObject is a dummy function for signalling that this is a partially-loaded object
-	// i.e. only TypeMeta and ObjectMeta are stored in memory.
-	IsPartialObject()
-}
diff --git a/pkg/runtime/zz_generated.deepcopy.go b/pkg/runtime/zz_generated.deepcopy.go
deleted file mode 100644
index 20beb72..0000000
--- a/pkg/runtime/zz_generated.deepcopy.go
+++ /dev/null
@@ -1,67 +0,0 @@
-// +build !ignore_autogenerated
-
-// Code generated by deepcopy-gen. DO NOT EDIT.
-
-package runtime
-
-import (
-	pkgruntime "k8s.io/apimachinery/pkg/runtime"
-)
-
-// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
-func (in *Metav1NameIdentifierFactory) DeepCopyInto(out *Metav1NameIdentifierFactory) {
-	*out = *in
-	return
-}
-
-// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new Metav1NameIdentifierFactory.
-func (in *Metav1NameIdentifierFactory) DeepCopy() *Metav1NameIdentifierFactory {
-	if in == nil {
-		return nil
-	}
-	out := new(Metav1NameIdentifierFactory)
-	in.DeepCopyInto(out)
-	return out
-}
-
-// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
-func (in *ObjectUIDIdentifierFactory) DeepCopyInto(out *ObjectUIDIdentifierFactory) {
-	*out = *in
-	return
-}
-
-// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ObjectUIDIdentifierFactory.
-func (in *ObjectUIDIdentifierFactory) DeepCopy() *ObjectUIDIdentifierFactory {
-	if in == nil {
-		return nil
-	}
-	out := new(ObjectUIDIdentifierFactory)
-	in.DeepCopyInto(out)
-	return out
-}
-
-// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
-func (in *PartialObjectImpl) DeepCopyInto(out *PartialObjectImpl) {
-	*out = *in
-	out.TypeMeta = in.TypeMeta
-	in.ObjectMeta.DeepCopyInto(&out.ObjectMeta)
-	return
-}
-
-// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PartialObjectImpl.
-func (in *PartialObjectImpl) DeepCopy() *PartialObjectImpl {
-	if in == nil {
-		return nil
-	}
-	out := new(PartialObjectImpl)
-	in.DeepCopyInto(out)
-	return out
-}
-
-// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new pkgruntime.Object.
-func (in *PartialObjectImpl) DeepCopyObject() pkgruntime.Object {
-	if c := in.DeepCopy(); c != nil {
-		return c
-	}
-	return nil
-}
diff --git a/pkg/serializer/comments.go b/pkg/serializer/comments.go
index 302c4db..a016939 100644
--- a/pkg/serializer/comments.go
+++ b/pkg/serializer/comments.go
@@ -27,7 +27,7 @@ var (
 func (d *decoder) tryToPreserveComments(doc []byte, obj runtime.Object, ct ContentType) {
 	// If the user opted into preserving comments and the format is YAML, proceed
 	// If they didn't, return directly
-	if !(*d.opts.PreserveComments && ct == ContentTypeYAML) {
+	if !(d.opts.PreserveComments == PreserveCommentsStrict && ct == ContentTypeYAML) {
 		return
 	}
 
@@ -41,7 +41,7 @@ func (d *decoder) tryToPreserveComments(doc []byte, obj runtime.Object, ct Conte
 // tryToPreserveComments tries to locate the possibly-saved original file data in the object's annotation
 func (e *encoder) encodeWithCommentSupport(versionEncoder runtime.Encoder, fw FrameWriter, obj runtime.Object, metaObj metav1.Object) error {
 	// If the user did not opt into preserving comments, just sanitize ObjectMeta temporarily and and return
-	if !*e.opts.PreserveComments {
+	if e.opts.PreserveComments == PreserveCommentsDisable {
 		// Normal encoding without the annotation (so it doesn't leak by accident)
 		return noAnnotationWrapper(metaObj, e.normalEncodeFunc(versionEncoder, fw, obj))
 	}
diff --git a/pkg/serializer/comments_test.go b/pkg/serializer/comments_test.go
index 8f4c65c..6332e5c 100644
--- a/pkg/serializer/comments_test.go
+++ b/pkg/serializer/comments_test.go
@@ -18,8 +18,8 @@ kind: Test
 spec:
   # Head comment
   data:
-  - field # Inline comment
-  - another
+    - field # Inline comment
+    - another
   thing:
     # Head comment
     var: true
@@ -29,9 +29,9 @@ const sampleData2 = `kind: Test
 spec:
   # Head comment
   data:
-  - field # Inline comment
-  - another:
-      subthing: "yes"
+    - field # Inline comment
+    - another:
+        subthing: "yes"
   thing:
     # Head comment
     var: true
diff --git a/pkg/serializer/convertor.go b/pkg/serializer/convertor.go
index bdea096..3fbc814 100644
--- a/pkg/serializer/convertor.go
+++ b/pkg/serializer/convertor.go
@@ -169,7 +169,8 @@ func (c *objectConvertor) ConvertToVersion(in runtime.Object, groupVersioner run
 	// as before, using the scheme's ConvertToVersion function. But if we don't want to convert the newly-decoded
 	// external object, we can just do nothing and the object will stay unconverted.
 	// doConversion is always true in the Encode codepath.
-	if !c.doConversion {
+	// Also, never convert unknown, partial metadata or unstructured objects (defined as "non-convertible").
+	if !c.doConversion || IsNonConvertible(in) {
 		// DeepCopy the object to make sure that although in would be somehow modified, it doesn't affect out
 		return in.DeepCopyObject(), nil
 	}
diff --git a/pkg/serializer/decode.go b/pkg/serializer/decode.go
index 4feff21..7aee5af 100644
--- a/pkg/serializer/decode.go
+++ b/pkg/serializer/decode.go
@@ -5,119 +5,38 @@ import (
 	"io"
 	"reflect"
 
-	"github.com/weaveworks/libgitops/pkg/util"
 	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
 	"k8s.io/apimachinery/pkg/runtime"
 	"k8s.io/apimachinery/pkg/runtime/schema"
 	"k8s.io/apimachinery/pkg/runtime/serializer/json"
 	"k8s.io/apimachinery/pkg/runtime/serializer/versioning"
-	"sigs.k8s.io/yaml"
+	serializeryaml "k8s.io/apimachinery/pkg/runtime/serializer/yaml"
 )
 
 // This is the groupversionkind for the v1.List object
 var listGVK = metav1.Unversioned.WithKind("List")
 
-type DecodingOptions struct {
-	// Not applicable for Decoder.DecodeInto(). If true, the decoded external object
-	// will be converted into its hub (or internal, where applicable) representation. Otherwise, the decoded
-	// object will be left in its external representation. (Default: false)
-	ConvertToHub *bool
-
-	// Parse the YAML/JSON in strict mode, returning a specific error if the input
-	// contains duplicate or unknown fields or formatting errors. (Default: true)
-	Strict *bool
-
-	// Automatically default the decoded object. (Default: false)
-	Default *bool
-
-	// Only applicable for Decoder.DecodeAll(). If the underlying data contains a v1.List,
-	// the items of the list will be traversed, decoded into their respective types, and
-	// appended to the returned slice. The v1.List will in this case not be returned.
-	// This conversion does NOT support preserving comments. If the given scheme doesn't
-	// recognize the v1.List, before using it will be registered automatically. (Default: true)
-	DecodeListElements *bool
-
-	// Whether to preserve YAML comments internally. This only works for objects embedding metav1.ObjectMeta.
-	// Only applicable to ContentTypeYAML framers.
-	// Using any other framer will be silently ignored. Usage of this option also requires setting
-	// the PreserveComments in EncodingOptions, too. (Default: false)
-	PreserveComments *bool
-
-	// DecodeUnknown specifies whether decode objects with an unknown GroupVersionKind into a
-	// *runtime.Unknown object when running Decode(All) (true value) or to return an error when
-	// any unrecognized type is found (false value). (Default: false)
-	DecodeUnknown *bool
-}
-
-type DecodingOptionsFunc func(*DecodingOptions)
-
-func WithConvertToHubDecode(convert bool) DecodingOptionsFunc {
-	return func(opts *DecodingOptions) {
-		opts.ConvertToHub = &convert
-	}
-}
-
-func WithStrictDecode(strict bool) DecodingOptionsFunc {
-	return func(opts *DecodingOptions) {
-		opts.Strict = &strict
-	}
-}
-
-func WithDefaultsDecode(defaults bool) DecodingOptionsFunc {
-	return func(opts *DecodingOptions) {
-		opts.Default = &defaults
-	}
-}
-
-func WithListElementsDecoding(listElements bool) DecodingOptionsFunc {
-	return func(opts *DecodingOptions) {
-		opts.DecodeListElements = &listElements
-	}
-}
+// TODO: To think about: should we take in the DecodeOptions at Decode time instead
+// as a variadic-sized Option slice? It would probably take caching the *json.Serializer
+// and runtime.Decoder for the given options they use, though.
 
-func WithCommentsDecode(comments bool) DecodingOptionsFunc {
-	return func(opts *DecodingOptions) {
-		opts.PreserveComments = &comments
-	}
-}
-
-func WithUnknownDecode(unknown bool) DecodingOptionsFunc {
-	return func(opts *DecodingOptions) {
-		opts.DecodeUnknown = &unknown
-	}
-}
-
-func WithDecodingOptions(newOpts DecodingOptions) DecodingOptionsFunc {
-	return func(opts *DecodingOptions) {
-		// TODO: Null-check all of these before using them
-		*opts = newOpts
-	}
-}
+func newDecoder(schemeAndCodec *schemeAndCodec, opts DecodeOptions) Decoder {
+	// Allow both YAML and JSON inputs (JSON is a subset of YAML), and deserialize in strict mode
+	s := json.NewSerializerWithOptions(json.DefaultMetaFactory, schemeAndCodec.scheme, schemeAndCodec.scheme, json.SerializerOptions{
+		Yaml:   true,
+		Strict: *opts.Strict,
+	})
 
-func defaultDecodeOpts() *DecodingOptions {
-	return &DecodingOptions{
-		ConvertToHub:       util.BoolPtr(false),
-		Strict:             util.BoolPtr(true),
-		Default:            util.BoolPtr(false),
-		DecodeListElements: util.BoolPtr(true),
-		PreserveComments:   util.BoolPtr(false),
-		DecodeUnknown:      util.BoolPtr(false),
-	}
-}
+	decodeCodec := decoderForVersion(schemeAndCodec.scheme, s, *opts.Default, *opts.ConvertToHub)
 
-func newDecodeOpts(fns ...DecodingOptionsFunc) *DecodingOptions {
-	opts := defaultDecodeOpts()
-	for _, fn := range fns {
-		fn(opts)
-	}
-	return opts
+	return &decoder{schemeAndCodec, decodeCodec, opts}
 }
 
 type decoder struct {
 	*schemeAndCodec
 
 	decoder runtime.Decoder
-	opts    DecodingOptions
+	opts    DecodeOptions
 }
 
 // Decode returns the decoded object from the next document in the FrameReader stream.
@@ -149,8 +68,14 @@ func (d *decoder) Decode(fr FrameReader) (runtime.Object, error) {
 func (d *decoder) decode(doc []byte, into runtime.Object, ct ContentType) (runtime.Object, error) {
 	// If the scheme doesn't recognize a v1.List, and we enabled opts.DecodeListElements,
 	// make the scheme able to decode the v1.List automatically
-	if *d.opts.DecodeListElements && !d.scheme.Recognizes(listGVK) {
-		d.scheme.AddKnownTypes(metav1.Unversioned, &metav1.List{})
+	if *d.opts.DecodeListElements {
+		// As .AddKnownTypes is writing to the scheme, make sure we guard the check and the write with a
+		// mutex.
+		d.schemeMu.Lock()
+		if !d.scheme.Recognizes(listGVK) {
+			d.scheme.AddKnownTypes(metav1.Unversioned, &metav1.List{})
+		}
+		d.schemeMu.Unlock()
 	}
 
 	// Record if this decode call should have runtime.DecodeInto-functionality
@@ -268,7 +193,7 @@ func (d *decoder) decodeUnknown(doc []byte, ct ContentType) (runtime.Object, err
 
 func (d *decoder) handleDecodeError(doc []byte, origErr error) error {
 	// Parse the document's TypeMeta information
-	gvk, err := extractYAMLTypeMeta(doc)
+	gvk, err := serializeryaml.DefaultMetaFactory.Interpret(doc)
 	if err != nil {
 		return fmt.Errorf("failed to interpret TypeMeta from the given the YAML: %v. Decode error was: %w", err, origErr)
 	}
@@ -320,18 +245,6 @@ func (d *decoder) extractNestedObjects(obj runtime.Object, ct ContentType) ([]ru
 	return objs, nil
 }
 
-func newDecoder(schemeAndCodec *schemeAndCodec, opts DecodingOptions) Decoder {
-	// Allow both YAML and JSON inputs (JSON is a subset of YAML), and deserialize in strict mode
-	s := json.NewSerializerWithOptions(json.DefaultMetaFactory, schemeAndCodec.scheme, schemeAndCodec.scheme, json.SerializerOptions{
-		Yaml:   true,
-		Strict: *opts.Strict,
-	})
-
-	decodeCodec := decoderForVersion(schemeAndCodec.scheme, s, *opts.Default, *opts.ConvertToHub)
-
-	return &decoder{schemeAndCodec, decodeCodec, opts}
-}
-
 // decoderForVersion is used instead of CodecFactory.DecoderForVersion, as we want to use our own converter
 func decoderForVersion(scheme *runtime.Scheme, decoder *json.Serializer, doDefaulting, doConversion bool) runtime.Decoder {
 	return newConversionCodecForScheme(
@@ -361,20 +274,38 @@ func newConversionCodecForScheme(
 		defaulter = scheme
 	}
 	convertor := newObjectConvertor(scheme, performConversion)
-	return versioning.NewCodec(encoder, decoder, convertor, scheme, scheme, defaulter, encodeVersion, decodeVersion, scheme.Name())
+	// a typer that recognizes metav1.PartialObjectMetadata{,List}
+	typer := &customTyper{scheme}
+	return versioning.NewCodec(encoder, decoder, convertor, scheme, typer, defaulter, encodeVersion, decodeVersion, scheme.Name())
 }
 
-// TODO: Use https://github.com/kubernetes/apimachinery/blob/master/pkg/runtime/serializer/yaml/meta.go
-// when we can assume everyone is vendoring k8s v1.19
-func extractYAMLTypeMeta(data []byte) (*schema.GroupVersionKind, error) {
-	typeMeta := runtime.TypeMeta{}
-	if err := yaml.Unmarshal(data, &typeMeta); err != nil {
-		return nil, fmt.Errorf("could not interpret GroupVersionKind: %w", err)
-	}
-	gv, err := schema.ParseGroupVersion(typeMeta.APIVersion)
-	if err != nil {
-		return nil, err
+var _ runtime.ObjectTyper = &customTyper{}
+
+type customTyper struct {
+	scheme *runtime.Scheme
+}
+
+// ObjectKinds is an extension to the native Scheme.ObjectKinds function, that also
+// recognizes partial matadata objects and lists. The logic here follows closely the
+// scheme's own logic.
+func (t *customTyper) ObjectKinds(obj runtime.Object) ([]schema.GroupVersionKind, bool, error) {
+	// partial objects are always fine to encode/decode as-is when GVK is set.
+	// this similar code exists in runtime.Scheme.ObjectKinds for reference.
+	if IsPartialObject(obj) || IsPartialObjectList(obj) {
+		// we require that the GVK be populated in order to recognize the object
+		gvk := obj.GetObjectKind().GroupVersionKind()
+		if len(gvk.Kind) == 0 {
+			return nil, false, runtime.NewMissingKindErr("unstructured object has no kind")
+		}
+		if len(gvk.Version) == 0 {
+			return nil, false, runtime.NewMissingVersionErr("unstructured object has no version")
+		}
+		return []schema.GroupVersionKind{gvk}, false, nil
 	}
-	gvk := gv.WithKind(typeMeta.Kind)
-	return &gvk, nil
+	return t.scheme.ObjectKinds(obj)
+}
+
+// Recognizes just calls the underlying Scheme.Recognizes
+func (t *customTyper) Recognizes(gvk schema.GroupVersionKind) bool {
+	return t.scheme.Recognizes(gvk)
 }
diff --git a/pkg/serializer/encode.go b/pkg/serializer/encode.go
index 7706193..a06bd8c 100644
--- a/pkg/serializer/encode.go
+++ b/pkg/serializer/encode.go
@@ -1,73 +1,25 @@
 package serializer
 
 import (
-	"github.com/sirupsen/logrus"
-	"github.com/weaveworks/libgitops/pkg/util"
+	"bytes"
+	"encoding/json"
+	"strings"
+
 	"k8s.io/apimachinery/pkg/runtime"
 	"k8s.io/apimachinery/pkg/runtime/schema"
 )
 
-type EncodingOptions struct {
-	// Use pretty printing when writing to the output. (Default: true)
-	// TODO: Fix that sometimes omitempty fields aren't respected
-	Pretty *bool
-	// Whether to preserve YAML comments internally. This only works for objects embedding metav1.ObjectMeta.
-	// Only applicable to ContentTypeYAML framers.
-	// Using any other framer will be silently ignored. Usage of this option also requires setting
-	// the PreserveComments in DecodingOptions, too. (Default: false)
-	// TODO: Make this a BestEffort & Strict mode
-	PreserveComments *bool
-
-	// TODO: Maybe consider an option to always convert to the preferred version (not just internal)
-}
-
-type EncodingOptionsFunc func(*EncodingOptions)
-
-func WithPrettyEncode(pretty bool) EncodingOptionsFunc {
-	return func(opts *EncodingOptions) {
-		opts.Pretty = &pretty
-	}
-}
-
-func WithCommentsEncode(comments bool) EncodingOptionsFunc {
-	return func(opts *EncodingOptions) {
-		opts.PreserveComments = &comments
-	}
-}
-
-func WithEncodingOptions(newOpts EncodingOptions) EncodingOptionsFunc {
-	return func(opts *EncodingOptions) {
-		// TODO: Null-check all of these before using them
-		*opts = newOpts
-	}
-}
-
-func defaultEncodeOpts() *EncodingOptions {
-	return &EncodingOptions{
-		Pretty:           util.BoolPtr(true),
-		PreserveComments: util.BoolPtr(false),
-	}
-}
-
-func newEncodeOpts(fns ...EncodingOptionsFunc) *EncodingOptions {
-	opts := defaultEncodeOpts()
-	for _, fn := range fns {
-		fn(opts)
+func newEncoder(schemeAndCodec *schemeAndCodec, opts EncodeOptions) Encoder {
+	return &encoder{
+		schemeAndCodec,
+		opts,
 	}
-	return opts
 }
 
 type encoder struct {
 	*schemeAndCodec
 
-	opts EncodingOptions
-}
-
-func newEncoder(schemeAndCodec *schemeAndCodec, opts EncodingOptions) Encoder {
-	return &encoder{
-		schemeAndCodec,
-		opts,
-	}
+	opts EncodeOptions
 }
 
 // Encode encodes the given objects and writes them to the specified FrameWriter.
@@ -75,6 +27,7 @@ func newEncoder(schemeAndCodec *schemeAndCodec, opts EncodingOptions) Encoder {
 // internal object given to the preferred external groupversion. No conversion will happen
 // if the given object is of an external version.
 // TODO: This should automatically convert to the preferred version
+// TODO: Fix that sometimes omitempty fields aren't respected
 func (e *encoder) Encode(fw FrameWriter, objs ...runtime.Object) error {
 	for _, obj := range objs {
 		// Get the kind for the given object
@@ -110,23 +63,23 @@ func (e *encoder) EncodeForGroupVersion(fw FrameWriter, obj runtime.Object, gv s
 		return ErrUnsupportedContentType
 	}
 
-	// Choose the pretty or non-pretty one
+	// Choose the default, non-pretty serializer, as we prettify if needed later
+	// We technically could use the JSON PrettySerializer here, but it does not catch the
+	// cases where the JSON iterator invokes MarshalJSON() on an object, and that object
+	// returns non-pretty bytes (e.g. *unstructured.Unstructured). Hence, it is more robust
+	// and extensible to always use the non-pretty serializer, and only on request indent
+	// a given number of spaces after JSON encoding.
 	encoder := serializerInfo.Serializer
 
-	// Use the pretty serializer if it was asked for and is defined for the content type
-	if *e.opts.Pretty {
-		// Apparently not all SerializerInfos have this field defined (e.g. YAML)
-		// TODO: This could be considered a bug in upstream, create an issue
-		if serializerInfo.PrettySerializer != nil {
-			encoder = serializerInfo.PrettySerializer
-		} else {
-			logrus.Debugf("PrettySerializer for ContentType %s is nil, falling back to Serializer.", fw.ContentType())
-		}
-	}
-
 	// Get a version-specific encoder for the specified groupversion
 	versionEncoder := encoderForVersion(e.scheme, encoder, gv)
 
+	// Check if the user requested prettified JSON output.
+	// If the ContentType is JSON this is ok, we will intent the encode output on the fly.
+	if *e.opts.JSONIndent > 0 && fw.ContentType() == ContentTypeJSON {
+		fw = &jsonPrettyFrameWriter{indent: *e.opts.JSONIndent, fw: fw}
+	}
+
 	// Cast the object to a metav1.Object to get access to annotations
 	metaobj, ok := toMetaObject(obj)
 	// For objects without ObjectMeta, the cast will fail. Allow that failure and do "normal" encoding
@@ -150,3 +103,24 @@ func encoderForVersion(scheme *runtime.Scheme, encoder runtime.Encoder, gv schem
 		true,    // convert if needed before encode
 	)
 }
+
+type jsonPrettyFrameWriter struct {
+	indent int
+	fw     FrameWriter
+}
+
+func (w *jsonPrettyFrameWriter) Write(p []byte) (n int, err error) {
+	// Indent the source bytes
+	var indented bytes.Buffer
+	err = json.Indent(&indented, p, "", strings.Repeat(" ", w.indent))
+	if err != nil {
+		return
+	}
+	// Write the pretty bytes to the underlying writer
+	n, err = w.fw.Write(indented.Bytes())
+	return
+}
+
+func (w *jsonPrettyFrameWriter) ContentType() ContentType {
+	return w.fw.ContentType()
+}
diff --git a/pkg/serializer/frame_reader.go b/pkg/serializer/frame_reader.go
index 26ead8d..a2ba308 100644
--- a/pkg/serializer/frame_reader.go
+++ b/pkg/serializer/frame_reader.go
@@ -6,6 +6,7 @@ import (
 	"io"
 	"io/ioutil"
 	"os"
+	"sync"
 
 	"k8s.io/apimachinery/pkg/runtime/serializer/json"
 )
@@ -71,6 +72,7 @@ func NewJSONFrameReader(rc ReadCloser) FrameReader {
 func newFrameReader(rc io.ReadCloser, contentType ContentType) *frameReader {
 	return &frameReader{
 		rc:           rc,
+		rcMu:         &sync.Mutex{},
 		bufSize:      defaultBufSize,
 		maxFrameSize: defaultMaxFrameSize,
 		contentType:  contentType,
@@ -79,12 +81,13 @@ func newFrameReader(rc io.ReadCloser, contentType ContentType) *frameReader {
 
 // frameReader is a FrameReader implementation
 type frameReader struct {
-	rc           io.ReadCloser
+	// the underlying readcloser and the mutex that guards it
+	rc   io.ReadCloser
+	rcMu *sync.Mutex
+
 	bufSize      int
 	maxFrameSize int
 	contentType  ContentType
-
-	// TODO: Maybe add mutexes for thread-safety (so no two goroutines read at the same time)
 }
 
 // ReadFrame reads one frame from the underlying io.Reader. ReadFrame
@@ -93,6 +96,10 @@ type frameReader struct {
 // ReadFrame keeps on reading using new calls. ReadFrame might return both data and
 // io.EOF. io.EOF will be returned in the final call.
 func (rf *frameReader) ReadFrame() (frame []byte, err error) {
+	// Only one actor can read at a time
+	rf.rcMu.Lock()
+	defer rf.rcMu.Unlock()
+
 	// Temporary buffer to parts of a frame into
 	var buf []byte
 	// How many bytes were read by the read call
@@ -149,6 +156,10 @@ func (rf *frameReader) ContentType() ContentType {
 
 // Close implements io.Closer and closes the underlying ReadCloser
 func (rf *frameReader) Close() error {
+	// Only one actor can access rf.rc at a time
+	rf.rcMu.Lock()
+	defer rf.rcMu.Unlock()
+
 	return rf.rc.Close()
 }
 
@@ -166,3 +177,42 @@ func FromFile(filePath string) ReadCloser {
 func FromBytes(content []byte) ReadCloser {
 	return ioutil.NopCloser(bytes.NewReader(content))
 }
+
+// NewSingleFrameReader returns a FrameReader for only a single frame of
+// the specified content type. This avoids overhead if it is known that the
+// byte array only contains one frame. The given frame is returned in
+// whole in the first ReadFrame() call, and io.EOF is returned in all future
+// invocations. This FrameReader works for any ContentType and transparently
+// exposes what was given through the ContentType() method.
+func NewSingleFrameReader(b []byte, ct ContentType) FrameReader {
+	return &singleFrameReader{
+		ct:            ct,
+		b:             b,
+		hasBeenRead:   false,
+		hasBeenReadMu: &sync.Mutex{},
+	}
+}
+
+var _ FrameReader = &singleFrameReader{}
+
+type singleFrameReader struct {
+	ct            ContentType
+	b             []byte
+	hasBeenRead   bool
+	hasBeenReadMu *sync.Mutex
+}
+
+func (r *singleFrameReader) ReadFrame() ([]byte, error) {
+	r.hasBeenReadMu.Lock()
+	defer r.hasBeenReadMu.Unlock()
+	// If ReadFrame() has been called once, just return io.EOF.
+	if r.hasBeenRead {
+		return nil, io.EOF
+	}
+	// The first time, mark that we've read, and return the single frame
+	r.hasBeenRead = true
+	return r.b, nil
+}
+
+func (r *singleFrameReader) ContentType() ContentType { return r.ct }
+func (r *singleFrameReader) Close() error             { return nil }
diff --git a/pkg/serializer/frame_reader_test.go b/pkg/serializer/frame_reader_test.go
index a696ed7..063ed8a 100644
--- a/pkg/serializer/frame_reader_test.go
+++ b/pkg/serializer/frame_reader_test.go
@@ -5,6 +5,7 @@ import (
 	"io/ioutil"
 	"reflect"
 	"strings"
+	"sync"
 	"testing"
 
 	"k8s.io/apimachinery/pkg/runtime/serializer/json"
@@ -92,6 +93,7 @@ func Test_FrameReader_ReadFrame(t *testing.T) {
 		t.Run(tt.name, func(t *testing.T) {
 			rf := &frameReader{
 				rc:           tt.fields.rc,
+				rcMu:         &sync.Mutex{},
 				bufSize:      tt.fields.bufSize,
 				maxFrameSize: tt.fields.maxFrameSize,
 			}
diff --git a/pkg/serializer/options.go b/pkg/serializer/options.go
new file mode 100644
index 0000000..e5736e6
--- /dev/null
+++ b/pkg/serializer/options.go
@@ -0,0 +1,258 @@
+package serializer
+
+import (
+	"k8s.io/utils/pointer"
+)
+
+// TODO: Import k8s.io/utils/pointer instead of baking our own ptrutils package.
+
+type EncodeOption interface {
+	ApplyToEncode(*EncodeOptions)
+}
+
+func defaultEncodeOpts() *EncodeOptions {
+	return &EncodeOptions{
+		// Default to "pretty encoding"
+		JSONIndent:       pointer.Int32Ptr(2),
+		PreserveComments: PreserveCommentsDisable,
+	}
+}
+
+type EncodeOptions struct {
+	// Indent JSON encoding output with this many spaces.
+	// Set this to 0, use PrettyEncode(false) or JSONIndent(0) to disable pretty output.
+	// Only applicable to ContentTypeJSON framers.
+	//
+	// Default: 2, i.e. pretty output
+	// TODO: Make this a property of the FrameWriter instead?
+	JSONIndent *int32
+
+	// Whether to preserve YAML comments internally.
+	// This only works for objects embedding metav1.ObjectMeta.
+	//
+	// Only applicable to ContentTypeYAML framers. Using any other framer will be silently ignored.
+	//
+	// Usage of this option also requires setting the PreserveComments in DecodeOptions, too.
+	//
+	// Default: PreserveCommentsDisable
+	PreserveComments PreserveComments
+
+	// TODO: Maybe consider an option to always convert to the preferred version (not just internal)
+}
+
+var _ EncodeOption = &EncodeOptions{}
+
+func (o *EncodeOptions) ApplyToEncode(target *EncodeOptions) {
+	if o.JSONIndent != nil {
+		target.JSONIndent = o.JSONIndent
+	}
+	if o.PreserveComments != 0 {
+		target.PreserveComments = o.PreserveComments
+	}
+}
+
+func (o *EncodeOptions) ApplyOptions(opts []EncodeOption) *EncodeOptions {
+	for _, opt := range opts {
+		opt.ApplyToEncode(o)
+	}
+	// it is guaranteed that all options are non-nil, as defaultEncodeOpts() includes all fields
+	return o
+}
+
+// Whether to preserve YAML comments internally.
+// This only works for objects embedding metav1.ObjectMeta.
+//
+// Only applicable to ContentTypeYAML framers. Using any other framer will be silently ignored.
+// TODO: Add a BestEffort mode
+type PreserveComments int
+
+const (
+	// PreserveCommentsDisable means do not try to preserve comments
+	PreserveCommentsDisable PreserveComments = 1 + iota
+	// PreserveCommentsStrict means try to preserve comments, and fail if it does not work
+	PreserveCommentsStrict
+)
+
+var _ EncodeOption = PreserveComments(0)
+var _ DecodeOption = PreserveComments(0)
+
+func (p PreserveComments) ApplyToEncode(target *EncodeOptions) {
+	// TODO: Validate?
+	target.PreserveComments = p
+}
+
+func (p PreserveComments) ApplyToDecode(target *DecodeOptions) {
+	// TODO: Validate?
+	target.PreserveComments = p
+}
+
+// Indent JSON encoding output with this many spaces.
+// Use PrettyEncode(false) or JSONIndent(0) to disable pretty output.
+// Only applicable to ContentTypeJSON framers.
+type JSONIndent int32
+
+var _ EncodeOption = JSONIndent(0)
+
+func (i JSONIndent) ApplyToEncode(target *EncodeOptions) {
+	target.JSONIndent = pointer.Int32Ptr(int32(i))
+}
+
+// Shorthand for JSONIndent(0) if false, or JSONIndent(2) if true
+type PrettyEncode bool
+
+var _ EncodeOption = PrettyEncode(false)
+
+func (pretty PrettyEncode) ApplyToEncode(target *EncodeOptions) {
+	if pretty {
+		JSONIndent(2).ApplyToEncode(target)
+	} else {
+		JSONIndent(0).ApplyToEncode(target)
+	}
+}
+
+// DECODING
+
+type DecodeOption interface {
+	ApplyToDecode(*DecodeOptions)
+}
+
+func defaultDecodeOpts() *DecodeOptions {
+	return &DecodeOptions{
+		ConvertToHub:       pointer.BoolPtr(false),
+		Strict:             pointer.BoolPtr(true),
+		Default:            pointer.BoolPtr(false),
+		DecodeListElements: pointer.BoolPtr(true),
+		PreserveComments:   PreserveCommentsDisable,
+		DecodeUnknown:      pointer.BoolPtr(false),
+	}
+}
+
+type DecodeOptions struct {
+	// Not applicable for Decoder.DecodeInto(). If true, the decoded external object
+	// will be converted into its hub (or internal, where applicable) representation.
+	// Otherwise, the decoded object will be left in its external representation.
+	//
+	// Default: false
+	ConvertToHub *bool
+
+	// Parse the YAML/JSON in strict mode, returning a specific error if the input
+	// contains duplicate or unknown fields or formatting errors.
+	//
+	// Default: true
+	Strict *bool
+
+	// Automatically default the decoded object.
+	// Default: false
+	Default *bool
+
+	// Only applicable for Decoder.DecodeAll(). If the underlying data contains a v1.List,
+	// the items of the list will be traversed, decoded into their respective types, and
+	// appended to the returned slice. The v1.List will in this case not be returned.
+	// This conversion does NOT support preserving comments. If the given scheme doesn't
+	// recognize the v1.List, before using it will be registered automatically.
+	//
+	// Default: true
+	DecodeListElements *bool
+
+	// Whether to preserve YAML comments internally.
+	// This only works for objects embedding metav1.ObjectMeta.
+	//
+	// Only applicable to ContentTypeYAML framers. Using any other framer will be silently ignored.
+	//
+	// Usage of this option also requires setting the PreserveComments in EncodeOptions, too.
+	//
+	// Default: PreserveCommentsDisable
+	PreserveComments PreserveComments
+
+	// DecodeUnknown specifies whether decode objects with an unknown GroupVersionKind into a
+	// *runtime.Unknown object when running Decode(All) (true value) or to return an error when
+	// any unrecognized type is found (false value).
+	//
+	// Default: false
+	DecodeUnknown *bool
+}
+
+var _ DecodeOption = &DecodeOptions{}
+
+func (o *DecodeOptions) ApplyToDecode(target *DecodeOptions) {
+	if o.ConvertToHub != nil {
+		target.ConvertToHub = o.ConvertToHub
+	}
+	if o.Strict != nil {
+		target.Strict = o.Strict
+	}
+	if o.Default != nil {
+		target.Default = o.Default
+	}
+	if o.DecodeListElements != nil {
+		target.DecodeListElements = o.DecodeListElements
+	}
+	if o.PreserveComments != 0 {
+		target.PreserveComments = o.PreserveComments
+	}
+	if o.DecodeUnknown != nil {
+		target.DecodeUnknown = o.DecodeUnknown
+	}
+}
+
+func (o *DecodeOptions) ApplyOptions(opts []DecodeOption) *DecodeOptions {
+	for _, opt := range opts {
+		opt.ApplyToDecode(o)
+	}
+	// it is guaranteed that all options are non-nil, as defaultDecodeOpts() includes all fields
+	return o
+}
+
+// Not applicable for Decoder.DecodeInto(). If true, the decoded external object
+// will be converted into its hub (or internal, where applicable) representation.
+// Otherwise, the decoded object will be left in its external representation.
+type ConvertToHub bool
+
+var _ DecodeOption = ConvertToHub(false)
+
+func (b ConvertToHub) ApplyToDecode(target *DecodeOptions) {
+	target.ConvertToHub = pointer.BoolPtr(bool(b))
+}
+
+// Parse the YAML/JSON in strict mode, returning a specific error if the input
+// contains duplicate or unknown fields or formatting errors.
+type DecodeStrict bool
+
+var _ DecodeOption = DecodeStrict(false)
+
+func (b DecodeStrict) ApplyToDecode(target *DecodeOptions) {
+	target.Strict = pointer.BoolPtr(bool(b))
+}
+
+// Automatically default the decoded object.
+type DefaultAtDecode bool
+
+var _ DecodeOption = DefaultAtDecode(false)
+
+func (b DefaultAtDecode) ApplyToDecode(target *DecodeOptions) {
+	target.Default = pointer.BoolPtr(bool(b))
+}
+
+// Only applicable for Decoder.DecodeAll(). If the underlying data contains a v1.List,
+// the items of the list will be traversed, decoded into their respective types, and
+// appended to the returned slice. The v1.List will in this case not be returned.
+// This conversion does NOT support preserving comments. If the given scheme doesn't
+// recognize the v1.List, before using it will be registered automatically.
+type DecodeListElements bool
+
+var _ DecodeOption = DecodeListElements(false)
+
+func (b DecodeListElements) ApplyToDecode(target *DecodeOptions) {
+	target.DecodeListElements = pointer.BoolPtr(bool(b))
+}
+
+// DecodeUnknown specifies whether decode objects with an unknown GroupVersionKind into a
+// *runtime.Unknown object when running Decode(All) (true value) or to return an error when
+// any unrecognized type is found (false value).
+type DecodeUnknown bool
+
+var _ DecodeOption = DecodeUnknown(false)
+
+func (b DecodeUnknown) ApplyToDecode(target *DecodeOptions) {
+	target.DecodeUnknown = pointer.BoolPtr(bool(b))
+}
diff --git a/pkg/serializer/patch.go b/pkg/serializer/patch.go
new file mode 100644
index 0000000..bd580e0
--- /dev/null
+++ b/pkg/serializer/patch.go
@@ -0,0 +1,124 @@
+package serializer
+
+import (
+	"bytes"
+	"encoding/json"
+	"errors"
+
+	"github.com/weaveworks/libgitops/pkg/util/patch"
+	"k8s.io/apimachinery/pkg/runtime"
+	"k8s.io/apimachinery/pkg/util/strategicpatch"
+	openapi "k8s.io/kube-openapi/pkg/util/proto"
+)
+
+// TODO: Move pkg/util/patch under pkg/serializer?
+
+type Patcher interface {
+	// ApplyOnStruct applies the given patch (JSON-encoded) using the given BytePatcher
+	// (that knows how to operate on that kind of patch type) into obj.
+	//
+	// obj MUST be a typed object. Unversioned, partial or unstructured objects are not
+	// supported. For those use-cases, convert your object into an unstructured one, and
+	// pass it to ApplyOnUnstructured.
+	//
+	// obj MUST NOT be an internal type. If you operate on an internal object as your "hub",
+	// convert the object yourself first to the GroupVersion of the patch bytes, and then
+	// convert back after this call.
+	//
+	// In case the patch would require knowledge about the schema (e.g. StrategicMergePatch),
+	// this function looks that metadata up using reflection of obj.
+	ApplyOnStruct(bytePatcher patch.BytePatcher, patch []byte, obj runtime.Object) error
+
+	// ApplyOnUnstructured applies the given patch (JSON-encoded) using the given BytePatcher
+	// (that knows how to operate on that kind of patch type) into the unstructured obj.
+	//
+	// If knowledge about the schema is required by the patch type (e.g. StrategicMergePatch),
+	// it is the liability of the caller to provide an OpenAPI schema.
+	ApplyOnUnstructured(bytePatcher patch.BytePatcher, patch []byte, obj runtime.Unstructured, schema openapi.Schema) error
+}
+
+type patcher struct {
+	*schemeAndCodec
+}
+
+// ApplyOnStruct applies the given patch (JSON-encoded) using the given BytePatcher
+// (that knows how to operate on that kind of patch type) into obj.
+//
+// obj MUST be a typed object. Unversioned, partial or unstructured objects are not
+// supported. For those use-cases, convert your object into an unstructured one, and
+// pass it to ApplyOnUnstructured.
+//
+// obj MUST NOT be an internal type. If you operate on an internal object as your "hub",
+// convert the object yourself first to the GroupVersion of the patch bytes, and then
+// convert back after this call.
+//
+// In case the patch would require knowledge about the schema (e.g. StrategicMergePatch),
+// this function looks that metadata up using reflection of obj.
+func (p *patcher) ApplyOnStruct(bytePatcher patch.BytePatcher, patch []byte, obj runtime.Object) error {
+	// Require that obj is typed
+	if !IsTyped(obj, p.scheme) {
+		return errors.New("obj must be typed")
+	}
+	// Get the GVK so we can check if obj is internal
+	gvk, err := GVKForObject(p.scheme, obj)
+	if err != nil {
+		return err
+	}
+	// It must not be internal, as we will encode it soon.
+	if gvk.Version == runtime.APIVersionInternal {
+		return errors.New("obj must not be internal")
+	}
+
+	// Create a non-pretty encoder
+	encopt := *defaultEncodeOpts().ApplyOptions([]EncodeOption{PrettyEncode(false)})
+	enc := newEncoder(p.schemeAndCodec, encopt)
+	// Encode without conversion to the buffer
+	var buf bytes.Buffer
+	if err := enc.EncodeForGroupVersion(NewJSONFrameWriter(&buf), obj, gvk.GroupVersion()); err != nil {
+		return err
+	}
+
+	// Get the schema in case needed by the BytePatcher
+	schema, err := strategicpatch.NewPatchMetaFromStruct(obj)
+	if err != nil {
+		return err
+	}
+
+	// Apply the patch, and get the new JSON out
+	newJSON, err := bytePatcher.Apply(buf.Bytes(), patch, schema)
+	if err != nil {
+		return err
+	}
+
+	// Decode into the object to apply the changes
+	fr := NewSingleFrameReader(newJSON, ContentTypeJSON)
+	dec := newDecoder(p.schemeAndCodec, *defaultDecodeOpts())
+	if err := dec.DecodeInto(fr, obj); err != nil {
+		return err
+	}
+
+	return nil
+}
+
+func (p *patcher) ApplyOnUnstructured(bytePatcher patch.BytePatcher, patch []byte, obj runtime.Unstructured, schema openapi.Schema) error {
+	// Marshal the object to form the source JSON
+	sourceJSON, err := json.Marshal(obj)
+	if err != nil {
+		return err
+	}
+
+	// Conditionally get the schema from the provided OpenAPI spec
+	var patchMeta strategicpatch.LookupPatchMeta
+	if schema != nil {
+		patchMeta = strategicpatch.NewPatchMetaFromOpenAPI(schema)
+	}
+
+	// Apply the patch, and get the new JSON out
+	newJSON, err := bytePatcher.Apply(sourceJSON, patch, patchMeta)
+	if err != nil {
+		return err
+	}
+
+	// Decode back into obj
+	return json.Unmarshal(newJSON, obj)
+}
diff --git a/pkg/serializer/serializer.go b/pkg/serializer/serializer.go
index eb798c9..fbbcdd1 100644
--- a/pkg/serializer/serializer.go
+++ b/pkg/serializer/serializer.go
@@ -3,6 +3,7 @@ package serializer
 import (
 	"errors"
 	"fmt"
+	"sync"
 
 	"k8s.io/apimachinery/pkg/runtime"
 	"k8s.io/apimachinery/pkg/runtime/schema"
@@ -22,8 +23,12 @@ const (
 	ContentTypeYAML = ContentType(runtime.ContentTypeYAML)
 )
 
-// ErrUnsupportedContentType is returned if the specified content type isn't supported
-var ErrUnsupportedContentType = errors.New("unsupported content type")
+var (
+	// ErrUnsupportedContentType is returned if the specified content type isn't supported
+	ErrUnsupportedContentType = errors.New("unsupported content type")
+	// ErrObjectIsNotList is returned when a runtime.Object was not a List type
+	ErrObjectIsNotList = errors.New("given runtime.Object is not a *List type, or does not implement metav1.ListInterface")
+)
 
 // ContentTyped is an interface for objects that are specific to a set ContentType.
 type ContentTyped interface {
@@ -31,6 +36,8 @@ type ContentTyped interface {
 	ContentType() ContentType
 }
 
+func (ct ContentType) ContentType() ContentType { return ct }
+
 // Serializer is an interface providing high-level decoding/encoding functionality
 // for types registered in a *runtime.Scheme
 type Serializer interface {
@@ -38,13 +45,13 @@ type Serializer interface {
 	// a FrameWriter. The decoder can be customized by passing some options (e.g. WithDecodingOptions)
 	// to this call.
 	// The decoder supports both "classic" API Machinery objects and controller-runtime CRDs
-	Decoder(optsFn ...DecodingOptionsFunc) Decoder
+	Decoder(optsFn ...DecodeOption) Decoder
 
 	// Encoder is a high-level interface for encoding Kubernetes API Machinery objects and writing them
 	// to a FrameWriter. The encoder can be customized by passing some options (e.g. WithEncodingOptions)
 	// to this call.
 	// The encoder supports both "classic" API Machinery objects and controller-runtime CRDs
-	Encoder(optsFn ...EncodingOptionsFunc) Encoder
+	Encoder(optsFn ...EncodeOption) Encoder
 
 	// Converter is a high-level interface for converting objects between different versions
 	// The converter supports both "classic" API Machinery objects and controller-runtime CRDs
@@ -53,6 +60,8 @@ type Serializer interface {
 	// Defaulter is a high-level interface for accessing defaulting functions in a scheme
 	Defaulter() Defaulter
 
+	Patcher() Patcher
+
 	// Scheme provides access to the underlying runtime.Scheme, may be used for low-level access to
 	// the "type universe" and advanced conversion/defaulting features
 	Scheme() *runtime.Scheme
@@ -63,8 +72,10 @@ type Serializer interface {
 }
 
 type schemeAndCodec struct {
-	scheme *runtime.Scheme
-	codecs *k8sserializer.CodecFactory
+	// scheme is not thread-safe, hence it is guarded by a mutex
+	scheme   *runtime.Scheme
+	schemeMu *sync.Mutex
+	codecs   *k8sserializer.CodecFactory
 }
 
 // Encoder is a high-level interface for encoding Kubernetes API Machinery objects and writing them
@@ -186,13 +197,16 @@ func NewSerializer(scheme *runtime.Scheme, codecs *k8sserializer.CodecFactory) S
 		*codecs = k8sserializer.NewCodecFactory(scheme)
 	}
 
+	schemeCodec := &schemeAndCodec{
+		scheme:   scheme,
+		schemeMu: &sync.Mutex{},
+		codecs:   codecs,
+	}
 	return &serializer{
-		schemeAndCodec: &schemeAndCodec{
-			scheme: scheme,
-			codecs: codecs,
-		},
-		converter: newConverter(scheme),
-		defaulter: newDefaulter(scheme),
+		schemeAndCodec: schemeCodec,
+		converter:      newConverter(scheme),
+		defaulter:      newDefaulter(scheme),
+		patcher:        &patcher{schemeCodec},
 	}
 }
 
@@ -201,6 +215,7 @@ type serializer struct {
 	*schemeAndCodec
 	converter *converter
 	defaulter *defaulter
+	patcher   *patcher
 }
 
 // Scheme provides access to the underlying runtime.Scheme, may be used for low-level access to
@@ -215,14 +230,12 @@ func (s *serializer) Codecs() *k8sserializer.CodecFactory {
 	return s.codecs
 }
 
-func (s *serializer) Decoder(optFns ...DecodingOptionsFunc) Decoder {
-	opts := newDecodeOpts(optFns...)
-	return newDecoder(s.schemeAndCodec, *opts)
+func (s *serializer) Decoder(opts ...DecodeOption) Decoder {
+	return newDecoder(s.schemeAndCodec, *defaultDecodeOpts().ApplyOptions(opts))
 }
 
-func (s *serializer) Encoder(optFns ...EncodingOptionsFunc) Encoder {
-	opts := newEncodeOpts(optFns...)
-	return newEncoder(s.schemeAndCodec, *opts)
+func (s *serializer) Encoder(opts ...EncodeOption) Encoder {
+	return newEncoder(s.schemeAndCodec, *defaultEncodeOpts().ApplyOptions(opts))
 }
 
 func (s *serializer) Converter() Converter {
@@ -233,6 +246,10 @@ func (s *serializer) Defaulter() Defaulter {
 	return s.defaulter
 }
 
+func (s *serializer) Patcher() Patcher {
+	return s.patcher
+}
+
 func prioritizedVersionForGroup(scheme *runtime.Scheme, groupName string) (schema.GroupVersion, error) {
 	// Get the prioritized versions for the given group
 	gvs := scheme.PrioritizedVersionsForGroup(groupName)
@@ -242,23 +259,3 @@ func prioritizedVersionForGroup(scheme *runtime.Scheme, groupName string) (schem
 	// Use the first, preferred, (external) version
 	return gvs[0], nil
 }
-
-func GVKForObject(scheme *runtime.Scheme, obj runtime.Object) (schema.GroupVersionKind, error) {
-	// If we already have TypeMeta filled in here, just use it
-	// TODO: This is probably not needed
-	gvk := obj.GetObjectKind().GroupVersionKind()
-	if !gvk.Empty() {
-		return gvk, nil
-	}
-
-	// TODO: If there are two GVKs returned, it's probably a misconfiguration in the scheme
-	// It might be expected though, and we can tolerate setting the GVK manually IFF there are more than
-	// one ObjectKind AND the given GVK is one of them.
-
-	// Get the possible kinds for the object
-	gvks, unversioned, err := scheme.ObjectKinds(obj)
-	if unversioned || err != nil || len(gvks) != 1 {
-		return schema.GroupVersionKind{}, fmt.Errorf("unversioned %t or err %v or invalid gvks %v", unversioned, err, gvks)
-	}
-	return gvks[0], nil
-}
diff --git a/pkg/serializer/serializer_test.go b/pkg/serializer/serializer_test.go
index ba23985..c475ec7 100644
--- a/pkg/serializer/serializer_test.go
+++ b/pkg/serializer/serializer_test.go
@@ -21,8 +21,8 @@ var (
 	codecs         = k8sserializer.NewCodecFactory(scheme)
 	ourserializer  = NewSerializer(scheme, &codecs)
 	defaultEncoder = ourserializer.Encoder(
-		WithPrettyEncode(false), // TODO: Also test the pretty serializer
-		WithCommentsEncode(true),
+		PrettyEncode(false), // TODO: Also test the pretty serializer
+		PreserveCommentsStrict,
 	)
 
 	groupname = "foogroup"
@@ -402,8 +402,8 @@ func TestDecode(t *testing.T) {
 	for _, rt := range tests {
 		t.Run(rt.name, func(t2 *testing.T) {
 			obj, actual := ourserializer.Decoder(
-				WithDefaultsDecode(rt.doDefaulting),
-				WithConvertToHubDecode(rt.doConversion),
+				DefaultAtDecode(rt.doDefaulting),
+				ConvertToHub(rt.doConversion),
 			).Decode(NewYAMLFrameReader(FromBytes(rt.data)))
 			if (actual != nil) != rt.expectedErr {
 				t2.Errorf("expected error %t but actual %t: %v", rt.expectedErr, actual != nil, actual)
@@ -444,7 +444,7 @@ func TestDecodeInto(t *testing.T) {
 		t.Run(rt.name, func(t2 *testing.T) {
 
 			actual := ourserializer.Decoder(
-				WithDefaultsDecode(rt.doDefaulting),
+				DefaultAtDecode(rt.doDefaulting),
 			).DecodeInto(NewYAMLFrameReader(FromBytes(rt.data)), rt.obj)
 			if (actual != nil) != rt.expectedErr {
 				t2.Errorf("expected error %t but actual %t: %v", rt.expectedErr, actual != nil, actual)
@@ -484,8 +484,8 @@ func TestDecodeAll(t *testing.T) {
 	for _, rt := range tests {
 		t.Run(rt.name, func(t2 *testing.T) {
 			objs, actual := ourserializer.Decoder(
-				WithDefaultsDecode(rt.doDefaulting),
-				WithListElementsDecoding(rt.listSplit),
+				DefaultAtDecode(rt.doDefaulting),
+				DecodeListElements(rt.listSplit),
 			).DecodeAll(NewYAMLFrameReader(FromBytes(rt.data)))
 			if (actual != nil) != rt.expectedErr {
 				t2.Errorf("expected error %t but actual %t: %v", rt.expectedErr, actual != nil, actual)
@@ -527,7 +527,7 @@ func TestDecodeUnknown(t *testing.T) {
 	for _, rt := range tests {
 		t.Run(rt.name, func(t2 *testing.T) {
 			obj, actual := ourserializer.Decoder(
-				WithUnknownDecode(rt.unknown),
+				DecodeUnknown(rt.unknown),
 			).Decode(NewYAMLFrameReader(FromBytes(rt.data)))
 			if (actual != nil) != rt.expectedErr {
 				t2.Errorf("expected error %t but actual %t: %v", rt.expectedErr, actual != nil, actual)
@@ -560,9 +560,9 @@ func TestRoundtrip(t *testing.T) {
 	for _, rt := range tests {
 		t.Run(rt.name, func(t2 *testing.T) {
 			obj, err := ourserializer.Decoder(
-				WithConvertToHubDecode(true),
-				WithCommentsDecode(true),
-				WithUnknownDecode(true),
+				ConvertToHub(true),
+				PreserveCommentsStrict,
+				DecodeUnknown(true),
 			).Decode(NewYAMLFrameReader(FromBytes(rt.data)))
 			if err != nil {
 				t2.Errorf("unexpected decode error: %v", err)
diff --git a/pkg/serializer/utils.go b/pkg/serializer/utils.go
new file mode 100644
index 0000000..f916a7a
--- /dev/null
+++ b/pkg/serializer/utils.go
@@ -0,0 +1,121 @@
+package serializer
+
+import (
+	"fmt"
+	"strings"
+
+	"k8s.io/apimachinery/pkg/api/meta"
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
+	"k8s.io/apimachinery/pkg/runtime"
+	"k8s.io/apimachinery/pkg/runtime/schema"
+	"sigs.k8s.io/controller-runtime/pkg/client"
+	"sigs.k8s.io/controller-runtime/pkg/client/apiutil"
+)
+
+func GVKForObject(scheme *runtime.Scheme, obj runtime.Object) (schema.GroupVersionKind, error) {
+	// Safety check: one should not do this
+	if obj == nil || obj.GetObjectKind() == nil {
+		return schema.GroupVersionKind{}, fmt.Errorf("GVKForObject: obj or obj.GetObjectKind() must not be nil")
+	}
+
+	// If this is a runtime.Unknown object, return the GVK stored in TypeMeta
+	if gvk := obj.GetObjectKind().GroupVersionKind(); IsUnknown(obj) && !gvk.Empty() {
+		return gvk, nil
+	}
+
+	// Special case: Allow objects with two versions to be registered, when the caller is specific
+	// about what version they want populated.
+	// This is needed essentially for working around that there are specific K8s types (structs)
+	// that have been registered with multiple GVKs (e.g. a Deployment struct in both apps & extensions)
+	// TODO: Maybe there is a better way to solve this? Remove unwanted entries from the scheme typeToGVK
+	// map manually?
+	gvks, _, _ := scheme.ObjectKinds(obj)
+	if len(gvks) > 1 {
+		// If we have a configuration with more than one gvk for the same object,
+		// check the set GVK on the object to "choose" the right one, if exists in the list
+		setGVK := obj.GetObjectKind().GroupVersionKind()
+		if !setGVK.Empty() {
+			for _, gvk := range gvks {
+				if EqualsGVK(setGVK, gvk) {
+					return gvk, nil
+				}
+			}
+		}
+	}
+
+	// TODO: Should we just copy-paste this one, or move it into k8s core to avoid importing controller-runtime
+	// only for this function?
+	return apiutil.GVKForObject(obj, scheme)
+}
+
+// GVKForList returns the GroupVersionKind for the items in a given List type.
+// In the case of Unstructured or PartialObjectMetadata, it is required that this
+// information is already set in TypeMeta. The "List" suffix is never returned.
+func GVKForList(obj client.ObjectList, scheme *runtime.Scheme) (schema.GroupVersionKind, error) {
+	// First, get the GVK as normal.
+	gvk, err := GVKForObject(scheme, obj)
+	if err != nil {
+		return schema.GroupVersionKind{}, err
+	}
+	// Make sure this is a list type, i.e. it has the an "Items" field.
+	isList := meta.IsListType(obj)
+	if !isList {
+		return schema.GroupVersionKind{}, ErrObjectIsNotList
+	}
+	// Make sure the returned GVK never ends in List.
+	gvk.Kind = strings.TrimSuffix(gvk.Kind, "List")
+	return gvk, nil
+}
+
+// EqualsGK returns true if gk1 and gk2 have the same fields.
+func EqualsGK(gk1, gk2 schema.GroupKind) bool {
+	return gk1.Group == gk2.Group && gk1.Kind == gk2.Kind
+}
+
+// EqualsGVK returns true if gvk1 and gvk2 have the same fields.
+func EqualsGVK(gvk1, gvk2 schema.GroupVersionKind) bool {
+	return EqualsGK(gvk1.GroupKind(), gvk2.GroupKind()) && gvk1.Version == gvk2.Version
+}
+
+func IsUnknown(obj runtime.Object) bool {
+	_, isUnknown := obj.(*runtime.Unknown)
+	return isUnknown
+}
+
+func IsPartialObject(obj runtime.Object) bool {
+	_, isPartial := obj.(*metav1.PartialObjectMetadata)
+	return isPartial
+}
+
+func IsPartialObjectList(obj runtime.Object) bool {
+	_, isPartialList := obj.(*metav1.PartialObjectMetadataList)
+	return isPartialList
+}
+
+// IsUnstructured checks if obj is runtime.Unstructured
+func IsUnstructured(obj runtime.Object) bool {
+	_, isUnstructured := obj.(runtime.Unstructured)
+	return isUnstructured
+}
+
+// IsUnstructuredList checks if obj is *unstructured.UnstructuredList
+func IsUnstructuredList(obj runtime.Object) bool {
+	_, isUnstructuredList := obj.(*unstructured.UnstructuredList)
+	return isUnstructuredList
+}
+
+// IsNonConvertible returns true for unstructured, partial and unknown objects
+// that should not be converted.
+func IsNonConvertible(obj runtime.Object) bool {
+	// TODO: Should Lists also be marked non-convertible?
+	// IsUnstructured also covers IsUnstructuredList -- *UnstructuredList implements runtime.Unstructured
+	return IsUnstructured(obj) || IsPartialObject(obj) || IsPartialObjectList(obj) || IsUnknown(obj)
+}
+
+// IsTyped returns true if the object is typed, i.e. registered with the given
+// scheme and not unversioned.
+func IsTyped(obj runtime.Object, scheme *runtime.Scheme) bool {
+	_, isUnversioned, err := scheme.ObjectKinds(obj)
+	return !isUnversioned && err == nil
+}
diff --git a/pkg/storage/backend/backend.go b/pkg/storage/backend/backend.go
new file mode 100644
index 0000000..39d769e
--- /dev/null
+++ b/pkg/storage/backend/backend.go
@@ -0,0 +1,332 @@
+package backend
+
+import (
+	"bytes"
+	"context"
+	"errors"
+	"fmt"
+
+	"github.com/weaveworks/libgitops/pkg/serializer"
+	"github.com/weaveworks/libgitops/pkg/storage"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+	"k8s.io/apimachinery/pkg/runtime"
+	"k8s.io/apimachinery/pkg/util/sets"
+)
+
+var (
+	// ErrCannotSaveMetadata is returned if the user tries to save metadata-only objects
+	ErrCannotSaveMetadata = errors.New("cannot save (Create|Update|Patch) *metav1.PartialObjectMetadata")
+	// ErrNameRequired is returned when .metadata.name is unset
+	// TODO: Support generateName?
+	ErrNameRequired = errors.New(".metadata.name is required")
+)
+
+// TODO: Make a *core.Unknown that has
+// 1. TypeMeta
+// 2. DeepCopies (for Object compatibility),
+// 3. ObjectMeta
+// 4. Spec { Data []byte, ContentType ContentType, Object interface{} }
+// 5. Status { Data []byte, ContentType ContentType, Object interface{} }
+// TODO: Need to make sure we never write this internal struct to disk (MarshalJSON error?)
+
+type Accessors interface {
+	Storage() storage.Storage
+	NamespaceEnforcer() NamespaceEnforcer
+	Scheme() *runtime.Scheme
+}
+
+type WriteAccessors interface {
+	Validator() Validator
+	StorageVersioner() StorageVersioner
+}
+
+type Reader interface {
+	Accessors
+
+	Get(ctx context.Context, obj core.Object) error
+	storage.Lister
+}
+
+type Writer interface {
+	Accessors
+	WriteAccessors
+
+	Create(ctx context.Context, obj core.Object) error
+	Update(ctx context.Context, obj core.Object) error
+	Delete(ctx context.Context, obj core.Object) error
+}
+
+type StatusWriter interface {
+	Accessors
+	WriteAccessors
+
+	UpdateStatus(ctx context.Context, obj core.Object) error
+}
+
+type Backend interface {
+	Reader
+	Writer
+	StatusWriter
+}
+
+type ChangeOperation string
+
+const (
+	ChangeOperationCreate ChangeOperation = "create"
+	ChangeOperationUpdate ChangeOperation = "update"
+	ChangeOperationDelete ChangeOperation = "delete"
+)
+
+type Validator interface {
+	ValidateChange(ctx context.Context, backend Reader, op ChangeOperation, obj core.Object) error
+}
+
+type StorageVersioner interface {
+	// TODO: Do we need the context here?
+	StorageVersion(ctx context.Context, id core.ObjectID) (core.GroupVersion, error)
+}
+
+func NewGeneric(
+	storage storage.Storage,
+	serializer serializer.Serializer, // TODO: only scheme required, encode/decode optional?
+	enforcer NamespaceEnforcer,
+	validator Validator, // TODO: optional?
+	versioner StorageVersioner, // TODO: optional?
+) (*Generic, error) {
+	if storage == nil {
+		return nil, fmt.Errorf("storage is mandatory")
+	}
+	if serializer == nil { // TODO: relax this to scheme, and add encoder/decoder to opts?
+		return nil, fmt.Errorf("serializer is mandatory")
+	}
+	if enforcer == nil {
+		return nil, fmt.Errorf("enforcer is mandatory")
+	}
+	// TODO: validate options
+	return &Generic{
+		scheme:  serializer.Scheme(),
+		encoder: serializer.Encoder(),
+		decoder: serializer.Decoder(),
+
+		storage:   storage,
+		enforcer:  enforcer,
+		validator: validator,
+		versioner: versioner,
+	}, nil
+}
+
+var _ Backend = &Generic{}
+
+type Generic struct {
+	scheme  *runtime.Scheme
+	decoder serializer.Decoder
+	encoder serializer.Encoder
+
+	storage   storage.Storage
+	enforcer  NamespaceEnforcer
+	validator Validator
+	versioner StorageVersioner
+}
+
+func (b *Generic) Scheme() *runtime.Scheme {
+	return b.scheme
+}
+
+func (b *Generic) Storage() storage.Storage {
+	return b.storage
+}
+
+func (b *Generic) NamespaceEnforcer() NamespaceEnforcer {
+	return b.enforcer
+}
+
+func (b *Generic) Validator() Validator {
+	return b.validator
+}
+
+func (b *Generic) StorageVersioner() StorageVersioner {
+	return b.versioner
+}
+
+func (b *Generic) Get(ctx context.Context, obj core.Object) error {
+	// Get the versioned ID for the given obj. This might mutate obj wrt namespacing info.
+	id, err := b.idForObj(ctx, obj)
+	if err != nil {
+		return err
+	}
+	// Read the underlying bytes
+	content, err := b.storage.Read(ctx, id)
+	if err != nil {
+		return err
+	}
+	// Get the right content type for the data
+	ct, err := b.storage.ContentType(ctx, id)
+	if err != nil {
+		return err
+	}
+
+	// TODO: Support various decoding options, e.g. defaulting?
+	// TODO: Does this "replace" already-set fields?
+	return b.decoder.DecodeInto(serializer.NewSingleFrameReader(content, ct), obj)
+}
+
+// ListNamespaces lists the available namespaces for the given GroupKind.
+// This function shall only be called for namespaced objects, it is up to
+// the caller to make sure they do not call this method for root-spaced
+// objects; for that the behavior is undefined (but returning an error
+// is recommended).
+func (b *Generic) ListNamespaces(ctx context.Context, gk core.GroupKind) (sets.String, error) {
+	return b.storage.ListNamespaces(ctx, gk)
+}
+
+// ListObjectKeys returns a list of names (with optionally, the namespace).
+// For namespaced GroupKinds, the caller must provide a namespace, and for
+// root-spaced GroupKinds, the caller must not. When namespaced, this function
+// must only return object keys for that given namespace.
+func (b *Generic) ListObjectIDs(ctx context.Context, gk core.GroupKind, namespace string) ([]core.UnversionedObjectID, error) {
+	return b.storage.ListObjectIDs(ctx, gk, namespace)
+}
+
+func (b *Generic) Create(ctx context.Context, obj core.Object) error {
+	// We must never save metadata-only structs
+	if serializer.IsPartialObject(obj) {
+		return ErrCannotSaveMetadata
+	}
+
+	// Get the versioned ID for the given obj. This might mutate obj wrt namespacing info.
+	id, err := b.idForObj(ctx, obj)
+	if err != nil {
+		return err
+	}
+
+	// Do not create it if it already exists
+	if b.storage.Exists(ctx, id) {
+		return core.NewErrAlreadyExists(id)
+	}
+
+	// Validate that the change is ok
+	// TODO: Don't make "upcasting" possible here
+	if b.validator != nil {
+		if err := b.validator.ValidateChange(ctx, b, ChangeOperationCreate, obj); err != nil {
+			return err
+		}
+	}
+
+	// Internal, common write shared with Update()
+	return b.write(ctx, id, obj)
+}
+func (b *Generic) Update(ctx context.Context, obj core.Object) error {
+	// We must never save metadata-only structs
+	if serializer.IsPartialObject(obj) {
+		return ErrCannotSaveMetadata
+	}
+
+	// Get the versioned ID for the given obj. This might mutate obj wrt namespacing info.
+	id, err := b.idForObj(ctx, obj)
+	if err != nil {
+		return err
+	}
+
+	// Require that the object already exists
+	if !b.storage.Exists(ctx, id) {
+		return core.NewErrNotFound(id)
+	}
+
+	// Validate that the change is ok
+	// TODO: Don't make "upcasting" possible here
+	if b.validator != nil {
+		if err := b.validator.ValidateChange(ctx, b, ChangeOperationUpdate, obj); err != nil {
+			return err
+		}
+	}
+
+	// Internal, common write shared with Create()
+	return b.write(ctx, id, obj)
+}
+
+func (b *Generic) UpdateStatus(ctx context.Context, obj core.Object) error {
+	return core.ErrNotImplemented // TODO
+}
+
+func (b *Generic) write(ctx context.Context, id core.ObjectID, obj core.Object) error {
+	// TODO: Figure out how to get ContentType before the object actually exists!
+	ct, err := b.storage.ContentType(ctx, id)
+	if err != nil {
+		return err
+	}
+	// Resolve the desired storage version
+	/* TODO: re-enable later
+	gv, err := b.versioner.StorageVersion(ctx, id)
+	if err != nil {
+		return err
+	}*/
+
+	// Set creationTimestamp if not already populated
+	t := obj.GetCreationTimestamp()
+	if t.IsZero() {
+		obj.SetCreationTimestamp(metav1.Now())
+	}
+
+	var objBytes bytes.Buffer
+	// TODO: Work with any ContentType, not just JSON/YAML. Or, make a SingleFrameWriter for any ct.
+	err = b.encoder.Encode(serializer.NewFrameWriter(ct, &objBytes), obj)
+	if err != nil {
+		return err
+	}
+
+	return b.storage.Write(ctx, id, objBytes.Bytes())
+}
+
+func (b *Generic) Delete(ctx context.Context, obj core.Object) error {
+	// Get the versioned ID for the given obj. This might mutate obj wrt namespacing info.
+	id, err := b.idForObj(ctx, obj)
+	if err != nil {
+		return err
+	}
+
+	// Verify it did exist
+	if !b.storage.Exists(ctx, id) {
+		return core.NewErrNotFound(id)
+	}
+
+	// Validate that the change is ok
+	// TODO: Don't make "upcasting" possible here
+	if b.validator != nil {
+		if err := b.validator.ValidateChange(ctx, b, ChangeOperationDelete, obj); err != nil {
+			return err
+		}
+	}
+
+	// Delete it from the underlying storage
+	return b.storage.Delete(ctx, id)
+}
+
+// Note: This should also work for unstructured and partial metadata objects
+func (b *Generic) idForObj(ctx context.Context, obj core.Object) (core.ObjectID, error) {
+	gvk, err := serializer.GVKForObject(b.scheme, obj)
+	if err != nil {
+		return nil, err
+	}
+
+	// Object must always have .metadata.name set
+	if len(obj.GetName()) == 0 {
+		return nil, ErrNameRequired
+	}
+
+	// Enforce the given namespace policy. This might mutate obj.
+	// TODO: disallow "upcasting" the Lister to a full-blown Storage?
+	if err := b.enforcer.EnforceNamespace(
+		ctx,
+		obj,
+		gvk,
+		b.Storage().Namespacer(),
+		b.Storage(),
+	); err != nil {
+		return nil, err
+	}
+
+	// At this point we know name is non-empty, and the namespace field is correct,
+	// according to policy
+	return core.NewObjectID(gvk, core.ObjectKeyFromObject(obj)), nil
+}
diff --git a/pkg/storage/backend/enforcer.go b/pkg/storage/backend/enforcer.go
new file mode 100644
index 0000000..8553283
--- /dev/null
+++ b/pkg/storage/backend/enforcer.go
@@ -0,0 +1,116 @@
+package backend
+
+import (
+	"context"
+	"errors"
+	"fmt"
+
+	"github.com/weaveworks/libgitops/pkg/storage"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+)
+
+var (
+	// ErrNoSuchNamespace means that the set of namespaces was searched in the
+	// system, but the requested namespace wasn't in that list.
+	ErrNoSuchNamespace = errors.New("no such namespace in the system")
+)
+
+// NamespaceEnforcer enforces a namespace policy for the Backend.
+type NamespaceEnforcer interface {
+	// EnforceNamespace makes sure that:
+	// a) Any namespaced object has a non-empty namespace field after this call
+	// b) Any non-namespaced object has an empty namespace field after this call
+	// c) The applicable namespace policy of the user's liking is enforced (e.g.
+	//    that there are only certain valid namespaces that can be used).
+	//
+	// This call is allowed to mutate obj. gvk represents the GroupVersionKind
+	// of obj. The namespacer can be used to figure out if the given object is
+	// namespaced or not. The given lister might be used to list object IDs,
+	// or existing namespaces in the system.
+	//
+	// See GenericNamespaceEnforcer for an example implementation, or
+	// pkg/storage/kube.NewNamespaceEnforcer() for a sample application.
+	EnforceNamespace(ctx context.Context, obj core.Object, gvk core.GroupVersionKind, namespacer core.Namespacer, lister storage.Lister) error
+}
+
+// GenericNamespaceEnforcer is a NamespaceEnforcer that:
+// a) sets a default namespace for namespaced objects that have
+//    the namespace field left empty
+// b) makes sure non-namespaced objects do not have the namespace
+//    field set, by pruning any previously-set value.
+// c) if NamespaceGroupKind is non-nil; lists valid Namespace objects
+//    in the system (of the given GroupKind); and matches namespaced
+//    objects' namespace field against the listed Namespace objects'
+//    .metadata.name field.
+//
+// For an example of how to configure this enforcer in the way
+// Kubernetes itself (approximately) does, see pkg/storage/kube.
+// NewNamespaceEnforcer().
+type GenericNamespaceEnforcer struct {
+	// DefaultNamespace describes the default namespace string
+	// that should be set, if a namespaced object's namespace
+	// field is empty.
+	// +required
+	DefaultNamespace string
+	// NamespaceGroupKind describes the GroupKind for Namespace
+	// objects in the system. If non-nil, objects with such
+	// GroupKind are listed, and their .metadata.name is matched
+	// against the current object's namespace field. If nil, any
+	// namespace value is considered valid.
+	// +optional
+	NamespaceGroupKind *core.GroupKind
+}
+
+func (e GenericNamespaceEnforcer) EnforceNamespace(ctx context.Context, obj core.Object, gvk core.GroupVersionKind, namespacer core.Namespacer, lister storage.Lister) error {
+	// Get namespacing info
+	namespaced, err := namespacer.IsNamespaced(gvk.GroupKind())
+	if err != nil {
+		return err
+	}
+
+	// Enforce generic rules
+	ns := obj.GetNamespace()
+	if !namespaced {
+		// If a namespace was set, it must be sanitized, as non-namespaced
+		// resources must have namespace field empty.
+		if len(ns) != 0 {
+			obj.SetNamespace("")
+		}
+		return nil
+	}
+	// The resource is namespaced.
+	// If it is empty, set it to the default namespace.
+	if len(ns) == 0 {
+		// Verify that DefaultNamespace is non-empty
+		if len(e.DefaultNamespace) == 0 {
+			return fmt.Errorf("GenericNamespaceEnforcer.DefaultNamespace is mandatory: %w", core.ErrInvalidParameter)
+		}
+		// Mutate obj and set the namespace field to the default, then return
+		obj.SetNamespace(e.DefaultNamespace)
+		return nil
+	}
+
+	// If the namespace field is set, but NamespaceGroupKind is
+	// nil, it means that any non-empty namespace value is
+	// valid.
+	if e.NamespaceGroupKind == nil {
+		return nil
+	}
+
+	// However, if a Namespace GroupKind was given, look it up using
+	// the lister, and verify its .metadata.name matches the given
+	// namespace value.
+	objIDs, err := lister.ListObjectIDs(ctx, *e.NamespaceGroupKind, "")
+	if err != nil {
+		return err
+	}
+	// Loop through the IDs, and try to match it against the set ns
+	for _, id := range objIDs {
+		if id.ObjectKey().Name == ns {
+			// Found the namespace; this is a valid setting
+			return nil
+		}
+	}
+	// The set namespace doesn't belong to the set of valid namespaces, error
+	return fmt.Errorf("%w: %q", ErrNoSuchNamespace, ns)
+}
diff --git a/pkg/storage/cache/cache.go b/pkg/storage/cache/cache.go
deleted file mode 100644
index 11a4991..0000000
--- a/pkg/storage/cache/cache.go
+++ /dev/null
@@ -1,197 +0,0 @@
-package cache
-
-/*
-
-TODO: Revisit if we need this file/package in the future.
-
-import (
-	log "github.com/sirupsen/logrus"
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/serializer"
-	"github.com/weaveworks/libgitops/pkg/storage"
-	"k8s.io/apimachinery/pkg/runtime/schema"
-)
-
-// Cache is an intermediate caching layer, which conforms to Storage
-// Typically you back the cache with an actual storage
-type Cache interface {
-	storage.Storage
-	// Flush is used to write the state of the entire cache to storage
-	// Warning: this is a very expensive operation
-	Flush() error
-}
-
-type cache struct {
-	// storage is the backing Storage for the cache
-	// used to look up non-cached Objects
-	storage storage.Storage
-
-	// index caches the Objects by GroupVersionKind and UID
-	// This guarantees uniqueness when looking up a specific Object
-	index *index
-}
-
-var _ Cache = &cache{}
-
-func NewCache(backingStorage storage.Storage) Cache {
-	c := &cache{
-		storage: backingStorage,
-		index:   newIndex(backingStorage),
-	}
-
-	return c
-}
-
-func (s *cache) Serializer() serializer.Serializer {
-	return s.storage.Serializer()
-}
-
-func (c *cache) New(gvk schema.GroupVersionKind) (runtime.Object, error) {
-	// Request the storage to create the Object. The
-	// newly generated Object has not got an UID which
-	// is required for indexing, so just return it
-	// without storing it into the cache
-	return c.storage.New(gvk)
-}
-
-func (c *cache) Get(gvk schema.GroupVersionKind, uid runtime.UID) (obj runtime.Object, err error) {
-	log.Tracef("cache: Get %s with UID %q", gvk.Kind, uid)
-
-	// If the requested Object resides in the cache, return it
-	if obj, err = c.index.loadByID(gvk, uid); err != nil || obj != nil {
-		return
-	}
-
-	// Request the Object from the storage
-	obj, err = c.storage.Get(gvk, uid)
-
-	// If no errors occurred, cache it
-	if err == nil {
-		err = c.index.store(obj)
-	}
-
-	return
-}
-
-func (c *cache) GetMeta(gvk schema.GroupVersionKind, uid runtime.UID) (obj runtime.Object, err error) {
-	log.Tracef("cache: GetMeta %s with UID %q", gvk.Kind, uid)
-
-	obj, err = c.storage.GetMeta(gvk, uid)
-
-	// If no errors occurred while loading, store the Object in the cache
-	if err == nil {
-		err = c.index.storeMeta(obj)
-	}
-
-	return
-}
-
-func (c *cache) Set(gvk schema.GroupVersionKind, obj runtime.Object) error {
-	log.Tracef("cache: Set %s with UID %q", gvk.Kind, obj.GetUID())
-
-	// Store the changed Object in the cache
-	if err := c.index.store(obj); err != nil {
-		return err
-	}
-
-	// TODO: For now the cache always flushes, we might add automatic flushing later
-	return c.storage.Set(gvk, obj)
-}
-
-func (c *cache) Patch(gvk schema.GroupVersionKind, uid runtime.UID, patch []byte) error {
-	// TODO: For now patches are always flushed, the cache will load the updated Object on-demand on access
-	return c.storage.Patch(gvk, uid, patch)
-}
-
-func (c *cache) Delete(gvk schema.GroupVersionKind, uid runtime.UID) error {
-	log.Tracef("cache: Delete %s with UID %q", gvk.Kind, uid)
-
-	// Delete the given Object from the cache and storage
-	c.index.delete(gvk, uid)
-	return c.storage.Delete(gvk, uid)
-}
-
-type listFunc func(gvk schema.GroupVersionKind) ([]runtime.Object, error)
-type cacheStoreFunc func([]runtime.Object) error
-
-// list is a common handler for List and ListMeta
-func (c *cache) list(gvk schema.GroupVersionKind, slf, clf listFunc, csf cacheStoreFunc) (objs []runtime.Object, err error) {
-	var storageCount uint64
-	if storageCount, err = c.storage.Count(gvk); err != nil {
-		return
-	}
-
-	if c.index.count(gvk) != storageCount {
-		log.Tracef("cache: miss when listing: %s", gvk)
-		// If the cache doesn't track all of the Objects, request them from the storage
-		if objs, err = slf(gvk); err != nil {
-			// If no errors occurred, store the Objects in the cache
-			err = csf(objs)
-		}
-	} else {
-		log.Tracef("cache: hit when listing: %s", gvk)
-		// If the cache tracks everything, return the cache's contents
-		objs, err = clf(gvk)
-	}
-
-	return
-}
-
-func (c *cache) List(gvk schema.GroupVersionKind) ([]runtime.Object, error) {
-	return c.list(gvk, c.storage.List, c.index.list, c.index.storeAll)
-}
-
-func (c *cache) ListMeta(gvk schema.GroupVersionKind) ([]runtime.Object, error) {
-	return c.list(gvk, c.storage.ListMeta, c.index.listMeta, c.index.storeAllMeta)
-}
-
-func (c *cache) Count(gvk schema.GroupVersionKind) (uint64, error) {
-	// The cache is transparent about how many items it has cached
-	return c.storage.Count(gvk)
-}
-
-func (c *cache) Checksum(gvk schema.GroupVersionKind, uid runtime.UID) (string, error) {
-	// The cache is transparent about the checksums
-	return c.storage.Checksum(gvk, uid)
-}
-
-func (c *cache) RawStorage() storage.RawStorage {
-	return c.storage.RawStorage()
-}
-
-func (c *cache) Close() error {
-	return c.storage.Close()
-}
-
-func (c *cache) Flush() error {
-	// Load the entire cache
-	allObjects, err := c.index.loadAll()
-	if err != nil {
-		return err
-	}
-
-	for _, obj := range allObjects {
-		// Request the storage to save each Object
-		if err := c.storage.Set(obj); err != nil {
-			return err
-		}
-	}
-
-	return nil
-}
-
-// PartialObjectFrom is used to create a bound PartialObjectImpl from an Object.
-// Note: This might be useful later (maybe here or maybe in pkg/runtime) if re-enable the cache
-func PartialObjectFrom(obj Object) (PartialObject, error) {
-	tm, ok := obj.GetObjectKind().(*metav1.TypeMeta)
-	if !ok {
-		return nil, fmt.Errorf("PartialObjectFrom: Cannot cast obj to *metav1.TypeMeta, is %T", obj.GetObjectKind())
-	}
-	om, ok := obj.GetObjectMeta().(*metav1.ObjectMeta)
-	if !ok {
-		return nil, fmt.Errorf("PartialObjectFrom: Cannot cast obj to *metav1.ObjectMeta, is %T", obj.GetObjectMeta())
-	}
-	return &PartialObjectImpl{tm, om}, nil
-}
-
-*/
diff --git a/pkg/storage/cache/index.go b/pkg/storage/cache/index.go
deleted file mode 100644
index 326014f..0000000
--- a/pkg/storage/cache/index.go
+++ /dev/null
@@ -1,156 +0,0 @@
-package cache
-
-/*
-
-TODO: Revisit if we need this file/package in the future.
-
-import (
-	log "github.com/sirupsen/logrus"
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/storage"
-	"k8s.io/apimachinery/pkg/runtime/schema"
-)
-
-type index struct {
-	storage storage.Storage
-	objects map[schema.GroupVersionKind]map[runtime.UID]*cacheObject
-}
-
-func newIndex(storage storage.Storage) *index {
-	return &index{
-		storage: storage,
-		objects: make(map[schema.GroupVersionKind]map[runtime.UID]*cacheObject),
-	}
-}
-
-func (i *index) loadByID(gvk schema.GroupVersionKind, uid runtime.UID) (runtime.Object, error) {
-	if uids, ok := i.objects[gvk]; ok {
-		if obj, ok := uids[uid]; ok {
-			log.Tracef("index: cache hit for %s with UID %q", gvk.Kind, uid)
-			return obj.loadFull()
-		}
-	}
-
-	log.Tracef("index: cache miss for %s with UID %q", gvk.Kind, uid)
-	return nil, nil
-}
-
-func (i *index) loadAll() ([]runtime.Object, error) {
-	var size uint64
-
-	for gvk := range i.objects {
-		size += i.count(gvk)
-	}
-
-	all := make([]runtime.Object, 0, size)
-
-	for gvk := range i.objects {
-		if objects, err := i.list(gvk); err == nil {
-			all = append(all, objects...)
-		} else {
-			return nil, err
-		}
-	}
-
-	return all, nil
-}
-
-func store(i *index, obj runtime.Object, apiType bool) error {
-	// If store is called for an invalid Object lacking an UID,
-	// panic and print the stack trace. This should never happen.
-	if obj.GetUID() == "" {
-		panic("Attempt to cache invalid Object: missing UID")
-	}
-
-	co, err := newCacheObject(i.storage, obj, apiType)
-	if err != nil {
-		return err
-	}
-
-	gvk := co.object.GetObjectKind().GroupVersionKind()
-
-	if _, ok := i.objects[gvk]; !ok {
-		i.objects[gvk] = make(map[runtime.UID]*cacheObject)
-	}
-
-	log.Tracef("index: storing %s object with UID %q, meta: %t", gvk.Kind, obj.GetName(), apiType)
-	i.objects[gvk][co.object.GetUID()] = co
-
-	return nil
-}
-
-func (i *index) store(obj runtime.Object) error {
-	return store(i, obj, false)
-}
-
-func (i *index) storeAll(objs []runtime.Object) (err error) {
-	for _, obj := range objs {
-		if err = i.store(obj); err != nil {
-			break
-		}
-	}
-
-	return
-}
-
-func (i *index) storeMeta(obj runtime.Object) error {
-	return store(i, obj, true)
-}
-
-func (i *index) storeAllMeta(objs []runtime.Object) (err error) {
-	for _, obj := range objs {
-		if uids, ok := i.objects[obj.GetObjectKind().GroupVersionKind()]; ok {
-			if _, ok := uids[obj.GetUID()]; ok {
-				continue
-			}
-		}
-
-		if err = i.storeMeta(obj); err != nil {
-			break
-		}
-	}
-
-	return
-}
-
-func (i *index) delete(gvk schema.GroupVersionKind, uid runtime.UID) {
-	if uids, ok := i.objects[gvk]; ok {
-		delete(uids, uid)
-	}
-}
-
-func (i *index) count(gvk schema.GroupVersionKind) (count uint64) {
-	count = uint64(len(i.objects[gvk]))
-	log.Tracef("index: counted %d %s object(s)", count, gvk.Kind)
-	return
-}
-
-func list(i *index, gvk schema.GroupVersionKind, apiTypes bool) ([]runtime.Object, error) {
-	uids := i.objects[gvk]
-	list := make([]runtime.Object, 0, len(uids))
-
-	log.Tracef("index: listing %s objects, meta: %t", gvk, apiTypes)
-	for _, obj := range uids {
-		loadFunc := obj.loadFull
-		if apiTypes {
-			loadFunc = obj.loadAPI
-		}
-
-		if result, err := loadFunc(); err != nil {
-			return nil, err
-		} else {
-			list = append(list, result)
-		}
-	}
-
-	return list, nil
-}
-
-func (i *index) list(gvk schema.GroupVersionKind) ([]runtime.Object, error) {
-	return list(i, gvk, false)
-}
-
-func (i *index) listMeta(gvk schema.GroupVersionKind) ([]runtime.Object, error) {
-	return list(i, gvk, true)
-}
-*/
diff --git a/pkg/storage/cache/object.go b/pkg/storage/cache/object.go
deleted file mode 100644
index c0e807c..0000000
--- a/pkg/storage/cache/object.go
+++ /dev/null
@@ -1,96 +0,0 @@
-package cache
-
-/*
-
-TODO: Revisit if we need this file/package in the future.
-
-import (
-	log "github.com/sirupsen/logrus"
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/storage"
-)
-
-type cacheObject struct {
-	storage  storage.Storage
-	object   runtime.Object
-	checksum string
-	apiType  bool
-}
-
-func newCacheObject(s storage.Storage, object runtime.Object, apiType bool) (c *cacheObject, err error) {
-	c = &cacheObject{
-		storage: s,
-		object:  object,
-		apiType: apiType,
-	}
-
-	if c.checksum, err = s.Checksum(c.object.GroupVersionKind(), c.object.GetUID()); err != nil {
-		c = nil
-	}
-
-	return
-}
-
-// loadFull returns the full Object, loading it only if it hasn't been cached before or the checksum has changed
-func (c *cacheObject) loadFull() (runtime.Object, error) {
-	var checksum string
-	reload := c.apiType
-
-	if !reload {
-		if chk, err := c.storage.Checksum(c.object.GroupVersionKind(), c.object.GetUID()); err != nil {
-			return nil, err
-		} else if chk != c.checksum {
-			log.Tracef("cacheObject: %q invalidated, checksum mismatch: %q -> %q", c.object.GetName(), c.checksum, chk)
-			checksum = chk
-			reload = true
-		} else {
-			log.Tracef("cacheObject: %q checksum: %q", c.object.GetName(), c.checksum)
-		}
-	}
-
-	if reload {
-		log.Tracef("cacheObject: full load triggered for %q", c.object.GetName())
-		obj, err := c.storage.Get(c.object.GroupVersionKind(), c.object.GetUID())
-		if err != nil {
-			return nil, err
-		}
-
-		// Only apply the change after a successful Get
-		c.object = obj
-		c.apiType = false
-
-		if len(checksum) > 0 {
-			c.checksum = checksum
-		}
-	}
-
-	return c.object, nil
-}
-
-// loadAPI returns the APIType of the Object, loading it only if the checksum has changed
-func (c *cacheObject) loadAPI() (runtime.Object, error) {
-	if chk, err := c.storage.Checksum(c.object.GroupVersionKind(), c.object.GetUID()); err != nil {
-		return nil, err
-	} else if chk != c.checksum {
-		log.Tracef("cacheObject: %q invalidated, checksum mismatch: %q -> %q", c.object.GetName(), c.checksum, chk)
-		log.Tracef("cacheObject: API load triggered for %q", c.object.GetName())
-		obj, err := c.storage.GetMeta(c.object.GroupVersionKind(), c.object.GetUID())
-		if err != nil {
-			return nil, err
-		}
-
-		// Only apply the change after a successful GetMeta
-		c.object = obj
-		c.checksum = chk
-		c.apiType = true
-	} else {
-		log.Tracef("cacheObject: %q checksum: %q", c.object.GetName(), c.checksum)
-	}
-
-	if c.apiType {
-		return c.object, nil
-	}
-
-	return runtime.PartialObjectFrom(c.object), nil
-}
-*/
diff --git a/pkg/storage/client/client.go b/pkg/storage/client/client.go
new file mode 100644
index 0000000..9c216a0
--- /dev/null
+++ b/pkg/storage/client/client.go
@@ -0,0 +1,315 @@
+package client
+
+import (
+	"context"
+	"errors"
+	"fmt"
+
+	"github.com/weaveworks/libgitops/pkg/filter"
+	"github.com/weaveworks/libgitops/pkg/serializer"
+	"github.com/weaveworks/libgitops/pkg/storage/backend"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	patchutil "github.com/weaveworks/libgitops/pkg/util/patch"
+	syncutil "github.com/weaveworks/libgitops/pkg/util/sync"
+	"k8s.io/apimachinery/pkg/api/meta"
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
+	kruntime "k8s.io/apimachinery/pkg/runtime"
+	utilerrs "k8s.io/apimachinery/pkg/util/errors"
+	"k8s.io/apimachinery/pkg/util/sets"
+	"sigs.k8s.io/controller-runtime/pkg/client"
+)
+
+// TODO: Pass an ObjectID that contains all PartialObjectMetadata info for "downstream" consumers
+// that can make use of it by "casting up".
+
+var (
+	// ErrUnsupportedPatchType is returned when an unsupported patch type is used
+	ErrUnsupportedPatchType = errors.New("unsupported patch type")
+)
+
+type Reader interface {
+	client.Reader
+	BackendReader() backend.Reader
+}
+
+type Writer interface {
+	client.Writer
+	BackendWriter() backend.Writer
+}
+
+type StatusClient interface {
+	client.StatusClient
+	BackendStatusWriter() backend.StatusWriter
+}
+
+// Client is an interface for persisting and retrieving API objects to/from a backend
+// One Client instance handles all different Kinds of Objects
+type Client interface {
+	Reader
+	Writer
+	// TODO: StatusClient
+	//client.Client
+}
+
+// NewGeneric constructs a new Generic client
+// TODO: Construct the default patcher from the given scheme, make patcher an opt instead
+func NewGeneric(backend backend.Backend, patcher serializer.Patcher) (*Generic, error) {
+	if backend == nil {
+		return nil, fmt.Errorf("backend is mandatory")
+	}
+	return &Generic{backend, patcher}, nil
+}
+
+// Generic implements the Client interface
+type Generic struct {
+	backend backend.Backend
+	patcher serializer.Patcher
+}
+
+var _ Client = &Generic{}
+
+func (c *Generic) Backend() backend.Backend      { return c.backend }
+func (c *Generic) BackendReader() backend.Reader { return c.backend }
+func (c *Generic) BackendWriter() backend.Writer { return c.backend }
+
+// Get returns a new Object for the resource at the specified kind/uid path, based on the file content.
+// In order to only extract the metadata of this object, pass in a *metav1.PartialObjectMetadata
+func (c *Generic) Get(ctx context.Context, key core.ObjectKey, obj core.Object) error {
+	obj.SetName(key.Name)
+	obj.SetNamespace(key.Namespace)
+
+	return c.backend.Get(ctx, obj)
+}
+
+// List lists Objects for the specific kind. Optionally, filters can be applied (see the filter package
+// for more information, e.g. filter.NameFilter{} and filter.UIDFilter{})
+// You can also pass in an *unstructured.UnstructuredList to get an unknown type's data or
+// *metav1.PartialObjectMetadataList to just get the metadata of all objects of the specified gvk.
+// If you do specify either an *unstructured.UnstructuredList or *metav1.PartialObjectMetadataList,
+// you need to populate TypeMeta with the GVK you want back.
+// TODO: Check if this works with metav1.List{}
+// TODO: Create constructors for the different kinds of lists?
+func (c *Generic) List(ctx context.Context, list core.ObjectList, opts ...client.ListOption) error {
+	// This call will verify that list actually is a List type.
+	gvk, err := serializer.GVKForList(list, c.Backend().Scheme())
+	if err != nil {
+		return err
+	}
+	// This applies both upstream and custom options
+	listOpts := (&ListOptions{}).ApplyOptions(opts)
+
+	// Get namespacing info
+	gk := gvk.GroupKind()
+	namespaced, err := c.Backend().Storage().Namespacer().IsNamespaced(gk)
+	if err != nil {
+		return err
+	}
+
+	// By default, only search the given namespace. It is fully valid for this to be an
+	// empty string: it is the only
+	namespaces := sets.NewString(listOpts.Namespace)
+	// However, if the GroupKind is namespaced, and the given "filter namespace" in list
+	// options is empty, it means that one should list all namespaces
+	if namespaced && listOpts.Namespace == "" {
+		namespaces, err = c.Backend().ListNamespaces(ctx, gk)
+		if err != nil {
+			return err
+		}
+	} else if !namespaced && listOpts.Namespace != "" {
+		return errors.New("invalid namespace option: cannot filter namespace for root-spaced object")
+	}
+
+	allIDs := []core.UnversionedObjectID{}
+	for ns := range namespaces {
+		ids, err := c.Backend().ListObjectIDs(ctx, gk, ns)
+		if err != nil {
+			return err
+		}
+		allIDs = append(allIDs, ids...)
+	}
+
+	// Populate objs through the given (non-buffered) channel
+	ch := make(chan core.Object)
+	objs := make([]kruntime.Object, 0, len(allIDs))
+
+	// How should the object be created?
+	createFunc := createObject(gvk, c.Backend().Scheme())
+	if serializer.IsPartialObjectList(list) {
+		createFunc = createPartialObject(gvk)
+	} else if serializer.IsUnstructuredList(list) {
+		createFunc = createUnstructuredObject(gvk)
+	}
+	// Temporary processing goroutine; execution starts instantly
+	m := syncutil.RunMonitor(func() error {
+		return c.processKeys(ctx, allIDs, &listOpts.FilterOptions, createFunc, ch)
+	})
+
+	for o := range ch {
+		objs = append(objs, o)
+	}
+
+	if err := m.Wait(); err != nil {
+		return err
+	}
+
+	// Populate the List's Items field with the objects returned
+	return meta.SetList(list, objs)
+}
+
+func (c *Generic) Create(ctx context.Context, obj core.Object, _ ...client.CreateOption) error {
+	return c.backend.Create(ctx, obj)
+}
+
+func (c *Generic) Update(ctx context.Context, obj core.Object, _ ...client.UpdateOption) error {
+	return c.backend.Update(ctx, obj)
+}
+
+// Patch performs a strategic merge patch on the object with the given UID, using the byte-encoded patch given
+func (c *Generic) Patch(ctx context.Context, obj core.Object, patch core.Patch, _ ...client.PatchOption) error {
+	// Fail-fast: We must never save metadata-only structs
+	if serializer.IsPartialObject(obj) {
+		return backend.ErrCannotSaveMetadata
+	}
+
+	// Acquire the patch data from the "desired state" object given now, i.e. in MergeFrom{}
+	// TODO: Shall we require GVK to be present here using a meta interpreter?
+	patchJSON, err := patch.Data(obj)
+	if err != nil {
+		return err
+	}
+
+	// Load the current latest state into obj temporarily, before patching it
+	// This also validates the GVK, name and namespace.
+	if err := c.backend.Get(ctx, obj); err != nil {
+		return err
+	}
+
+	// Get the right BytePatcher for this patch type
+	// TODO: Make this return an error
+	bytePatcher := patchutil.BytePatcherForType(patch.Type())
+	if bytePatcher == nil {
+		return fmt.Errorf("patch type not supported: %s", patch.Type())
+	}
+
+	// Apply the patch into the object using the given byte patcher
+	if unstruct, ok := obj.(kruntime.Unstructured); ok {
+		// TODO: Provide an option for the schema
+		err = c.patcher.ApplyOnUnstructured(bytePatcher, patchJSON, unstruct, nil)
+	} else {
+		err = c.patcher.ApplyOnStruct(bytePatcher, patchJSON, obj)
+	}
+	if err != nil {
+		return err
+	}
+
+	// Perform an update internally, similar to what .Update would yield
+	// TODO: Maybe write to the Storage conditionally? using DryRun all
+	return c.Update(ctx, obj)
+}
+
+// Delete removes an Object from the backend
+// PartialObjectMetadata should work here.
+func (c *Generic) Delete(ctx context.Context, obj core.Object, _ ...client.DeleteOption) error {
+	return c.backend.Delete(ctx, obj)
+}
+
+// DeleteAllOf deletes all matched resources by first doing a List() operation on the given GVK of
+// obj (obj is not used for anything else) and the given filters in opts. Only the Partial Meta
+func (c *Generic) DeleteAllOf(ctx context.Context, obj core.Object, opts ...client.DeleteAllOfOption) error {
+	// This applies both upstream and custom options, and propagates the options correctly to both
+	// List() and Delete()
+	customDeleteAllOpts := (&DeleteAllOfOptions{}).ApplyOptions(opts)
+
+	// Get the GVK of the object
+	gvk, err := serializer.GVKForObject(c.Backend().Scheme(), obj)
+	if err != nil {
+		return err
+	}
+
+	// List all matched objects for the given ListOptions, and GVK.
+	// UnstructuredList is used here so that we can use filters that operate on fields
+	list := &unstructured.UnstructuredList{}
+	list.SetGroupVersionKind(gvk)
+	if err := c.List(ctx, list, customDeleteAllOpts); err != nil {
+		return err
+	}
+
+	// Loop through all of the matched items, and Delete them one-by-one
+	for i := range list.Items {
+		if err := c.Delete(ctx, &list.Items[i], customDeleteAllOpts); err != nil {
+			return err
+		}
+	}
+	return nil
+}
+
+// Scheme returns the scheme this client is using.
+func (c *Generic) Scheme() *kruntime.Scheme {
+	return c.backend.Scheme()
+}
+
+// RESTMapper returns the rest this client is using. For now, this returns nil, so don't use.
+func (c *Generic) RESTMapper() meta.RESTMapper {
+	return nil
+}
+
+type newObjectFunc func() (core.Object, error)
+
+func createObject(gvk core.GroupVersionKind, scheme *kruntime.Scheme) newObjectFunc {
+	return func() (core.Object, error) {
+		return NewObjectForGVK(gvk, scheme)
+	}
+}
+
+func createPartialObject(gvk core.GroupVersionKind) newObjectFunc {
+	return func() (core.Object, error) {
+		obj := &metav1.PartialObjectMetadata{}
+		obj.SetGroupVersionKind(gvk)
+		return obj, nil
+	}
+}
+
+func createUnstructuredObject(gvk core.GroupVersionKind) newObjectFunc {
+	return func() (core.Object, error) {
+		obj := &unstructured.Unstructured{}
+		obj.SetGroupVersionKind(gvk)
+		return obj, nil
+	}
+}
+
+func (c *Generic) processKeys(ctx context.Context, ids []core.UnversionedObjectID, filterOpts *filter.FilterOptions, fn newObjectFunc, output chan core.Object) error {
+	goroutines := []func() error{}
+	for _, id := range ids {
+		goroutines = append(goroutines, c.processKey(ctx, id, filterOpts, fn, output))
+	}
+
+	defer close(output)
+
+	return utilerrs.AggregateGoroutines(goroutines...)
+}
+
+func (c *Generic) processKey(ctx context.Context, id core.UnversionedObjectID, filterOpts *filter.FilterOptions, fn newObjectFunc, output chan core.Object) func() error {
+	return func() error {
+		// Create a new object, and decode into it using Get
+		obj, err := fn()
+		if err != nil {
+			return err
+		}
+
+		if err := c.Get(ctx, id.ObjectKey(), obj); err != nil {
+			return err
+		}
+
+		// Match the object against the filters
+		matched, err := filterOpts.Match(obj)
+		if err != nil {
+			return err
+		}
+		if matched {
+			output <- obj
+		}
+
+		return nil
+	}
+}
diff --git a/pkg/storage/client/options.go b/pkg/storage/client/options.go
new file mode 100644
index 0000000..7fa8f8e
--- /dev/null
+++ b/pkg/storage/client/options.go
@@ -0,0 +1,75 @@
+package client
+
+import (
+	"github.com/weaveworks/libgitops/pkg/filter"
+	"sigs.k8s.io/controller-runtime/pkg/client"
+)
+
+type ListOption interface {
+	client.ListOption
+	filter.FilterOption
+}
+
+type ListOptions struct {
+	client.ListOptions
+	filter.FilterOptions
+}
+
+var _ ListOption = &ListOptions{}
+
+func (o *ListOptions) ApplyToList(target *client.ListOptions) {
+	o.ListOptions.ApplyToList(target)
+}
+
+func (o *ListOptions) ApplyToFilterOptions(target *filter.FilterOptions) {
+	o.FilterOptions.ApplyToFilterOptions(target)
+}
+
+func (o *ListOptions) ApplyOptions(opts []client.ListOption) *ListOptions {
+	// Apply the "normal" ListOptions
+	o.ListOptions.ApplyOptions(opts)
+	// Apply all FilterOptions, if they implement that interface
+	for _, opt := range opts {
+		o.FilterOptions.ApplyOption(opt)
+	}
+
+	// If listOpts.Namespace was given, add it to the list of ObjectFilters
+	if len(o.Namespace) != 0 {
+		o.ObjectFilters = append(o.ObjectFilters, filter.NamespaceFilter{Namespace: o.Namespace})
+	}
+	// If listOpts.LabelSelector was given, add it to the list of ObjectFilters
+	if o.LabelSelector != nil {
+		o.ObjectFilters = append(o.ObjectFilters, filter.LabelsFilter{LabelSelector: o.LabelSelector})
+	}
+
+	return o
+}
+
+type DeleteAllOfOption interface {
+	ListOption
+	client.DeleteAllOfOption
+}
+
+type DeleteAllOfOptions struct {
+	ListOptions
+	client.DeleteOptions
+}
+
+var _ DeleteAllOfOption = &DeleteAllOfOptions{}
+
+func (o *DeleteAllOfOptions) ApplyToDeleteAllOf(target *client.DeleteAllOfOptions) {
+	o.DeleteOptions.ApplyToDelete(&target.DeleteOptions)
+}
+
+func (o *DeleteAllOfOptions) ApplyOptions(opts []client.DeleteAllOfOption) *DeleteAllOfOptions {
+	// Cannot directly apply to o, hence, create a temporary object to which upstream opts are applied
+	do := (&client.DeleteAllOfOptions{}).ApplyOptions(opts)
+	o.ListOptions.ListOptions = do.ListOptions
+	o.DeleteOptions = do.DeleteOptions
+
+	// Apply all FilterOptions, if they implement that interface
+	for _, opt := range opts {
+		o.FilterOptions.ApplyOption(opt)
+	}
+	return o
+}
diff --git a/pkg/storage/client/transactional/client.go b/pkg/storage/client/transactional/client.go
new file mode 100644
index 0000000..1108c1d
--- /dev/null
+++ b/pkg/storage/client/transactional/client.go
@@ -0,0 +1,330 @@
+package transactional
+
+import (
+	"context"
+	"crypto/rand"
+	"encoding/hex"
+	"fmt"
+	"strings"
+	"sync"
+	"sync/atomic"
+
+	"github.com/sirupsen/logrus"
+	"github.com/weaveworks/libgitops/pkg/storage/backend"
+	"github.com/weaveworks/libgitops/pkg/storage/client"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	utilerrs "k8s.io/apimachinery/pkg/util/errors"
+)
+
+var _ Client = &Generic{}
+
+func NewGeneric(c client.Client, manager BranchManager, merger BranchMerger) (Client, error) {
+	if c == nil {
+		return nil, fmt.Errorf("%w: c is required", core.ErrInvalidParameter)
+	}
+	if manager == nil {
+		return nil, fmt.Errorf("%w: manager is required", core.ErrInvalidParameter)
+	}
+	return &Generic{
+		c:       c,
+		txs:     make(map[string]*txLock),
+		txsMu:   &sync.Mutex{},
+		manager: manager,
+		merger:  merger,
+	}, nil
+}
+
+type Generic struct {
+	c client.Client
+
+	txs   map[string]*txLock
+	txsMu *sync.Mutex
+
+	// +optional
+	merger BranchMerger
+	// +required
+	manager BranchManager
+}
+
+type txLock struct {
+	mu   *sync.RWMutex
+	mode TxMode
+	// active == 1 means "transaction active, mu is locked for writing"
+	// active == 0 means "transaction has stopped, mu has been unlocked"
+	active uint32
+}
+
+func (c *Generic) Get(ctx context.Context, key core.ObjectKey, obj core.Object) error {
+	return c.lockForReading(ctx, func() error {
+		return c.c.Get(ctx, key, obj)
+	})
+}
+
+func (c *Generic) List(ctx context.Context, list core.ObjectList, opts ...core.ListOption) error {
+	return c.lockForReading(ctx, func() error {
+		return c.c.List(ctx, list, opts...)
+	})
+}
+
+func (c *Generic) lockForReading(ctx context.Context, operation func() error) error {
+	ref := core.GetVersionRef(ctx)
+	if !ref.IsWritable() {
+		// Never block reads for read-only VersionRefs. We know nobody can change
+		// them during the read operation, so they should be race condition-free.
+		return operation()
+	}
+	// If the VersionRef is writable; treat it as a branch and lock it to avoid
+	// race conditions.
+	return c.lockAndReadBranch(ref.String(), operation)
+}
+
+func (c *Generic) lockAndReadBranch(branch string, callback func() error) error {
+	// Use c.txsMu to guard reads and writes to the c.txs map
+	c.txsMu.Lock()
+	// Check if information about a transaction on this branch exists.
+	txState, ok := c.txs[branch]
+	if !ok {
+		// grow the txs map by one
+		c.txs[branch] = &txLock{
+			mu: &sync.RWMutex{},
+		}
+		txState = c.txs[branch]
+	}
+	c.txsMu.Unlock()
+
+	// In the atomic mode, we lock the txLock during the read,
+	// so no new transactions can be started while the read
+	// operation goes on. In non-atomic modes, reads aren't locked,
+	// instead it is assumed that downstream implementations just
+	// read the latest commit on the given branch.
+	if txState.mode == TxModeAtomic {
+		txState.mu.RLock()
+	}
+	err := callback()
+	if txState.mode == TxModeAtomic {
+		txState.mu.RUnlock()
+	}
+	return err
+}
+
+func (c *Generic) initTx(ctx context.Context, info TxInfo) (context.Context, txFunc) {
+	// Aquire the tx-specific lock
+	c.txsMu.Lock()
+	txState, ok := c.txs[info.Head]
+	if !ok {
+		// grow the txs map by one
+		c.txs[info.Head] = &txLock{
+			mu: &sync.RWMutex{},
+		}
+		txState = c.txs[info.Head]
+	}
+	txState.mode = info.Options.Mode
+	c.txsMu.Unlock()
+
+	// Wait for all reads to complete (in the case of the atomic more),
+	// and then lock for writing. For non-atomic mode this uses the mutex
+	// as it is modifying txState, and two transactions must not run at
+	// the same time for the same branch.
+	//
+	// Always lock mu when a transaction is running on this branch,
+	// regardless of mode. If atomic mode is enabled, this also waits
+	// on any reads happening at this moment. For all modes, this ensures
+	// transactions happen in order.
+	txState.mu.Lock()
+	txState.active = 1 // set tx state to "active"
+
+	// Create a child context with a timeout
+	dlCtx, cleanupTimeout := context.WithTimeout(ctx, info.Options.Timeout)
+
+	// This function cleans up the transaction, and unlocks the tx muted
+	cleanupFunc := func() error {
+		// Cleanup after the transaction
+		if err := c.cleanupAfterTx(ctx, &info); err != nil {
+			return fmt.Errorf("Failed to cleanup branch %s after tx: %v", info.Head, err)
+		}
+		// Unlock the mutex so new transactions can take place on this branch
+		txState.mu.Unlock()
+		return nil
+	}
+
+	// Start waiting for the cancellation of the deadline context.
+	go func() {
+		// Wait for the context to either timeout or be cancelled
+		<-dlCtx.Done()
+		// This guard makes sure the cleanup function runs exactly
+		// once, regardless of transaction end cause.
+		if atomic.CompareAndSwapUint32(&txState.active, 1, 0) {
+			if err := cleanupFunc(); err != nil {
+				logrus.Errorf("Failed to cleanup after tx timeout: %v", err)
+			}
+		}
+	}()
+
+	abortFunc := func() error {
+		// The transaction ended; the caller is either Abort() or
+		// at the end of a successful transaction. The cause of
+		// Abort() happening can also be a context cancellation.
+		// If the parent context was cancelled or timed out; this
+		// function and the above function race to set active => 0
+		// Regardless, due to the atomic nature of the operation,
+		// cleanupFunc() will only be run twice.
+		if atomic.CompareAndSwapUint32(&txState.active, 1, 0) {
+			// We can now stop the timeout timer
+			cleanupTimeout()
+			// Clean up the transaction
+			return cleanupFunc()
+		}
+		return nil
+	}
+
+	return dlCtx, abortFunc
+}
+
+func (c *Generic) cleanupAfterTx(ctx context.Context, info *TxInfo) error {
+	// Always both clean the branch, and run post-tx tasks
+	return utilerrs.NewAggregate([]error{
+		c.manager.ResetToCleanBranch(ctx, info.Base),
+		// TODO: should this be in its own goroutine to switch back to main
+		// ASAP?
+		c.manager.TransactionHookChain().PostTransactionHook(ctx, *info),
+	})
+}
+
+func (c *Generic) BackendReader() backend.Reader {
+	return c.c.BackendReader()
+}
+
+func (c *Generic) BranchMerger() BranchMerger {
+	return c.merger
+}
+
+func (c *Generic) BranchManager() BranchManager {
+	return c.manager
+}
+
+func (c *Generic) Transaction(ctx context.Context, opts ...TxOption) Tx {
+	tx, err := c.transaction(ctx, opts...)
+	if err != nil {
+		panic(err)
+	}
+	return tx
+}
+
+func (c *Generic) BranchTransaction(ctx context.Context, headBranch string, opts ...TxOption) BranchTx {
+	tx, err := c.branchTransaction(ctx, headBranch, opts...)
+	if err != nil {
+		panic(err)
+	}
+	return tx
+}
+
+func (c *Generic) validateCtx(ctx context.Context) (core.VersionRef, error) {
+	// Check so versionref is writable
+	ref := core.GetVersionRef(ctx)
+	if !ref.IsWritable() {
+		return nil, fmt.Errorf("must not give a writable VersionRef to (Branch)Transaction()")
+	}
+	// Just return its
+	return ref, nil
+}
+
+func (c *Generic) transaction(ctx context.Context, opts ...TxOption) (Tx, error) {
+	// Validate the versionref from the context
+	ref, err := c.validateCtx(ctx)
+	if err != nil {
+		return nil, err
+	}
+
+	// Parse options
+	o := defaultTxOptions().ApplyOptions(opts)
+
+	branch := ref.String()
+	info := TxInfo{
+		Base:    branch,
+		Head:    branch,
+		Options: *o,
+	}
+	// Initialize the transaction
+	ctxWithDeadline, cleanupFunc := c.initTx(ctx, info)
+
+	// Run pre-tx checks
+	err = c.manager.TransactionHookChain().PreTransactionHook(ctxWithDeadline, info)
+
+	return &txImpl{
+		&txCommon{
+			err:         err,
+			c:           c.c,
+			manager:     c.manager,
+			ctx:         ctxWithDeadline,
+			info:        info,
+			cleanupFunc: cleanupFunc,
+		},
+	}, nil
+}
+
+func (c *Generic) branchTransaction(ctx context.Context, headBranch string, opts ...TxOption) (BranchTx, error) {
+	// Validate the versionref from the context
+	ref, err := c.validateCtx(ctx)
+	if err != nil {
+		return nil, err
+	}
+	baseBranch := ref.String()
+
+	// Append random bytes to the end of the head branch if it ends with a dash
+	if strings.HasSuffix(headBranch, "-") {
+		suffix, err := randomSHA(4)
+		if err != nil {
+			return nil, err
+		}
+		headBranch += suffix
+	}
+
+	// Validate that the base and head branches are distinct
+	if baseBranch == headBranch {
+		return nil, fmt.Errorf("head and target branches must not be the same")
+	}
+
+	logrus.Debugf("Base branch: %q. Head branch: %q.", baseBranch, headBranch)
+
+	// Parse options
+	o := defaultTxOptions().ApplyOptions(opts)
+
+	info := TxInfo{
+		Base:    baseBranch,
+		Head:    headBranch,
+		Options: *o,
+	}
+
+	// Register the head branch with the context
+	ctxWithHeadBranch := core.WithVersionRef(ctx, core.NewBranchRef(headBranch))
+	// Initialize the transaction
+	ctxWithDeadline, cleanupFunc := c.initTx(ctxWithHeadBranch, info)
+
+	// Run pre-tx checks and create the new branch
+	err = utilerrs.NewAggregate([]error{
+		c.manager.TransactionHookChain().PreTransactionHook(ctxWithDeadline, info),
+		c.manager.CreateBranch(ctxWithDeadline, headBranch),
+	})
+
+	return &txBranchImpl{
+		txCommon: &txCommon{
+			err:         err,
+			c:           c.c,
+			manager:     c.manager,
+			ctx:         ctxWithDeadline,
+			info:        info,
+			cleanupFunc: cleanupFunc,
+		},
+		merger: c.merger,
+	}, nil
+}
+
+// randomSHA returns a hex-encoded string from {byteLen} random bytes.
+func randomSHA(byteLen int) (string, error) {
+	b := make([]byte, byteLen)
+	_, err := rand.Read(b)
+	if err != nil {
+		return "", err
+	}
+	return hex.EncodeToString(b), nil
+}
diff --git a/pkg/storage/client/transactional/commit.go b/pkg/storage/client/transactional/commit.go
new file mode 100644
index 0000000..eeb5e9f
--- /dev/null
+++ b/pkg/storage/client/transactional/commit.go
@@ -0,0 +1,126 @@
+package transactional
+
+import (
+	"fmt"
+
+	"github.com/fluxcd/go-git-providers/validation"
+)
+
+// Commit describes a result of a transaction.
+type Commit interface {
+	// GetAuthor describes the author of this commit.
+	// +required
+	GetAuthor() CommitAuthor
+	// GetMessage describes the change in this commit.
+	// +required
+	GetMessage() CommitMessage
+	// Validate validates that all required fields are set, and given data is valid.
+	Validate() error
+}
+
+type CommitAuthor interface {
+	// GetName describes the author's name (e.g. as per git config)
+	// +required
+	GetName() string
+	// GetEmail describes the author's email (e.g. as per git config).
+	// It is optional generally, but might be required by some specific
+	// implementations.
+	// +optional
+	GetEmail() string
+	// The String() method must return a (ideally both human- and machine-
+	// readable) concatenated string including the name and email (if
+	// applicable) of the author.
+	fmt.Stringer
+}
+
+type CommitMessage interface {
+	// GetTitle describes the change concisely, so it can be used e.g. as
+	// a commit message or PR title. Certain implementations might enforce
+	// character limits on this string.
+	// +required
+	GetTitle() string
+	// GetDescription contains optional extra, more detailed information
+	// about the change.
+	// +optional
+	GetDescription() string
+	// The String() method must return a (ideally both human- and machine-
+	// readable) concatenated string including the title and description
+	// (if applicable) of the author.
+	fmt.Stringer
+}
+
+// GenericCommitResult implements Commit.
+var _ Commit = GenericCommit{}
+
+// GenericCommit implements Commit.
+type GenericCommit struct {
+	// GetAuthor describes the author of this commit.
+	// +required
+	Author CommitAuthor
+	// GetMessage describes the change in this commit.
+	// +required
+	Message CommitMessage
+}
+
+func (r GenericCommit) GetAuthor() CommitAuthor   { return r.Author }
+func (r GenericCommit) GetMessage() CommitMessage { return r.Message }
+
+func (r GenericCommit) Validate() error {
+	v := validation.New("GenericCommit")
+	if len(r.Author.GetName()) == 0 {
+		v.Required("Author.GetName")
+	}
+	if len(r.Message.GetTitle()) == 0 {
+		v.Required("Message.GetTitle")
+	}
+	return v.Error()
+}
+
+// GenericCommitAuthor implements CommitAuthor.
+var _ CommitAuthor = GenericCommitAuthor{}
+
+// GenericCommit implements Commit.
+type GenericCommitAuthor struct {
+	// Name describes the author's name (as per git config)
+	// +required
+	Name string
+	// Email describes the author's email (as per git config)
+	// +optional
+	Email string
+}
+
+func (r GenericCommitAuthor) GetName() string  { return r.Name }
+func (r GenericCommitAuthor) GetEmail() string { return r.Email }
+
+func (r GenericCommitAuthor) String() string {
+	if len(r.Email) != 0 {
+		return fmt.Sprintf("%s <%s>", r.Name, r.Email)
+	}
+	return r.Name
+}
+
+// GenericCommitMessage implements CommitMessage.
+var _ CommitMessage = GenericCommitMessage{}
+
+// GenericCommitMessage implements CommitMessage.
+type GenericCommitMessage struct {
+	// Title describes the change concisely, so it can be used e.g. as
+	// a commit message or PR title. Certain implementations might enforce
+	// character limits on this string.
+	// +required
+	Title string
+	// Description contains optional extra, more detailed information
+	// about the change.
+	// +optional
+	Description string
+}
+
+func (r GenericCommitMessage) GetTitle() string       { return r.Title }
+func (r GenericCommitMessage) GetDescription() string { return r.Description }
+
+func (r GenericCommitMessage) String() string {
+	if len(r.Description) != 0 {
+		return fmt.Sprintf("%s\n\n%s", r.Title, r.Description)
+	}
+	return r.Title
+}
diff --git a/pkg/storage/client/transactional/distributed/client.go b/pkg/storage/client/transactional/distributed/client.go
new file mode 100644
index 0000000..665c6fd
--- /dev/null
+++ b/pkg/storage/client/transactional/distributed/client.go
@@ -0,0 +1,313 @@
+package distributed
+
+import (
+	"context"
+	"fmt"
+	"sync"
+	"time"
+
+	"github.com/sirupsen/logrus"
+	"github.com/weaveworks/libgitops/pkg/storage/client/transactional"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"k8s.io/apimachinery/pkg/util/wait"
+)
+
+// NewClient creates a new distributed Client using the given underlying transactional Client,
+// remote, and options that configure how the Client should respond to network partitions.
+func NewClient(c transactional.Client, remote Remote, opts ...ClientOption) (*Generic, error) {
+	if c == nil {
+		return nil, fmt.Errorf("%w: c is mandatory", core.ErrInvalidParameter)
+	}
+	if remote == nil {
+		return nil, fmt.Errorf("%w: remote is mandatory", core.ErrInvalidParameter)
+	}
+
+	o := defaultOptions().ApplyOptions(opts)
+
+	g := &Generic{
+		Client:        c,
+		remote:        remote,
+		opts:          *o,
+		branchLocks:   make(map[string]*branchLock),
+		branchLocksMu: &sync.Mutex{},
+	}
+
+	// Register ourselves to hook into the branch manager's operations
+	c.BranchManager().CommitHookChain().Register(g)
+	c.BranchManager().TransactionHookChain().Register(g)
+
+	return g, nil
+}
+
+type Generic struct {
+	transactional.Client
+	remote Remote
+	opts   ClientOptions
+	// branchLocks maps a given branch to a given lock the state of the branch
+	branchLocks map[string]*branchLock
+	// branchLocksMu guards branchLocks
+	branchLocksMu *sync.Mutex
+}
+
+type branchLock struct {
+	// mu should be write-locked whenever the branch is actively running any
+	// function from the remote
+	mu *sync.RWMutex
+	// lastPull is guarded by mu, before reading, one should RLock mu
+	lastPull time.Time
+}
+
+func (c *Generic) Get(ctx context.Context, key core.ObjectKey, obj core.Object) error {
+	return c.readWhenPossible(ctx, func() error {
+		return c.Client.Get(ctx, key, obj)
+	})
+}
+
+func (c *Generic) List(ctx context.Context, list core.ObjectList, opts ...core.ListOption) error {
+	return c.readWhenPossible(ctx, func() error {
+		return c.Client.List(ctx, list, opts...)
+	})
+}
+
+func (c *Generic) readWhenPossible(ctx context.Context, operation func() error) error {
+	ref := core.GetVersionRef(ctx)
+	// If the ref is not writable, we don't have to worry about race conditions
+	if !ref.IsWritable() {
+		return operation()
+	}
+	branch := ref.String()
+
+	// Check if we need to do a pull before
+	if c.needsResync(branch, c.opts.CacheValidDuration) {
+		// Try to pull the remote branch. If it fails, use returnErr to figure out if
+		// this (depending on the configured PACELC mode) is a critical error, or if we
+		// should continue with the read
+		if err := c.pull(ctx, branch); err != nil {
+			if criticalErr := c.returnErr(err); criticalErr != nil {
+				return criticalErr
+			}
+		}
+	}
+	// Do the read operation
+	return operation()
+}
+
+func (c *Generic) getBranchLockInfo(branch string) *branchLock {
+	c.branchLocksMu.Lock()
+	defer c.branchLocksMu.Unlock()
+
+	// Check if there exists a lock for that branch
+	info, ok := c.branchLocks[branch]
+	if ok {
+		return info
+	}
+	// Write to the branchLocks map
+	c.branchLocks[branch] = &branchLock{
+		mu: &sync.RWMutex{},
+	}
+	return c.branchLocks[branch]
+}
+
+func (c *Generic) needsResync(branch string, d time.Duration) bool {
+	lck := c.getBranchLockInfo(branch)
+	// Lock while reading the last resync time
+	lck.mu.RLock()
+	defer lck.mu.RUnlock()
+	// Resync if there has been no sync so far, or if the last resync was too long ago
+	return lck.lastPull.IsZero() || time.Since(lck.lastPull) > d
+}
+
+// StartResyncLoop starts a resync loop for the given branches for
+// the given interval.
+//
+// resyncCacheInterval specifies the interval for which resyncs
+// (remote Pulls) should be run in the background. The duration must
+// be positive, and non-zero.
+//
+// resyncBranches specifies what branches to resync. The default is
+// []string{""}, i.e. only the "default" branch.
+//
+// ctx should be used to cancel the loop, if needed.
+//
+// While it is technically possible to start many of these resync
+// loops, it is not recommended. Start it once, for all the branches
+// you need. The branches will be pulled synchronously in order. The
+// resync interval is non-sliding, which means that the interval
+// includes the time of the operations.
+func (c *Generic) StartResyncLoop(ctx context.Context, resyncCacheInterval time.Duration, resyncBranches ...string) {
+	// Only start this loop if resyncCacheInterval > 0
+	if resyncCacheInterval <= 0 {
+		logrus.Warn("No need to start the resync loop; resyncCacheInterval <= 0")
+		return
+	}
+	// If unset, only sync the default branch.
+	if resyncBranches == nil {
+		resyncBranches = []string{""}
+	}
+
+	// Start the resync goroutine
+	go c.resyncLoop(ctx, resyncCacheInterval, resyncBranches)
+}
+
+func (c *Generic) resyncLoop(ctx context.Context, resyncCacheInterval time.Duration, resyncBranches []string) {
+	logrus.Debug("Starting the resync loop...")
+
+	wait.NonSlidingUntilWithContext(ctx, func(_ context.Context) {
+
+		for _, branch := range resyncBranches {
+			logrus.Tracef("resyncLoop: Will perform pull operation on branch: %q", branch)
+			// Perform a fetch, pull & checkout of the new revision
+			if err := c.pull(ctx, branch); err != nil {
+				logrus.Errorf("resyncLoop: pull failed with error: %v", err)
+				return
+			}
+		}
+	}, resyncCacheInterval)
+	logrus.Info("Exiting the resync loop...")
+}
+
+func (c *Generic) pull(ctx context.Context, branch string) error {
+	// Need to get the branch-specific lock variable
+	lck := c.getBranchLockInfo(branch)
+	// Write-lock while this operation is in progress
+	lck.mu.Lock()
+	defer lck.mu.Unlock()
+
+	// Create a new context that times out after the given duration
+	pullCtx, cancel := context.WithTimeout(ctx, c.opts.PullTimeout)
+	defer cancel()
+
+	// Make a ctx for the given branch
+	ctxForBranch := core.WithVersionRef(pullCtx, core.NewBranchRef(branch))
+	if err := c.remote.Pull(ctxForBranch); err != nil {
+		return err
+	}
+
+	// Register the timestamp into the lock
+	lck.lastPull = time.Now()
+
+	// All good
+	return nil
+}
+
+func (c *Generic) PreTransactionHook(ctx context.Context, info transactional.TxInfo) error {
+	// We count on ctx having the VersionRef registered for the head branch
+
+	// Lock the branch for writing, if supported by the remote
+	// If the lock fails, we DO NOT try to pull, but just exit (either with err or a nil error,
+	// depending on the configured PACELC mode)
+	// TODO: Can we rely on the timeout being exact enough here?
+	// TODO: How to do this before the branch even exists...?
+	if err := c.lock(ctx, info.Options.Timeout); err != nil {
+		return c.returnErr(err)
+	}
+
+	// Always Pull the _base_ branch before a transaction, to be up-to-date
+	// before creating the new head branch
+	if err := c.pull(ctx, info.Base); err != nil {
+		return c.returnErr(err)
+	}
+
+	// All good
+	return nil
+}
+
+func (c *Generic) PreCommitHook(ctx context.Context, commit transactional.Commit, info transactional.TxInfo) error {
+	return nil // nothing to do here
+}
+
+func (c *Generic) PostCommitHook(ctx context.Context, _ transactional.Commit, _ transactional.TxInfo) error {
+	// Push the branch in the ctx
+	if err := c.push(ctx); err != nil {
+		return c.returnErr(err)
+	}
+	return nil
+}
+
+func (c *Generic) PostTransactionHook(ctx context.Context, info transactional.TxInfo) error {
+	// Unlock the head branch, if supported
+	if err := c.unlock(ctx); err != nil {
+		return c.returnErr(err)
+	}
+
+	return nil
+}
+
+func (c *Generic) Remote() Remote {
+	return c.remote
+}
+
+// note: this must ONLY be called from such functions where it is guaranteed that the
+// ctx contains a branch versionref.
+func (c *Generic) branchFromCtx(ctx context.Context) string {
+	return core.GetVersionRef(ctx).String()
+}
+
+func (c *Generic) returnErr(err error) error {
+	// If RemoteErrorStream isn't defined, just pass the error through
+	if c.opts.RemoteErrorStream == nil {
+		return err
+	}
+	// Non-blocking send to the channel, and no return error
+	go func() {
+		c.opts.RemoteErrorStream <- err
+	}()
+	return nil
+}
+
+func (c *Generic) lock(ctx context.Context, d time.Duration) error {
+	lr, ok := c.remote.(LockableRemote)
+	if !ok {
+		return nil
+	}
+
+	// Need to get the branch-specific lock variable
+	lck := c.getBranchLockInfo(c.branchFromCtx(ctx))
+	// Write-lock while this operation is in progress
+	lck.mu.Lock()
+	defer lck.mu.Unlock()
+
+	// Enforce a timeout
+	lockCtx, cancel := context.WithTimeout(ctx, c.opts.LockTimeout)
+	defer cancel()
+
+	return lr.Lock(lockCtx, d)
+}
+
+func (c *Generic) unlock(ctx context.Context) error {
+	lr, ok := c.remote.(LockableRemote)
+	if !ok {
+		return nil
+	}
+
+	// Need to get the branch-specific lock variable
+	lck := c.getBranchLockInfo(c.branchFromCtx(ctx))
+	// Write-lock while this operation is in progress
+	lck.mu.Lock()
+	defer lck.mu.Unlock()
+
+	// Enforce a timeout
+	unlockCtx, cancel := context.WithTimeout(ctx, c.opts.LockTimeout)
+	defer cancel()
+
+	return lr.Unlock(unlockCtx)
+}
+
+func (c *Generic) push(ctx context.Context) error {
+	// Need to get the branch-specific lock variable
+	lck := c.getBranchLockInfo(c.branchFromCtx(ctx))
+	// Write-lock while this operation is in progress
+	lck.mu.Lock()
+	defer lck.mu.Unlock()
+
+	// Create a new context that times out after the given duration
+	pushCtx, cancel := context.WithTimeout(ctx, c.opts.PushTimeout)
+	defer cancel()
+
+	// Push the head branch using the remote
+	// If the Push fails, don't execute any other later statements
+	if err := c.remote.Push(pushCtx); err != nil {
+		return err
+	}
+	return nil
+}
diff --git a/pkg/storage/client/transactional/distributed/git/git.go b/pkg/storage/client/transactional/distributed/git/git.go
new file mode 100644
index 0000000..53cf157
--- /dev/null
+++ b/pkg/storage/client/transactional/distributed/git/git.go
@@ -0,0 +1,368 @@
+package git
+
+import (
+	"context"
+	"errors"
+	"fmt"
+	"io/ioutil"
+	"os"
+	"sync"
+	"time"
+
+	"github.com/fluxcd/go-git-providers/gitprovider"
+	git "github.com/go-git/go-git/v5"
+	"github.com/go-git/go-git/v5/plumbing"
+	"github.com/go-git/go-git/v5/plumbing/object"
+	log "github.com/sirupsen/logrus"
+	"github.com/weaveworks/libgitops/pkg/storage/client/transactional"
+	"github.com/weaveworks/libgitops/pkg/storage/client/transactional/distributed"
+)
+
+var (
+	// ErrNotStarted happens if you try to operate on the LocalClone before you have started
+	// it with StartCheckoutLoop.
+	ErrNotStarted = errors.New("the LocalClone hasn't been started (and hence, cloned) yet")
+	// ErrCannotWriteToReadOnly happens if you try to do a write operation for a non-authenticated Git repo.
+	ErrCannotWriteToReadOnly = errors.New("the LocalClone is read-only, cannot write")
+)
+
+const (
+	defaultBranch = "master"
+)
+
+// LocalCloneOptions provides options for the LocalClone.
+// TODO: Refactor this into the controller-runtime Options factory pattern.
+type LocalCloneOptions struct {
+	Branch string // default "master"
+
+	// Authentication method. If unspecified, this clone is read-only.
+	AuthMethod AuthMethod
+}
+
+func (o *LocalCloneOptions) Default() {
+	if o.Branch == "" {
+		o.Branch = defaultBranch
+	}
+}
+
+// LocalClone is an implementation of both a Remote, and a BranchManager, for Git.
+var _ transactional.BranchManager = &LocalClone{}
+var _ distributed.Remote = &LocalClone{}
+
+// Create a new Remote and BranchManager implementation using Git. The repo is cloned immediately
+// in the constructor, you can use ctx to enforce a timeout for the clone.
+func NewLocalClone(ctx context.Context, repoRef gitprovider.RepositoryRef, opts LocalCloneOptions) (*LocalClone, error) {
+	log.Info("Initializing the Git repo...")
+
+	// Default the options
+	opts.Default()
+
+	// Create a temporary directory for the clone
+	tmpDir, err := ioutil.TempDir("", "libgitops")
+	if err != nil {
+		return nil, err
+	}
+	log.Debugf("Created temporary directory for the git clone at %q", tmpDir)
+
+	d := &LocalClone{
+		repoRef:     repoRef,
+		opts:        opts,
+		cloneDir:    tmpDir,
+		lock:        &sync.Mutex{},
+		commitHooks: &transactional.MultiCommitHook{},
+		txHooks:     &transactional.MultiTransactionHook{},
+	}
+
+	log.Trace("URL endpoint parsed and authentication method chosen")
+
+	if d.canWrite() {
+		log.Infof("Running in read-write mode, will commit back current status to the repo")
+	} else {
+		log.Infof("Running in read-only mode, won't write status back to the repo")
+	}
+
+	// Clone the repo
+	if err := d.clone(ctx); err != nil {
+		return nil, err
+	}
+
+	return d, nil
+}
+
+// LocalClone is an implementation of both a Remote, and a BranchManager, for Git.
+type LocalClone struct {
+	// user-specified options
+	repoRef gitprovider.RepositoryRef
+	opts    LocalCloneOptions
+
+	// the temporary directory used for the clone
+	cloneDir string
+
+	// go-git objects. wt is the worktree of the repo, persistent during the lifetime of repo.
+	repo *git.Repository
+	wt   *git.Worktree
+
+	// the lock for git operations (so no ops are done simultaneously)
+	lock *sync.Mutex
+
+	commitHooks transactional.CommitHookChain
+	txHooks     transactional.TransactionHookChain
+}
+
+func (d *LocalClone) CommitHookChain() transactional.CommitHookChain {
+	return d.commitHooks
+}
+
+func (d *LocalClone) TransactionHookChain() transactional.TransactionHookChain {
+	return d.txHooks
+}
+
+func (d *LocalClone) Dir() string {
+	return d.cloneDir
+}
+
+func (d *LocalClone) MainBranch() string {
+	return d.opts.Branch
+}
+
+func (d *LocalClone) RepositoryRef() gitprovider.RepositoryRef {
+	return d.repoRef
+}
+
+func (d *LocalClone) canWrite() bool {
+	return d.opts.AuthMethod != nil
+}
+
+// verifyRead makes sure it's ok to start a read-something-from-git process
+func (d *LocalClone) verifyRead() error {
+	// Safeguard against not starting yet
+	if d.wt == nil {
+		return fmt.Errorf("cannot pull: %w", ErrNotStarted)
+	}
+	return nil
+}
+
+// verifyWrite makes sure it's ok to start a write-something-to-git process
+func (d *LocalClone) verifyWrite() error {
+	// We need all read privileges first
+	if err := d.verifyRead(); err != nil {
+		return err
+	}
+	// Make sure we don't write to a possibly read-only repo
+	if !d.canWrite() {
+		return ErrCannotWriteToReadOnly
+	}
+	return nil
+}
+
+func (d *LocalClone) clone(ctx context.Context) error {
+	// Lock the mutex now that we're starting, and unlock it when exiting
+	d.lock.Lock()
+	defer d.lock.Unlock()
+
+	cloneURL := d.repoRef.GetCloneURL(d.opts.AuthMethod.TransportType())
+
+	log.Infof("Starting to clone the repository %s", d.repoRef)
+	// Do a clone operation to the temporary directory
+	var err error
+	d.repo, err = git.PlainCloneContext(ctx, d.Dir(), false, &git.CloneOptions{
+		URL:           cloneURL,
+		Auth:          d.opts.AuthMethod,
+		ReferenceName: plumbing.NewBranchReferenceName(d.opts.Branch),
+		SingleBranch:  true,
+		NoCheckout:    false,
+		//Depth:             1, // ref: https://github.com/src-d/go-git/issues/1143
+		RecurseSubmodules: 0,
+		Progress:          nil,
+		Tags:              git.NoTags,
+	})
+	// Handle errors
+	if errors.Is(err, context.DeadlineExceeded) {
+		return fmt.Errorf("git clone operation timed out: %w", err)
+	} else if errors.Is(err, context.Canceled) {
+		return fmt.Errorf("git clone was cancelled: %w", err)
+	} else if err != nil {
+		return fmt.Errorf("git clone error: %v", err)
+	}
+
+	// Populate the worktree pointer
+	d.wt, err = d.repo.Worktree()
+	if err != nil {
+		return fmt.Errorf("git get worktree error: %v", err)
+	}
+
+	// Get the latest HEAD commit and report it to the user
+	ref, err := d.repo.Head()
+	if err != nil {
+		return err
+	}
+
+	log.Infof("Repo cloned; HEAD commit is %s", ref.Hash())
+	return nil
+}
+
+func (d *LocalClone) Pull(ctx context.Context) error {
+	// Lock the mutex now that we're starting, and unlock it when exiting
+	d.lock.Lock()
+	defer d.lock.Unlock()
+
+	// TODO: This should support doing Fetch() only maybe
+	// TODO: Remove the requirement to actually be on the branch
+	// that is being pulled.
+
+	// Make sure it's okay to read
+	if err := d.verifyRead(); err != nil {
+		return err
+	}
+
+	// Perform the git pull operation. The context carries a timeout
+	log.Trace("Starting pull operation")
+	err := d.wt.PullContext(ctx, &git.PullOptions{
+		Auth:         d.opts.AuthMethod,
+		SingleBranch: true,
+	})
+
+	// Handle errors
+	if errors.Is(err, git.NoErrAlreadyUpToDate) {
+		// all good, nothing more to do
+		log.Trace("Pull already up-to-date")
+		return nil
+	} else if errors.Is(err, context.DeadlineExceeded) {
+		return fmt.Errorf("git pull operation timed out: %w", err)
+	} else if errors.Is(err, context.Canceled) {
+		return fmt.Errorf("git pull was cancelled: %w", err)
+	} else if err != nil {
+		return fmt.Errorf("git pull error: %v", err)
+	}
+
+	log.Trace("Pulled successfully")
+
+	// Get current HEAD
+	ref, err := d.repo.Head()
+	if err != nil {
+		return err
+	}
+
+	log.Infof("New commit observed %s", ref.Hash())
+	return nil
+}
+
+func (d *LocalClone) Push(ctx context.Context) error {
+	// TODO: Push a specific branch only. Use opts.RefSpecs?
+
+	// Perform the git push operation. The context carries a timeout
+	log.Debug("Starting push operation")
+	err := d.repo.PushContext(ctx, &git.PushOptions{
+		Auth: d.opts.AuthMethod,
+	})
+
+	// Handle errors
+	if errors.Is(err, git.NoErrAlreadyUpToDate) {
+		// TODO: Is it good if there's nothing more to do; or a failure if there's nothing to push?
+		log.Trace("Push already up-to-date")
+		return nil
+	} else if errors.Is(err, context.DeadlineExceeded) {
+		return fmt.Errorf("git push operation timed out: %w", err)
+	} else if errors.Is(err, context.Canceled) {
+		return fmt.Errorf("git push was cancelled: %w", err)
+	} else if err != nil {
+		return fmt.Errorf("git push error: %v", err)
+	}
+
+	log.Trace("Pushed successfully")
+
+	return nil
+}
+
+func (d *LocalClone) CreateBranch(_ context.Context, branch string) error {
+	// Lock the mutex now that we're starting, and unlock it when exiting
+	d.lock.Lock()
+	defer d.lock.Unlock()
+
+	// TODO: Should the caller do a force-reset using ResetToCleanBranch before creating the branch?
+
+	// Make sure it's okay to write
+	if err := d.verifyWrite(); err != nil {
+		return err
+	}
+
+	return d.wt.Checkout(&git.CheckoutOptions{
+		Branch: plumbing.NewBranchReferenceName(branch),
+		Create: true,
+	})
+}
+
+func (d *LocalClone) ResetToCleanBranch(_ context.Context, branch string) error {
+	// Lock the mutex now that we're starting, and unlock it when exiting
+	d.lock.Lock()
+	defer d.lock.Unlock()
+
+	// Make sure it's okay to write
+	if err := d.verifyWrite(); err != nil {
+		return err
+	}
+
+	// Best-effort clean
+	_ = d.wt.Clean(&git.CleanOptions{
+		Dir: true,
+	})
+	// Force-checkout the main branch
+	return d.wt.Checkout(&git.CheckoutOptions{
+		Branch: plumbing.NewBranchReferenceName(branch),
+		Force:  true,
+	})
+	// TODO: Do a pull here too?
+}
+
+// Commit creates a commit of all changes in the current worktree with the given parameters.
+// It also automatically pushes the branch after the commit.
+// ErrNotStarted is returned if the repo hasn't been cloned yet.
+// ErrCannotWriteToReadOnly is returned if opts.AuthMethod wasn't provided.
+func (d *LocalClone) Commit(ctx context.Context, commit transactional.Commit) error {
+	// Lock the mutex now that we're starting, and unlock it when exiting
+	d.lock.Lock()
+	defer d.lock.Unlock()
+
+	// Make sure it's okay to write
+	if err := d.verifyWrite(); err != nil {
+		return err
+	}
+
+	s, err := d.wt.Status()
+	if err != nil {
+		return fmt.Errorf("git status failed: %v", err)
+	}
+	if s.IsClean() {
+		log.Debugf("No changed files in git repo, nothing to commit...")
+		// TODO: Should this be an error instead?
+		return nil
+	}
+
+	// Do a commit
+	log.Debug("Committing all local changes")
+	hash, err := d.wt.Commit(commit.GetMessage().String(), &git.CommitOptions{
+		All: true,
+		Author: &object.Signature{
+			Name:  commit.GetAuthor().GetName(),
+			Email: commit.GetAuthor().GetEmail(),
+			When:  time.Now(),
+		},
+	})
+	if err != nil {
+		return fmt.Errorf("git commit error: %v", err)
+	}
+
+	// Notify upstream that we now have a new commit, and allow writing again
+	log.Infof("A new commit has been created: %q", hash)
+	return nil
+}
+
+// Cleanup cancels running goroutines and operations, and removes the temporary clone directory
+func (d *LocalClone) Cleanup() error {
+	// Remove the temporary directory
+	if err := os.RemoveAll(d.Dir()); err != nil {
+		log.Errorf("Failed to clean up temp git directory: %v", err)
+		return err
+	}
+	return nil
+}
diff --git a/pkg/storage/client/transactional/distributed/git/github/github.go b/pkg/storage/client/transactional/distributed/git/github/github.go
new file mode 100644
index 0000000..23a2012
--- /dev/null
+++ b/pkg/storage/client/transactional/distributed/git/github/github.go
@@ -0,0 +1,182 @@
+package github
+
+import (
+	"context"
+	"errors"
+	"fmt"
+
+	"github.com/fluxcd/go-git-providers/github"
+	"github.com/fluxcd/go-git-providers/gitprovider"
+	"github.com/fluxcd/go-git-providers/validation"
+	gogithub "github.com/google/go-github/v32/github"
+	"github.com/sirupsen/logrus"
+	"github.com/weaveworks/libgitops/pkg/storage/client/transactional"
+)
+
+// PullRequest can be returned from a TransactionFunc instead of a CommitResult, if
+// a PullRequest is desired to be created by the PullRequestProvider.
+type PullRequest interface {
+	// PullRequestResult is a superset of CommitResult
+	transactional.Commit
+
+	// GetLabels specifies what labels should be applied on the PR.
+	// +optional
+	GetLabels() []string
+	// GetAssignees specifies what user login names should be assigned to this PR.
+	// Note: Only users with "pull" access or more can be assigned.
+	// +optional
+	GetAssignees() []string
+	// GetMilestone specifies what milestone this should be attached to.
+	// +optional
+	GetMilestone() string
+}
+
+// GenericPullRequest implements PullRequest.
+var _ PullRequest = GenericPullRequest{}
+
+// GenericPullRequest implements PullRequest.
+type GenericPullRequest struct {
+	// GenericPullRequest is a superset of a Commit.
+	transactional.Commit
+
+	// Labels specifies what labels should be applied on the PR.
+	// +optional
+	Labels []string
+	// Assignees specifies what user login names should be assigned to this PR.
+	// Note: Only users with "pull" access or more can be assigned.
+	// +optional
+	Assignees []string
+	// Milestone specifies what milestone this should be attached to.
+	// +optional
+	Milestone string
+}
+
+func (r GenericPullRequest) GetLabels() []string    { return r.Labels }
+func (r GenericPullRequest) GetAssignees() []string { return r.Assignees }
+func (r GenericPullRequest) GetMilestone() string   { return r.Milestone }
+
+func (r GenericPullRequest) Validate() error {
+	v := validation.New("GenericPullRequest")
+	// Just validate the "inner" object
+	v.Append(r.Commit.Validate(), r.Commit, "Commit")
+	return v.Error()
+}
+
+// TODO: This package should really only depend on go-git-providers' abstraction interface
+
+var ErrProviderNotSupported = errors.New("only the Github go-git-providers provider is supported at the moment")
+
+// NewGitHubPRCommitHandler returns a new transactional.CommitHandler from a gitprovider.Client.
+func NewGitHubPRCommitHandler(c gitprovider.Client, repoRef gitprovider.RepositoryRef) (transactional.CommitHook, error) {
+	// Make sure a Github client was passed
+	if c.ProviderID() != github.ProviderID {
+		return nil, ErrProviderNotSupported
+	}
+	return &prCreator{c, repoRef}, nil
+}
+
+type prCreator struct {
+	c       gitprovider.Client
+	repoRef gitprovider.RepositoryRef
+}
+
+func (c *prCreator) PreCommitHook(ctx context.Context, commit transactional.Commit, info transactional.TxInfo) error {
+	return nil
+}
+
+func (c *prCreator) PostCommitHook(ctx context.Context, commit transactional.Commit, info transactional.TxInfo) error {
+	// First, validate the input
+	if err := commit.Validate(); err != nil {
+		return fmt.Errorf("given transactional.Commit wasn't valid")
+	}
+
+	prCommit, ok := commit.(PullRequest)
+	if !ok {
+		return nil
+	}
+
+	// Use the "raw" go-github client to do this
+	ghClient := c.c.Raw().(*gogithub.Client)
+
+	// Helper variables
+	owner := c.repoRef.GetIdentity()
+	repo := c.repoRef.GetRepository()
+	var body *string
+	if commit.GetMessage().GetDescription() != "" {
+		body = gogithub.String(commit.GetMessage().GetDescription())
+	}
+
+	// Create the Pull Request
+	prPayload := &gogithub.NewPullRequest{
+		Head:  gogithub.String(info.Head),
+		Base:  gogithub.String(info.Base),
+		Title: gogithub.String(commit.GetMessage().GetTitle()),
+		Body:  body,
+	}
+	logrus.Infof("GitHub PR payload: %+v", prPayload)
+	pr, _, err := ghClient.PullRequests.Create(ctx, owner, repo, prPayload)
+	if err != nil {
+		return err
+	}
+
+	// If spec.GetMilestone() is set, fetch the ID of the milestone
+	// Only set milestoneID to non-nil if specified
+	var milestoneID *int
+	if len(prCommit.GetMilestone()) != 0 {
+		milestoneID, err = getMilestoneID(ctx, ghClient, owner, repo, prCommit.GetMilestone())
+		if err != nil {
+			return err
+		}
+	}
+
+	// Only set assignees to non-nil if specified
+	var assignees *[]string
+	if a := prCommit.GetAssignees(); len(a) != 0 {
+		assignees = &a
+	}
+
+	// Only set labels to non-nil if specified
+	var labels *[]string
+	if l := prCommit.GetLabels(); len(l) != 0 {
+		labels = &l
+	}
+
+	// Only PATCH the PR if any of the fields were set
+	if milestoneID != nil || assignees != nil || labels != nil {
+		_, _, err := ghClient.Issues.Edit(ctx, owner, repo, pr.GetNumber(), &gogithub.IssueRequest{
+			Milestone: milestoneID,
+			Assignees: assignees,
+			Labels:    labels,
+		})
+		if err != nil {
+			return err
+		}
+	}
+
+	return nil
+}
+
+func getMilestoneID(ctx context.Context, c *gogithub.Client, owner, repo, milestoneName string) (*int, error) {
+	// List all milestones in the repo
+	// TODO: This could/should use pagination
+	milestones, _, err := c.Issues.ListMilestones(ctx, owner, repo, &gogithub.MilestoneListOptions{
+		State: "all",
+	})
+	if err != nil {
+		return nil, err
+	}
+	// Loop through all milestones, search for one with the right name
+	for _, milestone := range milestones {
+		// Only consider a milestone with the right name
+		if milestone.GetTitle() != milestoneName {
+			continue
+		}
+		// Validate nil to avoid panics
+		if milestone.Number == nil {
+			return nil, fmt.Errorf("didn't expect milestone Number to be nil: %v", milestone)
+		}
+		// Return the Milestone number
+		return milestone.Number, nil
+	}
+	return nil, fmt.Errorf("couldn't find milestone with name: %s", milestoneName)
+}
diff --git a/pkg/gitdir/transport.go b/pkg/storage/client/transactional/distributed/git/transport.go
similarity index 97%
rename from pkg/gitdir/transport.go
rename to pkg/storage/client/transactional/distributed/git/transport.go
index df2c325..3017853 100644
--- a/pkg/gitdir/transport.go
+++ b/pkg/storage/client/transactional/distributed/git/transport.go
@@ -1,10 +1,10 @@
-package gitdir
+package git
 
 import (
 	"errors"
 
 	"github.com/fluxcd/go-git-providers/gitprovider"
-	"github.com/fluxcd/toolkit/pkg/ssh/knownhosts"
+	"github.com/fluxcd/pkg/ssh/knownhosts"
 	"github.com/go-git/go-git/v5/plumbing/transport"
 	"github.com/go-git/go-git/v5/plumbing/transport/http"
 	"github.com/go-git/go-git/v5/plumbing/transport/ssh"
diff --git a/pkg/storage/client/transactional/distributed/interfaces.go b/pkg/storage/client/transactional/distributed/interfaces.go
new file mode 100644
index 0000000..8110599
--- /dev/null
+++ b/pkg/storage/client/transactional/distributed/interfaces.go
@@ -0,0 +1,75 @@
+package distributed
+
+import (
+	"context"
+	"time"
+
+	"github.com/weaveworks/libgitops/pkg/storage/client/transactional"
+)
+
+// Client is a client that can sync state with a remote in a transactional way.
+type Client interface {
+	// The distributed Client extends the transactional Client
+	transactional.Client
+	// This Client is itself both a CommitHook and TransactionHook; these should
+	// be automatically registered with the transactional.Client's BranchManager
+	// in this Client's constructor.
+	transactional.CommitHook
+	transactional.TransactionHook
+
+	// StartResyncLoop starts a resync loop for the given branches for
+	// the given interval.
+	//
+	// resyncCacheInterval specifies the interval for which resyncs
+	// (remote Pulls) should be run in the background. The duration must
+	// be positive, and non-zero.
+	//
+	// resyncBranches specifies what branches to resync. The default is
+	// []string{""}, i.e. only the "default" branch.
+	//
+	// ctx should be used to cancel the loop, if needed.
+	//
+	// While it is technically possible to start many of these resync
+	// loops, it is not recommended. Start it once, for all the branches
+	// you need. The branches will be pulled synchronously in order. The
+	// resync interval is non-sliding, which means that the interval
+	// includes the time of the operations.
+	StartResyncLoop(ctx context.Context, resyncCacheInterval time.Duration, resyncBranches ...string)
+
+	// Remote exposes the underlying remote used
+	Remote() Remote
+}
+
+type Remote interface {
+	// Push pushes the attached branch (of the ctx) to the remote.
+	// Push must block as long as the operation is in progress, but also
+	// respect the timeout set on ctx and return instantly after it expires.
+	//
+	// It is guaranteed that Pull() and Push() are never called racily at
+	// the same time for the same branch, BUT Pull() and Push() might be called
+	// at the same time in any order for distinct branches. If the underlying
+	// Remote transport only supports one "writer transport" to it at the same time,
+	// the Remote must coordinate pulls and pushes with a mutex internally.
+	Push(ctx context.Context) error
+
+	// Pull pulls the attached branch (of the ctx) from the remote.
+	// Pull must block as long as the operation is in progress, but also
+	// respect the timeout set on ctx and return instantly after it expires.
+	//
+	// It is guaranteed that Pull() and Push() are never called racily at
+	// the same time for the same branch, BUT Pull() and Push() might be called
+	// at the same time in any order for distinct branches. If the underlying
+	// Remote transport only supports one "writer transport" to it at the same time,
+	// the Remote must coordinate pulls and pushes with a mutex internally.
+	Pull(ctx context.Context) error
+}
+
+// LockableRemote describes a remote that supports locking a remote branch for writing.
+type LockableRemote interface {
+	Remote
+
+	// Lock locks the branch attached to the context for writing, for the given duration.
+	Lock(ctx context.Context, d time.Duration) error
+	// Unlock reverses the write lock created by Lock()
+	Unlock(ctx context.Context) error
+}
diff --git a/pkg/storage/client/transactional/distributed/options.go b/pkg/storage/client/transactional/distributed/options.go
new file mode 100644
index 0000000..4640ce9
--- /dev/null
+++ b/pkg/storage/client/transactional/distributed/options.go
@@ -0,0 +1,97 @@
+package distributed
+
+import "time"
+
+// ClientOption is an interface for applying options to ClientOptions.
+type ClientOption interface {
+	ApplyToClient(*ClientOptions)
+}
+
+// ClientOptions specify options on how the distributed client should
+// act according to the PACELC theorem.
+//
+// The following configurations correspond to the PACELC levels:
+//
+// PC/EC: CacheValidDuration == 0 && RemoteErrorStream == nil:
+// 		This makes every read first do a remote Pull(), and fails
+//		critically if the Pull operation fails. Transactions fail
+//		if Push() fails.
+//
+// PC/EL: CacheValidDuration > 0 && RemoteErrorStream == nil:
+// 		This makes a read do a remote Pull only if the delta between
+// 		the last Pull and time.Now() exceeds CacheValidDuration.
+// 		StartResyncLoop(resyncCacheInterval) can be used to
+// 		periodically Pull in the background, so that the latency
+//		of reads are minimal. Transactions and reads fail if
+// 		Push() or Pull() fail.
+//
+// PA/EL: RemoteErrorStream != nil:
+//		How often reads invoke Pull() is given by CacheValidDuration
+// 		and StartResyncLoop(resyncCacheInterval) as per above.
+//		However, when a Pull() or Push() is invoked from a read or
+//		transaction, and a network partition happens, such errors are
+//		non-critical for the operation to succeed, as Availability is
+//		favored and cached objects are returned.
+type ClientOptions struct {
+	// CacheValidDuration is the period of time the cache is still
+	// valid since its last resync (remote Pull). If set to 0; all
+	// reads will invoke a resync right before reading; as the cache
+	// is never valid. This option set to 0 favors Consistency over
+	// Availability.
+	//
+	// CacheValidDuration == 0 and RemoteErrorStream != nil must not
+	// be set at the same time; as they contradict.
+	//
+	// Default: 1m
+	CacheValidDuration time.Duration
+	// RemoteErrorStream specifies a stream in which to readirect
+	// errors from the remote, instead of returning them to the caller.
+	// This is useful for allowing "offline operation", and favoring
+	// Availability over Consistency when a Partition happens (i.e.
+	// the network is unreachable). In normal operation, remote Push/Pull
+	// errors would propagate to the caller and "fail" the Transaction,
+	// however, if that is not desired, those errors can be propagated
+	// here, and the caller will succeed with the transaction.
+	// Default: nil (optional)
+	RemoteErrorStream chan error
+
+	// Default: 30s for all
+	LockTimeout time.Duration
+	PullTimeout time.Duration
+	PushTimeout time.Duration
+}
+
+func (o *ClientOptions) ApplyToClient(target *ClientOptions) {
+	if o.CacheValidDuration != 0 {
+		target.CacheValidDuration = o.CacheValidDuration
+	}
+	if o.RemoteErrorStream != nil {
+		target.RemoteErrorStream = o.RemoteErrorStream
+	}
+	if o.LockTimeout != 0 {
+		target.LockTimeout = o.LockTimeout
+	}
+	if o.PullTimeout != 0 {
+		target.PullTimeout = o.PullTimeout
+	}
+	if o.PushTimeout != 0 {
+		target.PushTimeout = o.PushTimeout
+	}
+}
+
+func (o *ClientOptions) ApplyOptions(opts []ClientOption) *ClientOptions {
+	for _, opt := range opts {
+		opt.ApplyToClient(o)
+	}
+	return o
+}
+
+func defaultOptions() *ClientOptions {
+	return &ClientOptions{
+		CacheValidDuration: 1 * time.Minute,
+		RemoteErrorStream:  nil,
+		LockTimeout:        30 * time.Second,
+		PullTimeout:        30 * time.Second,
+		PushTimeout:        30 * time.Second,
+	}
+}
diff --git a/pkg/storage/client/transactional/handlers.go b/pkg/storage/client/transactional/handlers.go
new file mode 100644
index 0000000..aa438e3
--- /dev/null
+++ b/pkg/storage/client/transactional/handlers.go
@@ -0,0 +1,103 @@
+package transactional
+
+import "context"
+
+type TxInfo struct {
+	Base    string
+	Head    string
+	Options TxOptions
+}
+
+type CommitHookChain interface {
+	// The chain also itself implements CommitHook
+	CommitHook
+	// Register registers a new CommitHook to the chain
+	Register(CommitHook)
+}
+
+type CommitHook interface {
+	PreCommitHook(ctx context.Context, commit Commit, info TxInfo) error
+	PostCommitHook(ctx context.Context, commit Commit, info TxInfo) error
+}
+
+var _ CommitHookChain = &MultiCommitHook{}
+var _ CommitHook = &MultiCommitHook{}
+
+type MultiCommitHook struct {
+	CommitHooks []CommitHook
+}
+
+func (m *MultiCommitHook) Register(h CommitHook) {
+	m.CommitHooks = append(m.CommitHooks, h)
+}
+
+func (m *MultiCommitHook) PreCommitHook(ctx context.Context, commit Commit, info TxInfo) error {
+	for _, ch := range m.CommitHooks {
+		if ch == nil {
+			continue
+		}
+		if err := ch.PreCommitHook(ctx, commit, info); err != nil {
+			return err
+		}
+	}
+	return nil
+}
+
+func (m *MultiCommitHook) PostCommitHook(ctx context.Context, commit Commit, info TxInfo) error {
+	for _, ch := range m.CommitHooks {
+		if ch == nil {
+			continue
+		}
+		if err := ch.PostCommitHook(ctx, commit, info); err != nil {
+			return err
+		}
+	}
+	return nil
+}
+
+type TransactionHookChain interface {
+	// The chain also itself implements TransactionHook
+	TransactionHook
+	// Register registers a new CommitHook to the chain
+	Register(TransactionHook)
+}
+
+type TransactionHook interface {
+	PreTransactionHook(ctx context.Context, info TxInfo) error
+	PostTransactionHook(ctx context.Context, info TxInfo) error
+}
+
+var _ TransactionHookChain = &MultiTransactionHook{}
+var _ TransactionHook = &MultiTransactionHook{}
+
+type MultiTransactionHook struct {
+	TransactionHooks []TransactionHook
+}
+
+func (m *MultiTransactionHook) Register(h TransactionHook) {
+	m.TransactionHooks = append(m.TransactionHooks, h)
+}
+
+func (m *MultiTransactionHook) PreTransactionHook(ctx context.Context, info TxInfo) error {
+	for _, th := range m.TransactionHooks {
+		if th == nil {
+			continue
+		}
+		if err := th.PreTransactionHook(ctx, info); err != nil {
+			return err
+		}
+	}
+	return nil
+}
+
+func (m *MultiTransactionHook) PostTransactionHook(ctx context.Context, info TxInfo) error {
+	for _, th := range m.TransactionHooks {
+		if th == nil {
+			continue
+		}
+		if err := th.PostTransactionHook(ctx, info); err != nil {
+			return err
+		}
+	}
+	return nil
+}
diff --git a/pkg/storage/client/transactional/interfaces.go b/pkg/storage/client/transactional/interfaces.go
new file mode 100644
index 0000000..7371f4c
--- /dev/null
+++ b/pkg/storage/client/transactional/interfaces.go
@@ -0,0 +1,82 @@
+package transactional
+
+import (
+	"context"
+
+	"github.com/weaveworks/libgitops/pkg/storage/client"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+)
+
+type Client interface {
+	client.Reader
+
+	BranchManager() BranchManager
+	BranchMerger() BranchMerger
+
+	Transaction(ctx context.Context, opts ...TxOption) Tx
+	BranchTransaction(ctx context.Context, branchName string, opts ...TxOption) BranchTx
+}
+
+type BranchManager interface {
+	CreateBranch(ctx context.Context, branch string) error
+	ResetToCleanBranch(ctx context.Context, branch string) error
+	Commit(ctx context.Context, commit Commit) error
+
+	// CommitHookChain must be non-nil, but can be a no-op
+	CommitHookChain() CommitHookChain
+	// TransactionHookChain must be non-nil, but can be a no-op
+	TransactionHookChain() TransactionHookChain
+}
+
+type BranchMerger interface {
+	MergeBranches(ctx context.Context, base, head string, commit Commit) error
+}
+
+type CustomTxFunc func(ctx context.Context) error
+
+type Tx interface {
+	Commit(Commit) error
+	Abort(err error) error
+
+	Client() client.Client
+
+	Custom(CustomTxFunc) Tx
+
+	Get(key core.ObjectKey, obj core.Object) Tx
+	List(list core.ObjectList, opts ...core.ListOption) Tx
+
+	Create(obj core.Object, opts ...core.CreateOption) Tx
+	Update(obj core.Object, opts ...core.UpdateOption) Tx
+	Patch(obj core.Object, patch core.Patch, opts ...core.PatchOption) Tx
+	Delete(obj core.Object, opts ...core.DeleteOption) Tx
+	DeleteAllOf(obj core.Object, opts ...core.DeleteAllOfOption) Tx
+
+	UpdateStatus(obj core.Object, opts ...core.UpdateOption) Tx
+	PatchStatus(obj core.Object, patch core.Patch, opts ...core.PatchOption) Tx
+}
+
+type BranchTx interface {
+	CreateTx(Commit) BranchTxResult
+	Abort(err error) error
+
+	Client() client.Client
+
+	Custom(CustomTxFunc) BranchTx
+
+	Get(key core.ObjectKey, obj core.Object) BranchTx
+	List(list core.ObjectList, opts ...core.ListOption) BranchTx
+
+	Create(obj core.Object, opts ...core.CreateOption) BranchTx
+	Update(obj core.Object, opts ...core.UpdateOption) BranchTx
+	Patch(obj core.Object, patch core.Patch, opts ...core.PatchOption) BranchTx
+	Delete(obj core.Object, opts ...core.DeleteOption) BranchTx
+	DeleteAllOf(obj core.Object, opts ...core.DeleteAllOfOption) BranchTx
+
+	UpdateStatus(obj core.Object, opts ...core.UpdateOption) BranchTx
+	PatchStatus(obj core.Object, patch core.Patch, opts ...core.PatchOption) BranchTx
+}
+
+type BranchTxResult interface {
+	Error() error
+	MergeWithBase(Commit) error
+}
diff --git a/pkg/storage/client/transactional/options.go b/pkg/storage/client/transactional/options.go
new file mode 100644
index 0000000..6b3679c
--- /dev/null
+++ b/pkg/storage/client/transactional/options.go
@@ -0,0 +1,66 @@
+package transactional
+
+import "time"
+
+type TxOption interface {
+	ApplyToTx(*TxOptions)
+}
+
+var _ TxOption = &TxOptions{}
+
+func defaultTxOptions() *TxOptions {
+	return &TxOptions{
+		Timeout: 1 * time.Minute,
+		Mode:    TxModeAtomic,
+	}
+}
+
+type TxOptions struct {
+	Timeout time.Duration
+	Mode    TxMode
+}
+
+func (o *TxOptions) ApplyToTx(target *TxOptions) {
+	if o.Timeout != 0 {
+		target.Timeout = o.Timeout
+	}
+	if len(o.Mode) != 0 {
+		target.Mode = o.Mode
+	}
+}
+
+func (o *TxOptions) ApplyOptions(opts []TxOption) *TxOptions {
+	for _, opt := range opts {
+		opt.ApplyToTx(o)
+	}
+	return o
+}
+
+var _ TxOption = TxMode("")
+
+type TxMode string
+
+const (
+	// TxModeAtomic makes the transaction fully atomic, i.e. so
+	// that any read happening against the target branch during the
+	// lifetime of the transaction will be blocked until the completition
+	// of the transaction.
+	TxModeAtomic TxMode = "Atomic"
+	// TxModeAllowReading will allow reads targeting the given
+	// branch a transaction is executing against; but before the
+	// transaction has completed all reads will strictly return
+	// the data available prior to the transaction taking place.
+	TxModeAllowReading TxMode = "AllowReading"
+)
+
+func (m TxMode) ApplyToTx(target *TxOptions) {
+	target.Mode = m
+}
+
+var _ TxOption = TxTimeout(0)
+
+type TxTimeout time.Duration
+
+func (t TxTimeout) ApplyToTx(target *TxOptions) {
+	target.Timeout = time.Duration(t)
+}
diff --git a/pkg/storage/client/transactional/tx.go b/pkg/storage/client/transactional/tx.go
new file mode 100644
index 0000000..30c6b6c
--- /dev/null
+++ b/pkg/storage/client/transactional/tx.go
@@ -0,0 +1,24 @@
+package transactional
+
+type txImpl struct {
+	*txCommon
+}
+
+func (tx *txImpl) Commit(c Commit) error {
+	// Run the operations, and try to create the commit
+	if err := tx.tryApplyAndCommitOperations(c); err != nil {
+		// If we failed with the transaction, abort directly
+		return tx.Abort(err)
+	}
+
+	// We successfully completed all the tasks needed
+	// Now, cleanup and unlock the branch
+	return tx.cleanupFunc()
+}
+
+func (tx *txImpl) Custom(op CustomTxFunc) Tx {
+	tx.ops = append(tx.ops, func() error {
+		return op(tx.ctx)
+	})
+	return tx
+}
diff --git a/pkg/storage/client/transactional/tx_branch.go b/pkg/storage/client/transactional/tx_branch.go
new file mode 100644
index 0000000..c7011a3
--- /dev/null
+++ b/pkg/storage/client/transactional/tx_branch.go
@@ -0,0 +1,71 @@
+package transactional
+
+import (
+	"context"
+	"fmt"
+)
+
+type txBranchImpl struct {
+	*txCommon
+
+	merger BranchMerger
+}
+
+func (tx *txBranchImpl) CreateTx(c Commit) BranchTxResult {
+	// Run the operations, and try to create the commit
+	if err := tx.tryApplyAndCommitOperations(c); err != nil {
+		// If we failed with the transaction, abort directly, and
+		// return the error wrapped in a BranchTxResult
+		abortErr := tx.Abort(err)
+		return newErrTxResult(abortErr)
+	}
+
+	// We successfully completed all the tasks needed
+	// Now, cleanup and unlock the branch
+	cleanupErr := tx.cleanupFunc()
+
+	// Allow the merger to merge, if supported
+	return &txResultImpl{
+		err:        cleanupErr,
+		ctx:        tx.ctx,
+		merger:     tx.merger,
+		baseBranch: tx.info.Base,
+		headBranch: tx.info.Head,
+	}
+}
+
+func (tx *txBranchImpl) Custom(op CustomTxFunc) BranchTx {
+	tx.ops = append(tx.ops, func() error {
+		return op(tx.ctx)
+	})
+	return tx
+}
+
+func newErrTxResult(err error) *txResultImpl {
+	return &txResultImpl{err: err}
+}
+
+type txResultImpl struct {
+	err        error
+	ctx        context.Context
+	merger     BranchMerger
+	baseBranch string
+	headBranch string
+}
+
+func (r *txResultImpl) Error() error {
+	return r.err
+}
+
+func (r *txResultImpl) MergeWithBase(c Commit) error {
+	// If there is an internal error, return it
+	if r.err != nil {
+		return r.err
+	}
+	// Make sure we have a merger
+	if r.merger == nil {
+		return fmt.Errorf("TxResult: The BranchMerger is nil")
+	}
+	// Try to merge the branch
+	return r.merger.MergeBranches(r.ctx, r.baseBranch, r.headBranch, c)
+}
diff --git a/pkg/storage/client/transactional/tx_common.go b/pkg/storage/client/transactional/tx_common.go
new file mode 100644
index 0000000..3448c81
--- /dev/null
+++ b/pkg/storage/client/transactional/tx_common.go
@@ -0,0 +1,70 @@
+package transactional
+
+import (
+	"context"
+
+	"github.com/weaveworks/libgitops/pkg/storage/client"
+	utilerrs "k8s.io/apimachinery/pkg/util/errors"
+)
+
+type txFunc func() error
+
+type txCommon struct {
+	err         error
+	c           client.Client
+	manager     BranchManager
+	ctx         context.Context
+	ops         []txFunc
+	info        TxInfo
+	cleanupFunc txFunc
+}
+
+func (tx *txCommon) Client() client.Client {
+	return tx.c
+}
+
+func (tx *txCommon) Abort(err error) error {
+	// Run the cleanup function and return an aggregate of the two possible errors
+	return utilerrs.NewAggregate([]error{
+		err,
+		tx.cleanupFunc(),
+	})
+}
+
+func (tx *txCommon) handlePreCommit(c Commit) txFunc {
+	return func() error {
+		return tx.manager.CommitHookChain().PreCommitHook(tx.ctx, c, tx.info)
+	}
+}
+
+func (tx *txCommon) commit(c Commit) txFunc {
+	return func() error {
+		return tx.manager.Commit(tx.ctx, c)
+	}
+}
+
+func (tx *txCommon) handlePostCommit(c Commit) txFunc {
+	return func() error {
+		return tx.manager.CommitHookChain().PostCommitHook(tx.ctx, c, tx.info)
+	}
+}
+
+func (tx *txCommon) tryApplyAndCommitOperations(c Commit) error {
+	// If an error occurred already before, just return it directly
+	if tx.err != nil {
+		return tx.err
+	}
+
+	// First, all registered client operations are run
+	// Then Pre-commit, commit, and post-commit functions are run
+	// If at any stage the context is cancelled, an error is returned
+	// immediately, and no more functions in the chain are run. The
+	// same goes for errors from any of the functions, the chain is
+	// immediately interrupted on errors.
+	return execTransactionsCtx(tx.ctx, append(
+		tx.ops,
+		tx.handlePreCommit(c),
+		tx.commit(c),
+		tx.handlePostCommit(c),
+	))
+}
diff --git a/pkg/storage/client/transactional/tx_ops.go b/pkg/storage/client/transactional/tx_ops.go
new file mode 100644
index 0000000..e0a6c37
--- /dev/null
+++ b/pkg/storage/client/transactional/tx_ops.go
@@ -0,0 +1,105 @@
+package transactional
+
+import (
+	"context"
+
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+)
+
+func (tx *txImpl) Get(key core.ObjectKey, obj core.Object) Tx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.Get(ctx, key, obj)
+	})
+}
+func (tx *txImpl) List(list core.ObjectList, opts ...core.ListOption) Tx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.List(ctx, list, opts...)
+	})
+}
+
+func (tx *txImpl) Create(obj core.Object, opts ...core.CreateOption) Tx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.Create(ctx, obj, opts...)
+	})
+}
+func (tx *txImpl) Update(obj core.Object, opts ...core.UpdateOption) Tx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.Update(ctx, obj, opts...)
+	})
+}
+func (tx *txImpl) Patch(obj core.Object, patch core.Patch, opts ...core.PatchOption) Tx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.Patch(ctx, obj, patch, opts...)
+	})
+}
+func (tx *txImpl) Delete(obj core.Object, opts ...core.DeleteOption) Tx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.Delete(ctx, obj, opts...)
+	})
+}
+func (tx *txImpl) DeleteAllOf(obj core.Object, opts ...core.DeleteAllOfOption) Tx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.DeleteAllOf(ctx, obj, opts...)
+	})
+}
+
+func (tx *txImpl) UpdateStatus(obj core.Object, opts ...core.UpdateOption) Tx {
+	return tx.Custom(func(ctx context.Context) error {
+		return nil // TODO tx.c.Status().Update(ctx, obj, opts...)
+	})
+}
+func (tx *txImpl) PatchStatus(obj core.Object, patch core.Patch, opts ...core.PatchOption) Tx {
+	return tx.Custom(func(ctx context.Context) error {
+		return nil // TODO tx.c.Status().Patch(ctx, obj, patch, opts...)
+	})
+}
+
+// TODO
+
+func (tx *txBranchImpl) Get(key core.ObjectKey, obj core.Object) BranchTx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.Get(ctx, key, obj)
+	})
+}
+func (tx *txBranchImpl) List(list core.ObjectList, opts ...core.ListOption) BranchTx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.List(ctx, list, opts...)
+	})
+}
+
+func (tx *txBranchImpl) Create(obj core.Object, opts ...core.CreateOption) BranchTx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.Create(ctx, obj, opts...)
+	})
+}
+func (tx *txBranchImpl) Update(obj core.Object, opts ...core.UpdateOption) BranchTx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.Update(ctx, obj, opts...)
+	})
+}
+func (tx *txBranchImpl) Patch(obj core.Object, patch core.Patch, opts ...core.PatchOption) BranchTx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.Patch(ctx, obj, patch, opts...)
+	})
+}
+func (tx *txBranchImpl) Delete(obj core.Object, opts ...core.DeleteOption) BranchTx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.Delete(ctx, obj, opts...)
+	})
+}
+func (tx *txBranchImpl) DeleteAllOf(obj core.Object, opts ...core.DeleteAllOfOption) BranchTx {
+	return tx.Custom(func(ctx context.Context) error {
+		return tx.c.DeleteAllOf(ctx, obj, opts...)
+	})
+}
+
+func (tx *txBranchImpl) UpdateStatus(obj core.Object, opts ...core.UpdateOption) BranchTx {
+	return tx.Custom(func(ctx context.Context) error {
+		return nil // TODO tx.c.Status().Update(ctx, obj, opts...)
+	})
+}
+func (tx *txBranchImpl) PatchStatus(obj core.Object, patch core.Patch, opts ...core.PatchOption) BranchTx {
+	return tx.Custom(func(ctx context.Context) error {
+		return nil // TODO tx.c.Status().Patch(ctx, obj, patch, opts...)
+	})
+}
diff --git a/pkg/storage/client/transactional/utils.go b/pkg/storage/client/transactional/utils.go
new file mode 100644
index 0000000..4812266
--- /dev/null
+++ b/pkg/storage/client/transactional/utils.go
@@ -0,0 +1,21 @@
+package transactional
+
+import "context"
+
+// execTransactionsCtx executes the functions in order. Before each
+// function in the chain is run; the context is checked for errors
+// (e.g. if it has been cancelled or timed out). If a context error
+// is returned, or if a function in the chain returns an error, this
+// function returns directly, without executing the rest of the
+// functions in the chain.
+func execTransactionsCtx(ctx context.Context, funcs []txFunc) error {
+	for _, fn := range funcs {
+		if err := ctx.Err(); err != nil {
+			return err
+		}
+		if err := fn(); err != nil {
+			return err
+		}
+	}
+	return nil
+}
diff --git a/pkg/storage/client/utils.go b/pkg/storage/client/utils.go
new file mode 100644
index 0000000..da86908
--- /dev/null
+++ b/pkg/storage/client/utils.go
@@ -0,0 +1,23 @@
+package client
+
+import (
+	"errors"
+	"fmt"
+
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"k8s.io/apimachinery/pkg/runtime"
+)
+
+var ErrNoMetadata = errors.New("it is required to embed ObjectMeta into the serialized API type")
+
+func NewObjectForGVK(gvk core.GroupVersionKind, scheme *runtime.Scheme) (core.Object, error) {
+	kobj, err := scheme.New(gvk)
+	if err != nil {
+		return nil, err
+	}
+	obj, ok := kobj.(core.Object)
+	if !ok {
+		return nil, fmt.Errorf("%w: %s", ErrNoMetadata, gvk)
+	}
+	return obj, nil
+}
diff --git a/pkg/storage/core/errors.go b/pkg/storage/core/errors.go
new file mode 100644
index 0000000..f65895a
--- /dev/null
+++ b/pkg/storage/core/errors.go
@@ -0,0 +1,50 @@
+package core
+
+import (
+	goerrors "errors"
+
+	"k8s.io/apimachinery/pkg/api/errors"
+	"k8s.io/apimachinery/pkg/runtime/schema"
+	"k8s.io/apimachinery/pkg/util/validation/field"
+)
+
+var (
+	// ErrNotImplemented can be returned for implementers that do not
+	// implement a specific part of an interface.
+	ErrNotImplemented = goerrors.New("not implemented")
+	// ErrInvalidParameter specifies that a given parameter
+	// (as a public struct field or function argument) was
+	// not valid according to the specification.
+	ErrInvalidParameter = goerrors.New("invalid parameter")
+)
+
+// StatusError is an error that supports also conversion
+// to a metav1.Status struct for more detailed information.
+type StatusError interface {
+	error
+	errors.APIStatus
+}
+
+func NewErrNotFound(id UnversionedObjectID) StatusError {
+	return errors.NewNotFound(schema.GroupResource{
+		Group:    id.GroupKind().Group,
+		Resource: id.GroupKind().Kind,
+	}, id.ObjectKey().Name)
+}
+
+func NewErrAlreadyExists(id UnversionedObjectID) StatusError {
+	return errors.NewAlreadyExists(schema.GroupResource{
+		Group:    id.GroupKind().Group,
+		Resource: id.GroupKind().Kind,
+	}, id.ObjectKey().Name)
+}
+
+func NewErrInvalid(id UnversionedObjectID, errs field.ErrorList) StatusError {
+	return errors.NewInvalid(id.GroupKind(), id.ObjectKey().Name, errs)
+}
+
+var (
+	IsErrNotFound      = errors.IsNotFound
+	IsErrAlreadyExists = errors.IsAlreadyExists
+	IsErrInvalid       = errors.IsInvalid
+)
diff --git a/pkg/storage/core/interfaces.go b/pkg/storage/core/interfaces.go
new file mode 100644
index 0000000..b25cec3
--- /dev/null
+++ b/pkg/storage/core/interfaces.go
@@ -0,0 +1,86 @@
+package core
+
+import (
+	"context"
+
+	"k8s.io/apimachinery/pkg/runtime/schema"
+	"k8s.io/apimachinery/pkg/types"
+	"sigs.k8s.io/controller-runtime/pkg/client"
+)
+
+// Note: package core must not depend on any other parts of the libgitops repo, possibly the serializer package as an exception.
+// Anything under k8s.io/apimachinery goes though, and important external imports
+// like github.com/spf13/afero is also ok. The pretty large sigs.k8s.io/controller-runtime
+// import is a bit sub-optimal, though.
+
+// GroupVersionKind aliases
+type GroupKind = schema.GroupKind
+type GroupVersion = schema.GroupVersion
+type GroupVersionKind = schema.GroupVersionKind
+
+// Client-related Object aliases
+type Object = client.Object
+type ObjectKey = types.NamespacedName
+type ObjectList = client.ObjectList
+type Patch = client.Patch
+
+// Client-related Option aliases
+type ListOption = client.ListOption
+type CreateOption = client.CreateOption
+type UpdateOption = client.UpdateOption
+type PatchOption = client.PatchOption
+type DeleteOption = client.DeleteOption
+type DeleteAllOfOption = client.DeleteAllOfOption
+
+// Helper functions from client.
+var ObjectKeyFromObject = client.ObjectKeyFromObject
+
+// Namespacer is an interface that lets the caller know if a GroupKind is namespaced
+// or not. There are two ready-made implementations:
+// 1. RESTMapperToNamespacer
+// 2. NewStaticNamespacer
+type Namespacer interface {
+	// IsNamespaced returns true if the GroupKind is a namespaced type
+	IsNamespaced(gk schema.GroupKind) (bool, error)
+}
+
+// TODO: Investigate if the ObjectRecognizer should return unversioned
+// or versioned ObjectID's
+type ObjectRecognizer interface {
+	ResolveObjectID(ctx context.Context, fileName string, content []byte) (ObjectID, error)
+}
+
+// UnversionedObjectID represents an ID for an Object whose version is not known.
+// However, the Group, Kind, Name and optionally, Namespace is known and should
+// uniquely identify the Object at a specific moment in time.
+type UnversionedObjectID interface {
+	GroupKind() GroupKind
+	ObjectKey() ObjectKey
+
+	WithVersion(version string) ObjectID
+}
+
+// ObjectID is a superset of UnversionedObjectID, that also specifies an exact version.
+type ObjectID interface {
+	UnversionedObjectID
+
+	GroupVersionKind() GroupVersionKind
+}
+
+// VersionRef is an interface that describes a reference to a specific version
+// of Objects in a Storage or Client.
+type VersionRef interface {
+	// String returns the commit or branch name.
+	String() string
+	// IsWritable determines if the VersionRef points to such a state where it
+	// is possible to write on top of it, i.e. as in the case of a Git branch.
+	//
+	// A specific Git commit, however, isn't considered writable, as it points
+	// to a specific point in time that can't just be rewritten, (assuming this
+	// library only is additive, which it is).
+	IsWritable() bool
+	// IsZeroValue determines if this VersionRef is the "zero value", which means
+	// that the caller should figure out how to handle that the user did not
+	// give specific opinions of what version of the Object to get.
+	IsZeroValue() bool
+}
diff --git a/pkg/storage/core/namespaces.go b/pkg/storage/core/namespaces.go
new file mode 100644
index 0000000..d0929f5
--- /dev/null
+++ b/pkg/storage/core/namespaces.go
@@ -0,0 +1,37 @@
+package core
+
+import (
+	"k8s.io/apimachinery/pkg/runtime/schema"
+)
+
+// StaticNamespacer implements Namespacer
+var _ Namespacer = StaticNamespacer{}
+
+// StaticNamespacer has a default policy, which is that objects are in general namespaced
+// (NamespacedIsDefaultPolicy == true), or that they are in general root-scoped
+// (NamespacedIsDefaultPolicy == false).
+//
+// To the default policy, Exceptions can be added, so that for that GroupKind, the default
+// policy is reversed.
+type StaticNamespacer struct {
+	NamespacedIsDefaultPolicy bool
+	Exceptions                []schema.GroupKind
+}
+
+func (n StaticNamespacer) IsNamespaced(gk schema.GroupKind) (bool, error) {
+	if n.NamespacedIsDefaultPolicy {
+		// namespace by default, the gks list is a list of root-scoped entities
+		return !n.gkIsException(gk), nil
+	}
+	// root by default, the gks in the list are namespaced
+	return n.gkIsException(gk), nil
+}
+
+func (n StaticNamespacer) gkIsException(target schema.GroupKind) bool {
+	for _, gk := range n.Exceptions {
+		if gk == target {
+			return true
+		}
+	}
+	return false
+}
diff --git a/pkg/storage/core/objectid.go b/pkg/storage/core/objectid.go
new file mode 100644
index 0000000..8dc747b
--- /dev/null
+++ b/pkg/storage/core/objectid.go
@@ -0,0 +1,29 @@
+package core
+
+import "k8s.io/apimachinery/pkg/runtime/schema"
+
+// NewUnversionedObjectID creates a new UnversionedObjectID from the given GroupKind and ObjectKey.
+func NewUnversionedObjectID(gk GroupKind, key ObjectKey) UnversionedObjectID {
+	return unversionedObjectID{gk, key}
+}
+
+type unversionedObjectID struct {
+	gk  GroupKind
+	key ObjectKey
+}
+
+func (o unversionedObjectID) GroupKind() GroupKind                { return o.gk }
+func (o unversionedObjectID) ObjectKey() ObjectKey                { return o.key }
+func (o unversionedObjectID) WithVersion(version string) ObjectID { return objectID{o, version} }
+
+// NewObjectID creates a new ObjectID from the given GroupVersionKind and ObjectKey.
+func NewObjectID(gvk GroupVersionKind, key ObjectKey) ObjectID {
+	return objectID{unversionedObjectID{gvk.GroupKind(), key}, gvk.Version}
+}
+
+type objectID struct {
+	unversionedObjectID
+	version string
+}
+
+func (o objectID) GroupVersionKind() schema.GroupVersionKind { return o.gk.WithVersion(o.version) }
diff --git a/pkg/storage/core/recognizer.go b/pkg/storage/core/recognizer.go
new file mode 100644
index 0000000..fac0fe1
--- /dev/null
+++ b/pkg/storage/core/recognizer.go
@@ -0,0 +1,58 @@
+package core
+
+import (
+	"context"
+	"errors"
+	"fmt"
+
+	"github.com/weaveworks/libgitops/pkg/serializer"
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+)
+
+// SerializerObjectRecognizer implements ObjectRecognizer.
+var _ ObjectRecognizer = &SerializerObjectRecognizer{}
+
+// SerializerObjectRecognizer is a simple implementation of ObjectRecognizer, that
+// decodes the given byte content with the assumption that it is YAML (which covers
+// both YAML and JSON formats) into a *metav1.PartialObjectMetadata, which allows
+// extracting the ObjectID from any Kubernetes API Machinery-compatible Object.
+//
+// This operation works even though *metav1.PartialObjectMetadata is not registered
+// with the underlying Scheme in any way.
+type SerializerObjectRecognizer struct {
+	// Serializer is a required field in order for ResolveObjectID to function.
+	Serializer serializer.Serializer
+	// AllowUnrecognized controls whether this implementation allows recognizing
+	// GVK combinations not known to the underlying Scheme. Default: false
+	AllowUnrecognized bool
+}
+
+func (r *SerializerObjectRecognizer) ResolveObjectID(_ context.Context, _ string, content []byte) (ObjectID, error) {
+	if r.Serializer == nil {
+		return nil, errors.New("programmer error: SerializerObjectRecognizer.Serializer is nil")
+	}
+	metaObj := &metav1.PartialObjectMetadata{}
+	err := r.Serializer.Decoder().DecodeInto(
+		serializer.NewSingleFrameReader(content, serializer.ContentTypeYAML),
+		metaObj,
+	)
+	if err != nil {
+		return nil, err
+	}
+	// Validate the object info
+	gvk := metaObj.GroupVersionKind()
+	if gvk.Group == "" && gvk.Version == "" {
+		return nil, fmt.Errorf(".apiVersion field must not be empty")
+	}
+	if gvk.Kind == "" {
+		return nil, fmt.Errorf(".kind field must not be empty")
+	}
+	if metaObj.Kind == "" {
+		return nil, fmt.Errorf(".metadata.name field must not be empty")
+	}
+	if !r.AllowUnrecognized && !r.Serializer.Scheme().Recognizes(gvk) {
+		return nil, fmt.Errorf("GroupVersionKind %v not recognized by the scheme", gvk)
+	}
+
+	return NewObjectID(metaObj.GroupVersionKind(), ObjectKeyFromObject(metaObj)), nil
+}
diff --git a/pkg/storage/core/versionref.go b/pkg/storage/core/versionref.go
new file mode 100644
index 0000000..c9b3892
--- /dev/null
+++ b/pkg/storage/core/versionref.go
@@ -0,0 +1,80 @@
+package core
+
+import (
+	"context"
+	"errors"
+)
+
+var versionRefKey = versionRefKeyImpl{}
+
+type versionRefKeyImpl struct{}
+
+// WithVersionRef attaches the given VersionRef to a Context (it
+// overwrites if one already exists in ctx). The key for the ref
+// is private in this package, so one must use this function to
+// register it.
+func WithVersionRef(ctx context.Context, ref VersionRef) context.Context {
+	return context.WithValue(ctx, versionRefKey, ref)
+}
+
+// GetVersionRef returns the VersionRef attached to this context.
+// If there is no attached VersionRef, or it is nil, a BranchRef
+// with branch "" will be returned as the "zero value" of VersionRef.
+func GetVersionRef(ctx context.Context) VersionRef {
+	r, ok := ctx.Value(versionRefKey).(VersionRef)
+	// Return default ref if none specified
+	if r == nil || !ok {
+		return NewBranchRef("")
+	}
+	return r
+}
+
+var ErrInvalidVersionRefType = errors.New("invalid version ref type")
+
+// NewBranchRef creates a new VersionRef for a given branch. It is
+// valid for the branch to be ""; in this case it means the "zero
+// value", or unspecified branch to be more precise, where the caller
+// can choose how to handle.
+func NewBranchRef(branch string) VersionRef { return branchRef{branch} }
+
+// NewCommitRef creates a new VersionRef for the given commit. The
+// commit must uniquely define a certain revision precisely. It must
+// not be an empty string.
+func NewCommitRef(commit string) (VersionRef, error) {
+	if len(commit) == 0 {
+		return nil, errors.New("commit must not be an empty string")
+	}
+	return commitRef{commit}, nil
+}
+
+// MustNewCommitRef runs NewCommitRef, but panics on errors
+func MustNewCommitRef(commit string) VersionRef {
+	ref, err := NewCommitRef(commit)
+	if err != nil {
+		panic(err)
+	}
+	return ref
+}
+
+type branchRef struct{ branch string }
+
+func (r branchRef) String() string { return r.branch }
+
+// A branch is considered writable, as commits can be added to it by libgitops
+func (branchRef) IsWritable() bool { return true }
+
+// A branch is considered the zero value if the branch is an empty string,
+// which it is e.g. when there was no VersionRef associated with a Context.
+func (r branchRef) IsZeroValue() bool { return r.branch == "" }
+
+type commitRef struct{ commit string }
+
+func (r commitRef) String() string { return r.commit }
+
+// A commit is not considered writable, as it is only a read snapshot of
+// a specific point in time.
+func (commitRef) IsWritable() bool { return false }
+
+// IsZeroValue should always return false for commits; as commit is mandatory
+// to be a non-empty string.
+func (r commitRef) IsZeroValue() bool { return r.commit == "" }
diff --git a/pkg/storage/event/event.go b/pkg/storage/event/event.go
new file mode 100644
index 0000000..3f57fdb
--- /dev/null
+++ b/pkg/storage/event/event.go
@@ -0,0 +1,48 @@
+package event
+
+import (
+	"fmt"
+
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+)
+
+// ObjectEventType is an enum describing a change in an Object's state.
+type ObjectEventType byte
+
+var _ fmt.Stringer = ObjectEventType(0)
+
+const (
+	ObjectEventNone   ObjectEventType = iota // 0
+	ObjectEventCreate                        // 1
+	ObjectEventUpdate                        // 2
+	ObjectEventDelete                        // 3
+	ObjectEventSync                          // 4
+)
+
+func (o ObjectEventType) String() string {
+	switch o {
+	case 0:
+		return "NONE"
+	case 1:
+		return "CREATE"
+	case 2:
+		return "UPDATE"
+	case 3:
+		return "DELETE"
+	case 4:
+		return "SYNC"
+	}
+
+	// Should never happen
+	return "UNKNOWN"
+}
+
+// ObjectEvent describes a change that has been observed
+// for the given object with the given ID.
+type ObjectEvent struct {
+	ID   core.UnversionedObjectID
+	Type ObjectEventType
+}
+
+// ObjectEventStream is a channel of ObjectEvents
+type ObjectEventStream chan *ObjectEvent
diff --git a/pkg/storage/event/interfaces.go b/pkg/storage/event/interfaces.go
new file mode 100644
index 0000000..b13c186
--- /dev/null
+++ b/pkg/storage/event/interfaces.go
@@ -0,0 +1,31 @@
+package event
+
+import (
+	"context"
+	"io"
+
+	"github.com/weaveworks/libgitops/pkg/storage"
+)
+
+// StorageCommon contains the methods that EventStorage adds to the
+// to the normal Storage.
+type StorageCommon interface {
+	// WatchForObjectEvents starts feeding ObjectEvents into the given "into"
+	// channel. The caller is responsible for setting a channel buffering
+	// limit large enough to not block normal operation. An error might
+	// be returned if a maximum amount of watches has been opened already,
+	// e.g. ErrTooManyWatches.
+	WatchForObjectEvents(ctx context.Context, into ObjectEventStream) error
+
+	// Close closes the EventStorage and underlying resources gracefully.
+	io.Closer
+}
+
+// EventStorage is the abstract combination of a normal Storage, and
+// a possiblility to listen for changes to objects as they change.
+// TODO: Maybe we could use some of controller-runtime's built-in functionality
+// for watching for changes?
+type EventStorage interface {
+	storage.Storage
+	StorageCommon
+}
diff --git a/pkg/storage/filesystem/dir_traversal.go b/pkg/storage/filesystem/dir_traversal.go
new file mode 100644
index 0000000..12284d7
--- /dev/null
+++ b/pkg/storage/filesystem/dir_traversal.go
@@ -0,0 +1,37 @@
+package filesystem
+
+import (
+	"context"
+	"os"
+)
+
+// ListValidFilesInFilesystem discovers files in the given Filesystem that has a
+// ContentType that contentTyper recognizes, and is not a path that is excluded by
+// pathExcluder.
+func ListValidFilesInFilesystem(ctx context.Context, fs Filesystem, contentTyper ContentTyper, pathExcluder PathExcluder) (files []string, err error) {
+	err = fs.Walk(ctx, "", func(path string, info os.FileInfo, err error) error {
+		if err != nil {
+			return err
+		}
+
+		// Only include valid files
+		if !info.IsDir() && IsValidFileInFilesystem(ctx, fs, contentTyper, pathExcluder, path) {
+			files = append(files, path)
+		}
+		return nil
+	})
+	return
+}
+
+// IsValidFileInFilesystem checks if file (a relative path) has a ContentType
+// that contentTyper recognizes, and is not a path that is excluded by pathExcluder.
+func IsValidFileInFilesystem(ctx context.Context, fs Filesystem, contentTyper ContentTyper, pathExcluder PathExcluder, file string) bool {
+	// return false if this path should be excluded
+	if pathExcluder.ShouldExcludePath(file) {
+		return false
+	}
+
+	// If the content type is valid for this path, err == nil => return true
+	_, err := contentTyper.ContentTypeForPath(ctx, fs, file)
+	return err == nil
+}
diff --git a/pkg/storage/filesystem/fileevents/events.go b/pkg/storage/filesystem/fileevents/events.go
new file mode 100644
index 0000000..38c385a
--- /dev/null
+++ b/pkg/storage/filesystem/fileevents/events.go
@@ -0,0 +1,36 @@
+package fileevents
+
+// FileEventType is an enum describing a change in a file's state
+type FileEventType byte
+
+const (
+	FileEventNone   FileEventType = iota // 0
+	FileEventModify                      // 1
+	FileEventDelete                      // 2
+	FileEventMove                        // 3
+)
+
+func (e FileEventType) String() string {
+	switch e {
+	case 0:
+		return "NONE"
+	case 1:
+		return "MODIFY"
+	case 2:
+		return "DELETE"
+	case 3:
+		return "MOVE"
+	}
+
+	return "UNKNOWN"
+}
+
+// FileEvent describes a file change of a certain kind at a certain
+// (relative) path. Often emitted by FileEventsEmitter.
+type FileEvent struct {
+	Path string
+	Type FileEventType
+}
+
+// FileEventStream is a channel of FileEvents
+type FileEventStream chan *FileEvent
diff --git a/pkg/util/watcher/filewatcher.go b/pkg/storage/filesystem/fileevents/inotify/filewatcher.go
similarity index 52%
rename from pkg/util/watcher/filewatcher.go
rename to pkg/storage/filesystem/fileevents/inotify/filewatcher.go
index 67db335..58d8518 100644
--- a/pkg/util/watcher/filewatcher.go
+++ b/pkg/storage/filesystem/fileevents/inotify/filewatcher.go
@@ -1,46 +1,26 @@
-package watcher
+package inotify
 
 import (
+	"context"
 	"fmt"
-	"path"
+	"path/filepath"
+	gosync "sync"
 	"time"
 
 	"github.com/rjeczalik/notify"
+	"github.com/sirupsen/logrus"
 	log "github.com/sirupsen/logrus"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem/fileevents"
 	"github.com/weaveworks/libgitops/pkg/util/sync"
 	"golang.org/x/sys/unix"
+	"k8s.io/apimachinery/pkg/util/sets"
 )
 
-const eventBuffer = 4096 // How many events and updates we can buffer before watching is interrupted
 var listenEvents = []notify.Event{notify.InDelete, notify.InCloseWrite, notify.InMovedFrom, notify.InMovedTo}
 
-var eventMap = map[notify.Event]FileEvent{
-	notify.InDelete:     FileEventDelete,
-	notify.InCloseWrite: FileEventModify,
-}
-
-// combinedEvent describes multiple events that should be concatenated into a single event
-type combinedEvent struct {
-	input  []notify.Event // input is a slice of events to match (in bytes, it speeds up the comparison)
-	output int            // output is the event's index that should be returned, negative values equal nil
-}
-
-func (c *combinedEvent) match(events notifyEvents) (notify.EventInfo, bool) {
-	if len(c.input) > len(events) {
-		return nil, false // Not enough events, cannot match
-	}
-
-	for i := 0; i < len(c.input); i++ {
-		if events[i].Event() != c.input[i] {
-			return nil, false
-		}
-	}
-
-	if c.output > 0 {
-		return events[c.output], true
-	}
-
-	return nil, true
+var eventMap = map[notify.Event]fileevents.FileEventType{
+	notify.InDelete:     fileevents.FileEventDelete,
+	notify.InCloseWrite: fileevents.FileEventModify,
 }
 
 // combinedEvents describes the event combinations to concatenate,
@@ -54,99 +34,113 @@ var combinedEvents = []combinedEvent{
 
 type notifyEvents []notify.EventInfo
 type eventStream chan notify.EventInfo
-type FileUpdateStream chan *FileUpdate
-
-// Options specifies options for the FileWatcher
-type Options struct {
-	// ExcludeDirs specifies what directories to not watch
-	ExcludeDirs []string
-	// BatchTimeout specifies the duration to wait after last event before dispatching grouped inotify events
-	BatchTimeout time.Duration
-	// ValidExtensions specifies what file extensions to look at
-	ValidExtensions []string
-}
 
-// DefaultOptions returns the default options
-func DefaultOptions() Options {
-	return Options{
-		ExcludeDirs:     []string{".git"},
-		BatchTimeout:    1 * time.Second,
-		ValidExtensions: []string{".yaml", ".yml", ".json"},
-	}
-}
+// FileEvents is a slice of FileEvent pointers
+type FileEvents []*fileevents.FileEvent
 
 // NewFileWatcher returns a list of files in the watched directory in
 // addition to the generated FileWatcher, it can be used to populate
 // MappedRawStorage fileMappings
-func NewFileWatcher(dir string) (w *FileWatcher, files []string, err error) {
-	return NewFileWatcherWithOptions(dir, DefaultOptions())
-}
+func NewFileWatcher(dir string, opts ...FileWatcherOption) (fileevents.Emitter, error) {
+	o := defaultOptions().ApplyOptions(opts)
 
-// NewFileWatcher returns a list of files in the watched directory in
-// addition to the generated FileWatcher, it can be used to populate
-// MappedRawStorage fileMappings
-func NewFileWatcherWithOptions(dir string, opts Options) (w *FileWatcher, files []string, err error) {
-	w = &FileWatcher{
-		dir:     dir,
-		events:  make(eventStream, eventBuffer),
-		updates: make(FileUpdateStream, eventBuffer),
-		batcher: sync.NewBatchWriter(opts.BatchTimeout),
-		opts:    opts,
+	w := &FileWatcher{
+		dir: dir,
+
+		inbound: make(eventStream, int(o.EventBufferSize)),
+		// outbound is set by WatchForFileEvents
+		outboundMu: &gosync.Mutex{},
+
+		suspendFiles:   sets.NewString(),
+		suspendFilesMu: &gosync.Mutex{},
+
+		// monitor and dispatcher set by WatchForFileEvents, guarded by outboundMu
+
+		opts: *o,
+
+		batcher: sync.NewBatchWriter(o.BatchTimeout),
 	}
 
 	log.Tracef("FileWatcher: Starting recursive watch for %q", dir)
-	if err = notify.Watch(path.Join(dir, "..."), w.events, listenEvents...); err != nil {
-		notify.Stop(w.events)
-	} else if files, err = w.getFiles(); err == nil {
-		w.monitor = sync.RunMonitor(w.monitorFunc)
-		w.dispatcher = sync.RunMonitor(w.dispatchFunc)
+	if err := notify.Watch(filepath.Join(dir, "..."), w.inbound, listenEvents...); err != nil {
+		notify.Stop(w.inbound)
+		return nil, err
 	}
 
-	return
+	return w, nil
 }
 
+var _ fileevents.Emitter = &FileWatcher{}
+
 // FileWatcher recursively monitors changes in files in the given directory
 // and sends out events based on their state changes. Only files conforming
 // to validSuffix are monitored. The FileWatcher can be suspended for a single
 // event at a time to eliminate updates by WatchStorage causing a loop.
 type FileWatcher struct {
-	dir          string
-	events       eventStream
-	updates      FileUpdateStream
-	suspendEvent FileEvent
-	monitor      *sync.Monitor
-	dispatcher   *sync.Monitor
-	opts         Options
+	dir string
+	// channels
+	inbound    eventStream
+	outbound   fileevents.FileEventStream
+	outboundMu *gosync.Mutex
+	// new suspend logic
+	suspendFiles   sets.String
+	suspendFilesMu *gosync.Mutex
+	// goroutines
+	monitor    *sync.Monitor
+	dispatcher *sync.Monitor
+
+	// opts
+	opts FileWatcherOptions
 	// the batcher is used for properly sending many concurrent inotify events
 	// as a group, after a specified timeout. This fixes the issue of one single
 	// file operation being registered as many different inotify events
 	batcher *sync.BatchWriter
 }
 
-func (w *FileWatcher) monitorFunc() {
+func (w *FileWatcher) WatchForFileEvents(ctx context.Context, into fileevents.FileEventStream) error {
+	w.outboundMu.Lock()
+	defer w.outboundMu.Unlock()
+	// We don't support more than one listener
+	// TODO: maybe support many listeners in the future?
+	if w.outbound != nil {
+		return fmt.Errorf("FileWatcher: not more than one watch supported: %w", fileevents.ErrTooManyWatches)
+	}
+	w.outbound = into
+	// Start the backing goroutines
+	w.monitor = sync.RunMonitor(w.monitorFunc)
+	w.dispatcher = sync.RunMonitor(w.dispatchFunc)
+	return nil // all ok
+}
+
+func (w *FileWatcher) monitorFunc() error {
 	log.Debug("FileWatcher: Monitoring thread started")
 	defer log.Debug("FileWatcher: Monitoring thread stopped")
-	defer close(w.updates) // Close the update stream after the FileWatcher has stopped
+	defer close(w.outbound) // Close the update stream after the FileWatcher has stopped
 
 	for {
-		event, ok := <-w.events
+		event, ok := <-w.inbound
 		if !ok {
-			return
+			logrus.Debug("FileWatcher: Got non-ok channel recieve from w.inbound, exiting monitorFunc")
+			return nil
 		}
 
 		if ievent(event).Mask&unix.IN_ISDIR != 0 {
 			continue // Skip directories
 		}
 
-		if !w.validFile(event.Path()) {
-			continue // Skip invalid files
+		// Get the relative path between the root directory and the changed file
+		// Note: This is just used for the PathExcluder, absolute paths are used
+		// in the underlying file-change computation system, until in sendUpdate
+		// where they are converted into relative paths before sending to the listener.
+		relativePath, err := filepath.Rel(w.dir, event.Path())
+		if err != nil {
+			logrus.Errorf("FileWatcher: Error occurred when computing relative path between: %s and %s: %v", w.dir, event.Path(), err)
+			continue
 		}
 
-		updateEvent := convertEvent(event.Event())
-		if w.suspendEvent > 0 && updateEvent == w.suspendEvent {
-			w.suspendEvent = 0
-			log.Debugf("FileWatcher: Skipping suspended event %s for path: %q", updateEvent, event.Path())
-			continue // Skip the suspended event
+		// The PathExcluder only operates on relative paths.
+		if w.opts.PathExcluder.ShouldExcludePath(relativePath) {
+			continue // Skip ignored files
 		}
 
 		// Get any events registered for the specific file, and append the specified event
@@ -158,18 +152,20 @@ func (w *FileWatcher) monitorFunc() {
 		eventList = append(eventList, event)
 
 		// Register the event in the map, and dispatch all the events at once after the timeout
+		// Note that event.Path() is just the unique key for the map here, it is not actually
+		// used later when computing the changes of the filesystem.
 		w.batcher.Store(event.Path(), eventList)
 		log.Debugf("FileWatcher: Registered inotify events %v for path %q", eventList, event.Path())
 	}
 }
 
-func (w *FileWatcher) dispatchFunc() {
+func (w *FileWatcher) dispatchFunc() error {
 	log.Debug("FileWatcher: Dispatch thread started")
 	defer log.Debug("FileWatcher: Dispatch thread stopped")
 
 	for {
 		// Wait until we have a batch dispatched to us
-		ok := w.batcher.ProcessBatch(func(key, val interface{}) bool {
+		ok := w.batcher.ProcessBatch(func(_, val interface{}) bool {
 			// Concatenate all known events, and dispatch them to be handled one by one
 			for _, event := range w.concatenateEvents(val.(notifyEvents)) {
 				w.sendUpdate(event)
@@ -179,56 +175,85 @@ func (w *FileWatcher) dispatchFunc() {
 			return true
 		})
 		if !ok {
-			return // The BatchWriter channel is closed, stop processing
+			logrus.Debug("FileWatcher: Got non-ok channel recieve from w.batcher, exiting dispatchFunc")
+			return nil // The BatchWriter channel is closed, stop processing
 		}
 
 		log.Debug("FileWatcher: Dispatched events batch and reset the events cache")
 	}
 }
 
-func (w *FileWatcher) sendUpdate(update *FileUpdate) {
-	log.Debugf("FileWatcher: Sending update: %s -> %q", update.Event, update.Path)
-	w.updates <- update
-}
+func (w *FileWatcher) sendUpdate(event *fileevents.FileEvent) {
+	// Get the relative path between the root directory and the changed file
+	relativePath, err := filepath.Rel(w.dir, event.Path)
+	if err != nil {
+		logrus.Errorf("FileWatcher: Error occurred when computing relative path between: %s and %s: %v", w.dir, event.Path, err)
+		return
+	}
+	// Replace the full path with the relative path for the signaling upstream
+	event.Path = relativePath
 
-// GetFileUpdateStream gets the channel with FileUpdates
-func (w *FileWatcher) GetFileUpdateStream() FileUpdateStream {
-	return w.updates
+	if w.shouldSuspendEvent(event.Path) {
+		log.Debugf("FileWatcher: Skipping suspended event %s for path: %q", event.Type, event.Path)
+		return // Skip the suspended event
+	}
+
+	log.Debugf("FileWatcher: Sending update: %s -> %q", event.Type, event.Path)
+	w.outbound <- event
 }
 
 // Close closes active underlying resources
-func (w *FileWatcher) Close() {
-	notify.Stop(w.events)
+func (w *FileWatcher) Close() error {
+	notify.Stop(w.inbound)
 	w.batcher.Close()
-	close(w.events) // Close the event stream
-	w.monitor.Wait()
-	w.dispatcher.Wait()
+	close(w.inbound) // Close the inbound event stream
+	// No need to check the error here, as we only return nil above
+	_ = w.monitor.Wait()
+	_ = w.dispatcher.Wait()
+	return nil
 }
 
-// Suspend enables a one-time suspend of the given event,
-// the FileWatcher will skip the given event once
-func (w *FileWatcher) Suspend(updateEvent FileEvent) {
-	w.suspendEvent = updateEvent
+// Suspend enables a one-time suspend of the given path
+// TODO: clarify how the path should be formatted
+func (w *FileWatcher) Suspend(_ context.Context, path string) {
+	w.suspendFilesMu.Lock()
+	defer w.suspendFilesMu.Unlock()
+	w.suspendFiles.Insert(path)
 }
 
-func convertEvent(event notify.Event) FileEvent {
+// shouldSuspendEvent checks if an event for the given path
+// should be suspended for one time. If it should, true will
+// be returned, and the mapping will be removed next time.
+func (w *FileWatcher) shouldSuspendEvent(path string) bool {
+	w.suspendFilesMu.Lock()
+	defer w.suspendFilesMu.Unlock()
+	// If the path should not be suspended, just return false and be done
+	if !w.suspendFiles.Has(path) {
+		return false
+	}
+	// Otherwise, remove it from the list and mark it as suspended
+	w.suspendFiles.Delete(path)
+	return true
+}
+
+func convertEvent(event notify.Event) fileevents.FileEventType {
 	if updateEvent, ok := eventMap[event]; ok {
 		return updateEvent
 	}
 
-	return FileEventNone
+	return fileevents.FileEventNone
 }
 
-func convertUpdate(event notify.EventInfo) *FileUpdate {
+func convertUpdate(event notify.EventInfo) *fileevents.FileEvent {
 	fileEvent := convertEvent(event.Event())
-	if fileEvent == FileEventNone {
+	if fileEvent == fileevents.FileEventNone {
 		// This should never happen
 		panic(fmt.Sprintf("invalid event for update conversion: %q", event.Event().String()))
 	}
 
-	return &FileUpdate{
-		Event: fileEvent,
-		Path:  event.Path(),
+	return &fileevents.FileEvent{
+		Path: event.Path(),
+		Type: fileEvent,
 	}
 }
 
@@ -247,7 +272,7 @@ func (w *FileWatcher) newMoveCache(event notify.EventInfo) *moveCache {
 	}
 
 	// moveCaches wait one second to be cancelled before firing
-	m.timer = time.AfterFunc(time.Second, m.incomplete)
+	m.timer = time.AfterFunc(w.opts.BatchTimeout, m.incomplete)
 	return m
 }
 
@@ -260,42 +285,53 @@ func (m *moveCache) cookie() uint32 {
 // if only one is received, the file is moved in/out of a watched directory, which
 // is treated as a normal creation/deletion by this method.
 func (m *moveCache) incomplete() {
-	var event FileEvent
+	var evType fileevents.FileEventType
 
 	switch m.event.Event() {
 	case notify.InMovedFrom:
-		event = FileEventDelete
+		evType = fileevents.FileEventDelete
 	case notify.InMovedTo:
-		event = FileEventModify
+		evType = fileevents.FileEventModify
 	default:
 		// This should never happen
 		panic(fmt.Sprintf("moveCache: unrecognized event: %v", m.event.Event()))
 	}
 
 	log.Tracef("moveCache: Timer expired for %d, dispatching...", m.cookie())
-	m.watcher.sendUpdate(&FileUpdate{event, m.event.Path()})
+	m.watcher.sendUpdate(&fileevents.FileEvent{Path: m.event.Path(), Type: evType})
 
 	// Delete the cache after the timer has fired
+	moveCachesMu.Lock()
 	delete(moveCaches, m.cookie())
+	moveCachesMu.Unlock()
 }
 
 func (m *moveCache) cancel() {
 	m.timer.Stop()
+	moveCachesMu.Lock()
 	delete(moveCaches, m.cookie())
+	moveCachesMu.Unlock()
 	log.Tracef("moveCache: Dispatching cancelled for %d", m.cookie())
 }
 
-// moveCaches keeps track of active moves by cookie
-var moveCaches = make(map[uint32]*moveCache)
+var (
+	// moveCaches keeps track of active moves by cookie
+	moveCaches   = make(map[uint32]*moveCache)
+	moveCachesMu = &gosync.RWMutex{}
+)
 
 // move processes InMovedFrom and InMovedTo events in any order
 // and dispatches FileUpdates when a move is detected
-func (w *FileWatcher) move(event notify.EventInfo) (moveUpdate *FileUpdate) {
+func (w *FileWatcher) move(event notify.EventInfo) (moveUpdate *fileevents.FileEvent) {
 	cookie := ievent(event).Cookie
+	moveCachesMu.RLock()
 	cache, ok := moveCaches[cookie]
+	moveCachesMu.RUnlock()
 	if !ok {
 		// The cookie is not cached, create a new cache object for it
+		moveCachesMu.Lock()
 		moveCaches[cookie] = w.newMoveCache(event)
+		moveCachesMu.Unlock()
 		return
 	}
 
@@ -305,8 +341,8 @@ func (w *FileWatcher) move(event notify.EventInfo) (moveUpdate *FileUpdate) {
 		sourcePath, destPath = destPath, sourcePath
 		fallthrough
 	case notify.InMovedTo:
-		cache.cancel()                                    // Cancel dispatching the cache's incomplete move
-		moveUpdate = &FileUpdate{FileEventMove, destPath} // Register an internal, complete move instead
+		cache.cancel()                                                                     // Cancel dispatching the cache's incomplete move
+		moveUpdate = &fileevents.FileEvent{Path: destPath, Type: fileevents.FileEventMove} // Register an internal, complete move instead
 		log.Tracef("FileWatcher: Detected move: %q -> %q", sourcePath, destPath)
 	}
 
@@ -315,8 +351,8 @@ func (w *FileWatcher) move(event notify.EventInfo) (moveUpdate *FileUpdate) {
 
 // concatenateEvents takes in a slice of events and concatenates
 // all events possible based on combinedEvents. It also manages
-// file moving and conversion from notifyEvents to FileUpdates
-func (w *FileWatcher) concatenateEvents(events notifyEvents) FileUpdates {
+// file moving and conversion from notifyEvents to FileEvents
+func (w *FileWatcher) concatenateEvents(events notifyEvents) FileEvents {
 	for _, combinedEvent := range combinedEvents {
 		// Test if the prefix of the given events matches combinedEvent.input
 		if event, ok := combinedEvent.match(events); ok {
@@ -332,7 +368,7 @@ func (w *FileWatcher) concatenateEvents(events notifyEvents) FileUpdates {
 	}
 
 	// Convert the events to updates
-	updates := make(FileUpdates, 0, len(events))
+	updates := make(FileEvents, 0, len(events))
 	for _, event := range events {
 		switch event.Event() {
 		case notify.InMovedFrom, notify.InMovedTo:
@@ -352,3 +388,27 @@ func (w *FileWatcher) concatenateEvents(events notifyEvents) FileUpdates {
 func ievent(event notify.EventInfo) *unix.InotifyEvent {
 	return event.Sys().(*unix.InotifyEvent)
 }
+
+// combinedEvent describes multiple events that should be concatenated into a single event
+type combinedEvent struct {
+	input  []notify.Event // input is a slice of events to match (in bytes, it speeds up the comparison)
+	output int            // output is the event's index that should be returned, negative values equal nil
+}
+
+func (c *combinedEvent) match(events notifyEvents) (notify.EventInfo, bool) {
+	if len(c.input) > len(events) {
+		return nil, false // Not enough events, cannot match
+	}
+
+	for i := 0; i < len(c.input); i++ {
+		if events[i].Event() != c.input[i] {
+			return nil, false
+		}
+	}
+
+	if c.output > 0 {
+		return events[c.output], true
+	}
+
+	return nil, true
+}
diff --git a/pkg/util/watcher/filewatcher_test.go b/pkg/storage/filesystem/fileevents/inotify/filewatcher_test.go
similarity index 60%
rename from pkg/util/watcher/filewatcher_test.go
rename to pkg/storage/filesystem/fileevents/inotify/filewatcher_test.go
index b80f9b2..c423f24 100644
--- a/pkg/util/watcher/filewatcher_test.go
+++ b/pkg/storage/filesystem/fileevents/inotify/filewatcher_test.go
@@ -1,9 +1,12 @@
-package watcher
+package inotify
 
 import (
+	"fmt"
+	"strings"
 	"testing"
 
 	"github.com/rjeczalik/notify"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem/fileevents"
 	"golang.org/x/sys/unix"
 )
 
@@ -51,33 +54,33 @@ var testEvents = []notifyEvents{
 	},
 }
 
-var targets = []FileEvents{
+var targets = []FileEventTypes{
 	{
-		FileEventModify,
+		fileevents.FileEventModify,
 	},
 	{
-		FileEventDelete,
+		fileevents.FileEventDelete,
 	},
 	{
-		FileEventModify,
-		FileEventMove,
-		FileEventDelete,
+		fileevents.FileEventModify,
+		fileevents.FileEventMove,
+		fileevents.FileEventDelete,
 	},
 	{
-		FileEventModify,
+		fileevents.FileEventModify,
 	},
 	{},
 }
 
-func extractEvents(updates FileUpdates) (events FileEvents) {
-	for _, update := range updates {
-		events = append(events, update.Event)
+func extractEventTypes(events FileEvents) (eventTypes FileEventTypes) {
+	for _, event := range events {
+		eventTypes = append(eventTypes, event.Type)
 	}
 
 	return
 }
 
-func eventsEqual(a, b FileEvents) bool {
+func eventsEqual(a, b FileEventTypes) bool {
 	if len(a) != len(b) {
 		return false
 	}
@@ -91,9 +94,23 @@ func eventsEqual(a, b FileEvents) bool {
 	return true
 }
 
+// FileEventTypes is a slice of FileEventType
+type FileEventTypes []fileevents.FileEventType
+
+var _ fmt.Stringer = FileEventTypes{}
+
+func (e FileEventTypes) String() string {
+	strs := make([]string, 0, len(e))
+	for _, ev := range e {
+		strs = append(strs, ev.String())
+	}
+
+	return strings.Join(strs, ",")
+}
+
 func TestEventConcatenation(t *testing.T) {
 	for i, e := range testEvents {
-		result := extractEvents((&FileWatcher{}).concatenateEvents(e))
+		result := extractEventTypes((&FileWatcher{}).concatenateEvents(e))
 		if !eventsEqual(result, targets[i]) {
 			t.Errorf("wrong concatenation result: %v != %v", result, targets[i])
 		}
diff --git a/pkg/storage/filesystem/fileevents/inotify/options.go b/pkg/storage/filesystem/fileevents/inotify/options.go
new file mode 100644
index 0000000..2c48e5d
--- /dev/null
+++ b/pkg/storage/filesystem/fileevents/inotify/options.go
@@ -0,0 +1,59 @@
+package inotify
+
+import (
+	"time"
+
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem"
+)
+
+// How many inotify events we can buffer before watching is interrupted
+const DefaultEventBufferSize int32 = 4096
+
+type FileWatcherOption interface {
+	ApplyToFileWatcher(*FileWatcherOptions)
+}
+
+var _ FileWatcherOption = &FileWatcherOptions{}
+
+// FileWatcherOptions specifies options for the FileWatcher
+type FileWatcherOptions struct {
+	// BatchTimeout specifies the duration to wait after last event
+	// before dispatching grouped inotify events
+	// Default: 1s
+	BatchTimeout time.Duration
+	// EventBufferSize describes how many inotify events can be buffered
+	// before watching is interrupted/delayed.
+	// Default: DefaultEventBufferSize
+	EventBufferSize int32
+	// PathExcluder provides a way to exclude paths.
+	// Default: filesystem.DefaultPathExcluders()
+	PathExcluder filesystem.PathExcluder
+}
+
+func (o *FileWatcherOptions) ApplyToFileWatcher(target *FileWatcherOptions) {
+	if o.BatchTimeout != 0 {
+		target.BatchTimeout = o.BatchTimeout
+	}
+	if o.EventBufferSize != 0 {
+		target.EventBufferSize = o.EventBufferSize
+	}
+	if o.PathExcluder != nil {
+		target.PathExcluder = o.PathExcluder
+	}
+}
+
+func (o *FileWatcherOptions) ApplyOptions(opts []FileWatcherOption) *FileWatcherOptions {
+	for _, opt := range opts {
+		opt.ApplyToFileWatcher(o)
+	}
+	return o
+}
+
+// defaultOptions returns the default options
+func defaultOptions() *FileWatcherOptions {
+	return &FileWatcherOptions{
+		BatchTimeout:    1 * time.Second,
+		EventBufferSize: DefaultEventBufferSize,
+		PathExcluder:    filesystem.DefaultPathExcluders(),
+	}
+}
diff --git a/pkg/storage/filesystem/fileevents/interfaces.go b/pkg/storage/filesystem/fileevents/interfaces.go
new file mode 100644
index 0000000..77d7708
--- /dev/null
+++ b/pkg/storage/filesystem/fileevents/interfaces.go
@@ -0,0 +1,57 @@
+package fileevents
+
+import (
+	"context"
+	"errors"
+	"io"
+
+	"github.com/weaveworks/libgitops/pkg/storage/event"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem"
+)
+
+var (
+	// ErrTooManyWatches can happen when trying to register too many
+	// watching reciever channels to an event emitter.
+	ErrTooManyWatches = errors.New("too many watches already opened")
+)
+
+// Emitter is an interface that provides high-level inotify-like
+// behaviour to consumers. It can be used e.g. by even higher-level
+// interfaces like FilesystemEventStorage.
+type Emitter interface {
+	// WatchForFileEvents starts feeding FileEvents into the given "into"
+	// channel. The caller is responsible for setting a channel buffering
+	// limit large enough to not block normal operation. An error might
+	// be returned if a maximum amount of watches has been opened already,
+	// e.g. ErrTooManyWatches.
+	//
+	// Note that it is the receiver's responsibility to "validate" the
+	// file so it matches any user defined policy (e.g. only specific
+	// content types, or a PathExcluder has been given).
+	WatchForFileEvents(ctx context.Context, into FileEventStream) error
+
+	// Suspend blocks the next event dispatch for this given path. Useful
+	// for not sending "your own" modification events into the
+	// FileEventStream that is listening. path is relative.
+	Suspend(ctx context.Context, path string)
+
+	// Close closes the emitter gracefully.
+	io.Closer
+}
+
+// StorageCommon is an extension to event.StorageCommon that
+// also contains an underlying Emitter. This is meant to be
+// used in tandem with filesystem.Storages.
+type StorageCommon interface {
+	event.StorageCommon
+
+	// FileEventsEmitter gets the Emitter used internally.
+	FileEventsEmitter() Emitter
+}
+
+// FilesystemEventStorage is the combination of a filesystem.Storage,
+// and the possibility to listen for object updates from a Emitter.
+type FilesystemEventStorage interface {
+	filesystem.Storage
+	StorageCommon
+}
diff --git a/pkg/storage/filesystem/filefinder_simple.go b/pkg/storage/filesystem/filefinder_simple.go
new file mode 100644
index 0000000..e0e6940
--- /dev/null
+++ b/pkg/storage/filesystem/filefinder_simple.go
@@ -0,0 +1,235 @@
+package filesystem
+
+import (
+	"context"
+	"errors"
+	"fmt"
+	"os"
+	"path/filepath"
+	"strings"
+
+	"github.com/weaveworks/libgitops/pkg/serializer"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"k8s.io/apimachinery/pkg/util/sets"
+)
+
+// NewSimpleStorage is a default opinionated constructor for a Storage
+// using SimpleFileFinder as the FileFinder, and the local disk as target.
+// If you need more advanced customizablility than provided here, you can compose
+// the call to filesystem.NewGeneric yourself.
+func NewSimpleStorage(dir string, namespacer core.Namespacer, opts SimpleFileFinderOptions) (Storage, error) {
+	fs := NewOSFilesystem(dir)
+	fileFinder, err := NewSimpleFileFinder(fs, opts)
+	if err != nil {
+		return nil, err
+	}
+	// fileFinder and namespacer are validated by filesystem.NewGeneric.
+	return NewGeneric(fileFinder, namespacer)
+}
+
+func NewSimpleFileFinder(fs Filesystem, opts SimpleFileFinderOptions) (*SimpleFileFinder, error) {
+	if fs == nil {
+		return nil, fmt.Errorf("NewSimpleFileFinder: fs is mandatory")
+	}
+	ct := serializer.ContentTypeJSON
+	if len(opts.ContentType) != 0 {
+		ct = opts.ContentType
+	}
+	resolver := DefaultFileExtensionResolver
+	if opts.FileExtensionResolver != nil {
+		resolver = opts.FileExtensionResolver
+	}
+	return &SimpleFileFinder{
+		fs:           fs,
+		opts:         opts,
+		contentTyper: StaticContentTyper{ContentType: ct},
+		resolver:     resolver,
+	}, nil
+}
+
+// isObjectIDNamespaced returns true if the ID is of a namespaced GroupKind, and
+// false if the GroupKind is non-namespaced. NOTE: This ONLY works for FileFinders
+// where the Storage has made sure that the namespacing conventions are followed.
+func isObjectIDNamespaced(id core.UnversionedObjectID) bool {
+	return id.ObjectKey().Namespace != ""
+}
+
+var _ FileFinder = &SimpleFileFinder{}
+
+// SimpleFileFinder is a FileFinder-compliant implementation that
+// stores Objects on disk using a straightforward directory layout.
+//
+// The following directory layout is used:
+// if DisableGroupDirectory == false && SubDirectoryFileName == "" {
+//	<dir>/<group>/<kind>/<namespace>/<name>.<ext> 	if namespaced or
+//	<dir>/<group>/<kind>/<name>.<ext> 				if non-namespaced
+// }
+// else if DisableGroupDirectory == false && SubDirectoryFileName == "foo" {
+//	<dir>/<group>/<kind>/<namespace>/<name>/foo.<ext> 	if namespaced or
+//	<dir>/<group>/<kind>/<name>/foo.<ext> 				if non-namespaced
+// }
+// else if DisableGroupDirectory == true && SubDirectoryFileName == "" {
+//	<dir>/<kind>/<namespace>/<name>.<ext> 	if namespaced or
+//	<dir>/<kind>/<name>.<ext> 				if non-namespaced
+// }
+// else if DisableGroupDirectory == true && SubDirectoryFileName == "foo" {
+//	<dir>/<kind>/<namespace>/<name>/foo.<ext> 	if namespaced or
+//	<dir>/<kind>/<name>/foo.<ext> 				if non-namespaced
+// }
+//
+// <ext> is resolved by the FileExtensionResolver, for the given ContentType.
+//
+// This FileFinder does not support the ObjectAt method.
+type SimpleFileFinder struct {
+	fs           Filesystem
+	opts         SimpleFileFinderOptions
+	contentTyper StaticContentTyper
+	resolver     FileExtensionResolver
+}
+
+type SimpleFileFinderOptions struct {
+	// Default: false; means enable group directory
+	DisableGroupDirectory bool
+	// Default: ""; means use file names as the means of storage
+	SubDirectoryFileName string
+	// Default: serializer.ContentTypeJSON
+	ContentType serializer.ContentType
+	// Default: DefaultFileExtensionResolver
+	FileExtensionResolver FileExtensionResolver
+}
+
+// TODO: Use group name "core" if group is "" to support core k8s objects.
+
+func (f *SimpleFileFinder) Filesystem() Filesystem {
+	return f.fs
+}
+
+func (f *SimpleFileFinder) ContentTyper() ContentTyper {
+	return f.contentTyper
+}
+
+// ObjectPath gets the file path relative to the root directory
+func (f *SimpleFileFinder) ObjectPath(ctx context.Context, id core.UnversionedObjectID) (string, error) {
+	// /<kindpath>/
+	paths := []string{f.kindKeyPath(id.GroupKind())}
+
+	if isObjectIDNamespaced(id) {
+		// ./<namespace>/
+		paths = append(paths, id.ObjectKey().Namespace)
+	}
+	// Get the file extension
+	ext, err := f.ext()
+	if err != nil {
+		return "", err
+	}
+	if f.opts.SubDirectoryFileName == "" {
+		// ./<name>.<ext>
+		paths = append(paths, id.ObjectKey().Name+ext)
+	} else {
+		// ./<name>/<SubDirectoryFileName>.<ext>
+		paths = append(paths, id.ObjectKey().Name, f.opts.SubDirectoryFileName+ext)
+	}
+	return filepath.Join(paths...), nil
+}
+
+func (f *SimpleFileFinder) kindKeyPath(gk core.GroupKind) string {
+	if f.opts.DisableGroupDirectory {
+		// ./<kind>/
+		return filepath.Join(gk.Kind)
+	}
+	// ./<group>/<kind>/
+	return filepath.Join(gk.Group, gk.Kind)
+}
+
+// ObjectAt retrieves the ID containing the virtual path based
+// on the given physical file path.
+func (f *SimpleFileFinder) ObjectAt(ctx context.Context, path string) (core.UnversionedObjectID, error) {
+	return nil, errors.New("not implemented")
+}
+
+func (f *SimpleFileFinder) ext() (string, error) {
+	return f.resolver.ExtensionForContentType(f.contentTyper.ContentType)
+}
+
+// ListNamespaces lists the available namespaces for the given GroupKind.
+// This function shall only be called for namespaced objects, it is up to
+// the caller to make sure they do not call this method for root-spaced
+// objects. If any of the given rules are violated, ErrNamespacedMismatch
+// should be returned as a wrapped error.
+//
+// The implementer can choose between basing the answer strictly on e.g.
+// v1.Namespace objects that exist in the system, or just the set of
+// different namespaces that have been set on any object belonging to
+// the given GroupKind.
+func (f *SimpleFileFinder) ListNamespaces(ctx context.Context, gk core.GroupKind) (sets.String, error) {
+	entries, err := readDir(ctx, f.fs, f.kindKeyPath(gk))
+	if err != nil {
+		return nil, err
+	}
+	return sets.NewString(entries...), nil
+}
+
+// ListObjectIDs returns a list of unversioned ObjectIDs.
+// For namespaced GroupKinds, the caller must provide a namespace, and for
+// root-spaced GroupKinds, the caller must not. When namespaced, this function
+// must only return object IDs for that given namespace. If any of the given
+// rules are violated, ErrNamespacedMismatch should be returned as a wrapped error.
+func (f *SimpleFileFinder) ListObjectIDs(ctx context.Context, gk core.GroupKind, namespace string) ([]core.UnversionedObjectID, error) {
+	// If namespace is empty, the names will be in ./<kindkey>, otherwise ./<kindkey>/<ns>
+	namesDir := filepath.Join(f.kindKeyPath(gk), namespace)
+	entries, err := readDir(ctx, f.fs, namesDir)
+	if err != nil {
+		return nil, err
+	}
+	// Get the file extension
+	ext, err := f.ext()
+	if err != nil {
+		return nil, err
+	}
+	// Map the names to UnversionedObjectIDs
+	ids := make([]core.UnversionedObjectID, 0, len(entries))
+	for _, entry := range entries {
+		// Loop through all entries, and make sure they are sanitized .metadata.name's
+		if f.opts.SubDirectoryFileName != "" {
+			// If f.SubDirectoryFileName != "", the file names already match .metadata.name
+			// Make sure the metadata file ./<.metadata.name>/<SubDirectoryFileName>.<ext> actually exists
+			expectedPath := filepath.Join(namesDir, entry, f.opts.SubDirectoryFileName+ext)
+			if exists, _ := f.fs.Exists(ctx, expectedPath); !exists {
+				continue
+			}
+		} else {
+			// Storage path is ./<name>.<ext>. entry is "<name>.<ext>"
+			// Verify the extension is there and strip it from name. If ext isn't there, just continue
+			if !strings.HasSuffix(entry, ext) {
+				continue
+			}
+			// Remove the extension from the name
+			entry = strings.TrimSuffix(entry, ext)
+		}
+		// If we got this far, add the key to the list
+		ids = append(ids, core.NewUnversionedObjectID(gk, core.ObjectKey{Name: entry, Namespace: namespace}))
+	}
+	return ids, nil
+}
+
+func readDir(ctx context.Context, fs Filesystem, dir string) ([]string, error) {
+	fi, err := fs.Stat(ctx, dir)
+	if os.IsNotExist(err) {
+		// It's ok if the directory doesn't exist (yet), we just don't have any items then :)
+		return nil, nil
+	} else if !fi.IsDir() {
+		// Unexpected, if the directory actually would be a file
+		return nil, fmt.Errorf("expected that %s is a directory", dir)
+	}
+
+	// When we know that path is a directory, go ahead and read it
+	entries, err := fs.ReadDir(ctx, dir)
+	if err != nil {
+		return nil, err
+	}
+	fileNames := make([]string, 0, len(entries))
+	for _, entry := range entries {
+		fileNames = append(fileNames, entry.Name())
+	}
+	return fileNames, nil
+}
diff --git a/pkg/storage/filesystem/filesystem.go b/pkg/storage/filesystem/filesystem.go
new file mode 100644
index 0000000..f523e7b
--- /dev/null
+++ b/pkg/storage/filesystem/filesystem.go
@@ -0,0 +1,128 @@
+package filesystem
+
+import (
+	"context"
+	"os"
+	"path/filepath"
+	"strconv"
+
+	"github.com/spf13/afero"
+)
+
+// Filesystem extends afero.Fs and afero.Afero with contexts added to every method.
+type Filesystem interface {
+
+	// Members of afero.Fs
+
+	// MkdirAll creates a directory path and all parents that does not exist
+	// yet.
+	MkdirAll(ctx context.Context, path string, perm os.FileMode) error
+	// Remove removes a file identified by name, returning an error, if any
+	// happens.
+	Remove(ctx context.Context, name string) error
+	// Stat returns a FileInfo describing the named file, or an error, if any
+	// happens.
+	Stat(ctx context.Context, name string) (os.FileInfo, error)
+
+	// Members of afero.Afero
+
+	ReadDir(ctx context.Context, dirname string) ([]os.FileInfo, error)
+
+	Exists(ctx context.Context, path string) (bool, error)
+
+	ReadFile(ctx context.Context, filename string) ([]byte, error)
+
+	WriteFile(ctx context.Context, filename string, data []byte, perm os.FileMode) error
+
+	Walk(ctx context.Context, root string, walkFn filepath.WalkFunc) error
+
+	// Custom methods
+
+	// Checksum returns a checksum of the given file.
+	//
+	// What the checksum is is application-dependent, however, it
+	// should be the same for two invocations, as long as the stored
+	// data is the same. It might change over time although the
+	// underlying data did not. Examples of checksums that can be
+	// used is: the file modification timestamp, a sha256sum of the
+	// file content, or the latest Git commit when the file was
+	// changed.
+	//
+	// os.IsNotExist(err) can be used to check if the file doesn't
+	// exist.
+	Checksum(ctx context.Context, filename string) (string, error)
+
+	// RootDirectory specifies where on disk the root directory is stored.
+	// This path MUST be absolute. All other paths for the other methods
+	// MUST be relative to this directory.
+	RootDirectory() string
+}
+
+// NewOSFilesystem creates a new afero.OsFs for the local directory, using
+// NewFilesystem underneath.
+func NewOSFilesystem(rootDir string) Filesystem {
+	return NewFilesystem(afero.NewOsFs(), rootDir)
+}
+
+// NewFilesystem wraps an underlying afero.Fs without context knowledge,
+// in a Filesystem-compliant implementation; scoped at the given directory
+// (i.e. wrapped in afero.NewBasePathFs(fs, rootDir)).
+//
+// Checksum is calculated based on the modification timestamp of the file.
+func NewFilesystem(fs afero.Fs, rootDir string) Filesystem {
+	// TODO: rootDir validation? It must be absolute, exist, and be a directory.
+	return &filesystem{afero.NewBasePathFs(fs, rootDir), rootDir}
+}
+
+type filesystem struct {
+	fs      afero.Fs
+	rootDir string
+}
+
+func (f *filesystem) RootDirectory() string {
+	return f.rootDir
+}
+
+func (f *filesystem) Checksum(ctx context.Context, filename string) (string, error) {
+	fi, err := f.Stat(ctx, filename)
+	if err != nil {
+		return "", err
+	}
+	return checksumFromFileInfo(fi), nil
+}
+
+func (f *filesystem) MkdirAll(_ context.Context, path string, perm os.FileMode) error {
+	return f.fs.MkdirAll(path, perm)
+}
+
+func (f *filesystem) Remove(_ context.Context, name string) error {
+	return f.fs.Remove(name)
+}
+
+func (f *filesystem) Stat(_ context.Context, name string) (os.FileInfo, error) {
+	return f.fs.Stat(name)
+}
+
+func (f *filesystem) ReadDir(_ context.Context, dirname string) ([]os.FileInfo, error) {
+	return afero.ReadDir(f.fs, dirname)
+}
+
+func (f *filesystem) Exists(_ context.Context, path string) (bool, error) {
+	return afero.Exists(f.fs, path)
+}
+
+func (f *filesystem) ReadFile(_ context.Context, filename string) ([]byte, error) {
+	return afero.ReadFile(f.fs, filename)
+}
+
+func (f *filesystem) WriteFile(_ context.Context, filename string, data []byte, perm os.FileMode) error {
+	return afero.WriteFile(f.fs, filename, data, perm)
+}
+
+func (f *filesystem) Walk(_ context.Context, root string, walkFn filepath.WalkFunc) error {
+	return afero.Walk(f.fs, root, walkFn)
+}
+
+func checksumFromFileInfo(fi os.FileInfo) string {
+	return strconv.FormatInt(fi.ModTime().UnixNano(), 10)
+}
diff --git a/pkg/storage/filesystem/format.go b/pkg/storage/filesystem/format.go
new file mode 100644
index 0000000..b36aa1c
--- /dev/null
+++ b/pkg/storage/filesystem/format.go
@@ -0,0 +1,92 @@
+package filesystem
+
+import (
+	"context"
+	"errors"
+	"fmt"
+	"path/filepath"
+
+	"github.com/weaveworks/libgitops/pkg/serializer"
+)
+
+var (
+	ErrCannotDetermineContentType = errors.New("cannot determine content type")
+	ErrUnrecognizedContentType    = errors.New("unrecognized content type")
+)
+
+// ContentTyper resolves the Content Type of a file given its path and the afero
+// filesystem abstraction, so that it is possible to even examine the file if needed
+// for making the judgement. See DefaultContentTyper for a sample implementation.
+type ContentTyper interface {
+	// ContentTypeForPath should return the content type for the file that exists in
+	// the given Filesystem (path is relative). If the content type cannot be determined
+	// please return a wrapped ErrCannotDetermineContentType error.
+	ContentTypeForPath(ctx context.Context, fs Filesystem, path string) (serializer.ContentType, error)
+}
+
+// DefaultContentTypes describes the default connection between
+// file extensions and a content types.
+var DefaultContentTyper ContentTyper = ContentTypeForExtension{
+	".json": serializer.ContentTypeJSON,
+	".yaml": serializer.ContentTypeYAML,
+	".yml":  serializer.ContentTypeYAML,
+}
+
+// ContentTypeForExtension implements the ContentTyper interface
+// by looking up the extension of the given path in ContentTypeForPath
+// matched against the key of the map. The extension in the map key
+// must start with a dot, e.g. ".json". The value of the map contains
+// the corresponding content type. There might be many extensions which
+// map to the same content type, e.g. both ".yaml" -> ContentTypeYAML
+// and ".yml" -> ContentTypeYAML.
+type ContentTypeForExtension map[string]serializer.ContentType
+
+func (m ContentTypeForExtension) ContentTypeForPath(ctx context.Context, _ Filesystem, path string) (serializer.ContentType, error) {
+	ct, ok := m[filepath.Ext(path)]
+	if !ok {
+		return serializer.ContentType(""), fmt.Errorf("%w for file %q", ErrCannotDetermineContentType, path)
+	}
+	return ct, nil
+}
+
+// StaticContentTyper always responds with the same, statically-set, ContentType for any path.
+type StaticContentTyper struct {
+	// ContentType is a required field
+	ContentType serializer.ContentType
+}
+
+func (t StaticContentTyper) ContentTypeForPath(_ context.Context, _ Filesystem, _ string) (serializer.ContentType, error) {
+	if len(t.ContentType) == 0 {
+		return "", fmt.Errorf("StaticContentTyper.ContentType must not be empty")
+	}
+	return t.ContentType, nil
+}
+
+// FileExtensionResolver knows how to resolve what file extension to use for
+// a given ContentType.
+type FileExtensionResolver interface {
+	// ContentTypeExtension returns the file extension for the given ContentType.
+	// The returned string MUST start with a dot, e.g. ".json". If the given
+	// ContentType is not known, it is recommended to return a wrapped
+	// ErrUnrecognizedContentType.
+	ExtensionForContentType(ct serializer.ContentType) (string, error)
+}
+
+// DefaultFileExtensionResolver describes a default connection between
+// the file extensions and ContentTypes , namely JSON -> ".json" and
+// YAML -> ".yaml".
+var DefaultFileExtensionResolver FileExtensionResolver = ExtensionForContentType{
+	serializer.ContentTypeJSON: ".json",
+	serializer.ContentTypeYAML: ".yaml",
+}
+
+// ExtensionForContentType is a simple map implementation of FileExtensionResolver.
+type ExtensionForContentType map[serializer.ContentType]string
+
+func (m ExtensionForContentType) ExtensionForContentType(ct serializer.ContentType) (string, error) {
+	ext, ok := m[ct]
+	if !ok {
+		return "", fmt.Errorf("%q: %q", ErrUnrecognizedContentType, ct)
+	}
+	return ext, nil
+}
diff --git a/pkg/storage/filesystem/interfaces.go b/pkg/storage/filesystem/interfaces.go
new file mode 100644
index 0000000..2626680
--- /dev/null
+++ b/pkg/storage/filesystem/interfaces.go
@@ -0,0 +1,49 @@
+package filesystem
+
+import (
+	"context"
+
+	"github.com/weaveworks/libgitops/pkg/storage"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+)
+
+// Storage (in this filesystem package) extends storage.Storage by specializing it to operate in a
+// filesystem context, and in other words use a FileFinder to locate the
+// files to operate on.
+type Storage interface {
+	storage.Storage
+
+	// FileFinder returns the underlying FileFinder used.
+	// TODO: Maybe one Storage can have multiple FileFinders?
+	FileFinder() FileFinder
+}
+
+// FileFinder is a generic implementation for locating files on disk, to be
+// used by a Storage.
+//
+// Important: The caller MUST guarantee that the implementation can figure
+// out if the GroupKind is namespaced or not by the following check:
+//
+// namespaced := id.ObjectKey().Namespace != ""
+//
+// In other words, the caller must enforce a namespace being set for namespaced
+// kinds, and namespace not being set for non-namespaced kinds.
+type FileFinder interface {
+	// Filesystem gets the underlying filesystem abstraction, if
+	// applicable.
+	Filesystem() Filesystem
+
+	// ContentTyper gets the underlying ContentTyper used. The ContentTyper
+	// must always return a result although the underlying given path doesn't
+	// exist.
+	ContentTyper() ContentTyper
+
+	// ObjectPath gets the file path relative to the root directory.
+	// In order to support a create operation, this function must also return a valid path for
+	// files that do not yet exist on disk.
+	ObjectPath(ctx context.Context, id core.UnversionedObjectID) (string, error)
+	// ObjectAt retrieves the ID based on the given relative file path to fs.
+	ObjectAt(ctx context.Context, path string) (core.UnversionedObjectID, error)
+	// The FileFinder should be able to list namespaces and Object IDs
+	storage.Lister
+}
diff --git a/pkg/storage/filesystem/path_excluder.go b/pkg/storage/filesystem/path_excluder.go
new file mode 100644
index 0000000..58e8d2a
--- /dev/null
+++ b/pkg/storage/filesystem/path_excluder.go
@@ -0,0 +1,92 @@
+package filesystem
+
+import (
+	"os"
+	"path/filepath"
+	"strings"
+
+	"k8s.io/apimachinery/pkg/util/sets"
+)
+
+// PathExcluder is an interface that lets the user implement custom policies
+// for whether a given relative path to a given directory (fs is scoped at
+// that directory) should be considered for an operation (e.g. inotify watch
+// or file search).
+type PathExcluder interface {
+	// ShouldExcludePath takes in a relative path to the file which maybe
+	// should be excluded.
+	ShouldExcludePath(path string) bool
+}
+
+// DefaultPathExcluders returns a composition of
+// ExcludeDirectoryNames{} for ".git" dirs and ExcludeExtensions{} for the ".swp" file extensions.
+func DefaultPathExcluders() PathExcluder {
+	return MultiPathExcluder{
+		PathExcluders: []PathExcluder{
+			ExcludeDirectoryNames{
+				DirectoryNamesToExclude: []string{".git"},
+			},
+			ExcludeExtensions{
+				Extensions: []string{".swp"}, // nano creates temporary .swp
+			},
+		},
+	}
+}
+
+// ExcludeDirectoryNames implements PathExcluder.
+var _ PathExcluder = ExcludeDirectoryNames{}
+
+// ExcludeDirectories is a sample implementation of PathExcluder, that excludes
+// files that have any parent directories with the given names.
+type ExcludeDirectoryNames struct {
+	DirectoryNamesToExclude []string
+}
+
+func (e ExcludeDirectoryNames) ShouldExcludePath(path string) bool {
+	parts := strings.Split(filepath.Clean(path), string(os.PathSeparator))
+	return sets.NewString(parts[:len(parts)-1]...).HasAny(e.DirectoryNamesToExclude...)
+}
+
+// ExcludeExtensions implements PathExcluder.
+var _ PathExcluder = ExcludeExtensions{}
+
+// ExcludeExtensions is a sample implementation of PathExcluder, that excludes
+// all files with the given extensions. The strings in the Extensions slice
+// must be in the form of filepath.Ext, i.e. ".json", ".txt", and so forth.
+// The zero value of ExcludeExtensions excludes no files.
+type ExcludeExtensions struct {
+	Extensions []string
+}
+
+func (e ExcludeExtensions) ShouldExcludePath(path string) bool {
+	ext := filepath.Ext(path)
+	for _, exclExt := range e.Extensions {
+		if ext == exclExt {
+			return true
+		}
+	}
+	return false
+}
+
+// MultiPathExcluder implements PathExcluder.
+var _ PathExcluder = &MultiPathExcluder{}
+
+// MultiPathExcluder is a composite PathExcluder that runs all of the
+// PathExcluders in the slice one-by-one, and returns true if any of them
+// does. The zero value of MultiPathExcluder excludes no files.
+type MultiPathExcluder struct {
+	PathExcluders []PathExcluder
+}
+
+func (m MultiPathExcluder) ShouldExcludePath(path string) bool {
+	// Loop through all the excluders, and return true if any of them does
+	for _, excl := range m.PathExcluders {
+		if excl == nil {
+			continue
+		}
+		if excl.ShouldExcludePath(path) {
+			return true
+		}
+	}
+	return false
+}
diff --git a/pkg/storage/filesystem/path_excluder_test.go b/pkg/storage/filesystem/path_excluder_test.go
new file mode 100644
index 0000000..5995fd2
--- /dev/null
+++ b/pkg/storage/filesystem/path_excluder_test.go
@@ -0,0 +1,77 @@
+package filesystem
+
+import (
+	"testing"
+)
+
+func TestExcludeGitDirectory_ShouldExcludePath(t *testing.T) {
+	tests := []struct {
+		name string
+		path string
+		want bool
+	}{
+		{
+			name: "normal",
+			path: ".git/foo",
+			want: true,
+		},
+		{
+			name: "with relative path",
+			path: "./.git/bar/baz",
+			want: true,
+		},
+		{
+			name: "with many parents",
+			path: "/foo/bar/.git/hello",
+			want: true,
+		},
+		{
+			name: "with many children",
+			path: ".git/foo/bar/baz",
+			want: true,
+		},
+		{
+			name: "with parents and children",
+			path: "./foo/bar/.git/baz/bar",
+			want: true,
+		},
+		{
+			name: "empty",
+			path: "",
+			want: false,
+		},
+		{
+			name: "local dir",
+			path: ".",
+			want: false,
+		},
+		{
+			name: "other prefix",
+			path: "foo.git",
+			want: false,
+		},
+		{
+			name: "other suffix",
+			path: ".gitea",
+			want: false,
+		},
+		{
+			name: "absolute path without git",
+			path: "/foo/bar/no/git/here",
+			want: false,
+		},
+		{
+			name: "don't catch files named .git",
+			path: "/hello/.git",
+			want: false,
+		},
+	}
+	e := ExcludeDirectoryNames{DirectoryNamesToExclude: []string{".git"}}
+	for _, tt := range tests {
+		t.Run(tt.name, func(t *testing.T) {
+			if got := e.ShouldExcludePath(tt.path); got != tt.want {
+				t.Errorf("ExcludeGitDirectory.ShouldExcludePath() = %v, want %v", got, tt.want)
+			}
+		})
+	}
+}
diff --git a/pkg/storage/filesystem/storage.go b/pkg/storage/filesystem/storage.go
new file mode 100644
index 0000000..f3bc287
--- /dev/null
+++ b/pkg/storage/filesystem/storage.go
@@ -0,0 +1,170 @@
+package filesystem
+
+import (
+	"context"
+	"fmt"
+	"os"
+	"path/filepath"
+
+	"github.com/weaveworks/libgitops/pkg/serializer"
+	"github.com/weaveworks/libgitops/pkg/storage"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"k8s.io/apimachinery/pkg/util/sets"
+)
+
+// NewGeneric creates a new Generic using the given lower-level
+// FileFinder and Namespacer.
+func NewGeneric(fileFinder FileFinder, namespacer core.Namespacer) (Storage, error) {
+	if fileFinder == nil {
+		return nil, fmt.Errorf("NewGeneric: fileFinder is mandatory")
+	}
+	if namespacer == nil {
+		return nil, fmt.Errorf("NewGeneric: namespacer is mandatory")
+	}
+
+	return &Generic{
+		fileFinder: fileFinder,
+		namespacer: namespacer,
+	}, nil
+}
+
+// Generic is a Storage-compliant implementation, that
+// combines the given lower-level FileFinder, Namespacer and Filesystem interfaces
+// in a generic manner.
+type Generic struct {
+	fileFinder FileFinder
+	namespacer core.Namespacer
+}
+
+func (r *Generic) Namespacer() core.Namespacer {
+	return r.namespacer
+}
+
+func (r *Generic) FileFinder() FileFinder {
+	return r.fileFinder
+}
+
+func (r *Generic) Read(ctx context.Context, id core.UnversionedObjectID) ([]byte, error) {
+	// Get the path and verify namespacing info
+	p, err := r.getPath(ctx, id)
+	if err != nil {
+		return nil, err
+	}
+	// Check if the resource indicated by key exists
+	if !r.exists(ctx, p) {
+		return nil, core.NewErrNotFound(id)
+	}
+	// Read the file
+	return r.FileFinder().Filesystem().ReadFile(ctx, p)
+}
+
+func (r *Generic) Exists(ctx context.Context, id core.UnversionedObjectID) bool {
+	// Get the path and verify namespacing info
+	p, err := r.getPath(ctx, id)
+	if err != nil {
+		return false
+	}
+	return r.exists(ctx, p)
+}
+
+func (r *Generic) exists(ctx context.Context, path string) bool {
+	exists, _ := r.FileFinder().Filesystem().Exists(ctx, path)
+	return exists
+}
+
+func (r *Generic) Checksum(ctx context.Context, id core.UnversionedObjectID) (string, error) {
+	// Get the path and verify namespacing info
+	p, err := r.getPath(ctx, id)
+	if err != nil {
+		return "", err
+	}
+	// Return a "high level" error if the file does not exist
+	checksum, err := r.FileFinder().Filesystem().Checksum(ctx, p)
+	if os.IsNotExist(err) {
+		return "", core.NewErrNotFound(id)
+	} else if err != nil {
+		return "", err
+	}
+	return checksum, nil
+}
+
+func (r *Generic) ContentType(ctx context.Context, id core.UnversionedObjectID) (serializer.ContentType, error) {
+	// Get the path and verify namespacing info
+	p, err := r.getPath(ctx, id)
+	if err != nil {
+		return "", err
+	}
+	return r.FileFinder().ContentTyper().ContentTypeForPath(ctx, r.fileFinder.Filesystem(), p)
+}
+
+func (r *Generic) Write(ctx context.Context, id core.UnversionedObjectID, content []byte) error {
+	// Get the path and verify namespacing info
+	p, err := r.getPath(ctx, id)
+	if err != nil {
+		return err
+	}
+
+	// Create the underlying directories if they do not exist already
+	if !r.exists(ctx, p) {
+		if err := r.FileFinder().Filesystem().MkdirAll(ctx, filepath.Dir(p), 0755); err != nil {
+			return err
+		}
+	}
+	// Write the file content
+	return r.FileFinder().Filesystem().WriteFile(ctx, p, content, 0664)
+}
+
+func (r *Generic) Delete(ctx context.Context, id core.UnversionedObjectID) error {
+	// Get the path and verify namespacing info
+	p, err := r.getPath(ctx, id)
+	if err != nil {
+		return err
+	}
+
+	// Check if the resource indicated by key exists
+	if !r.exists(ctx, p) {
+		return core.NewErrNotFound(id)
+	}
+	// Remove the file
+	return r.FileFinder().Filesystem().Remove(ctx, p)
+}
+
+// ListNamespaces lists the available namespaces for the given GroupKind.
+// This function shall only be called for namespaced objects, it is up to
+// the caller to make sure they do not call this method for root-spaced
+// objects; for that the behavior is undefined (but returning an error
+// is recommended).
+func (r *Generic) ListNamespaces(ctx context.Context, gk core.GroupKind) (sets.String, error) {
+	namespaced, err := r.namespacer.IsNamespaced(gk)
+	if err != nil {
+		return nil, err
+	}
+	// Validate the groupkind
+	if !namespaced {
+		return nil, fmt.Errorf("%w: cannot list namespaces for non-namespaced kind: %v", storage.ErrNamespacedMismatch, gk)
+	}
+	// Just use the underlying filefinder
+	return r.FileFinder().ListNamespaces(ctx, gk)
+}
+
+// ListObjectIDs returns a list of unversioned ObjectIDs.
+// For namespaced GroupKinds, the caller must provide a namespace, and for
+// root-spaced GroupKinds, the caller must not. When namespaced, this function
+// must only return object IDs for that given namespace.
+func (r *Generic) ListObjectIDs(ctx context.Context, gk core.GroupKind, namespace string) ([]core.UnversionedObjectID, error) {
+	// Validate the namespace parameter
+	if err := storage.VerifyNamespaced(r.Namespacer(), gk, namespace); err != nil {
+		return nil, err
+	}
+	// Just use the underlying filefinder
+	return r.FileFinder().ListObjectIDs(ctx, gk, namespace)
+}
+
+func (r *Generic) getPath(ctx context.Context, id core.UnversionedObjectID) (string, error) {
+	// Verify namespacing info
+	if err := storage.VerifyNamespaced(r.Namespacer(), id.GroupKind(), id.ObjectKey().Namespace); err != nil {
+		return "", err
+	}
+	// Get the path
+	return r.FileFinder().ObjectPath(ctx, id)
+}
diff --git a/pkg/storage/filesystem/unstructured/event/storage.go b/pkg/storage/filesystem/unstructured/event/storage.go
new file mode 100644
index 0000000..0d674b5
--- /dev/null
+++ b/pkg/storage/filesystem/unstructured/event/storage.go
@@ -0,0 +1,352 @@
+package unstructuredevent
+
+import (
+	"context"
+	"fmt"
+	gosync "sync"
+
+	"github.com/sirupsen/logrus"
+	"github.com/weaveworks/libgitops/pkg/storage"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"github.com/weaveworks/libgitops/pkg/storage/event"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem/fileevents"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem/fileevents/inotify"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem/unstructured"
+	"github.com/weaveworks/libgitops/pkg/util/sync"
+)
+
+// UnstructuredEventStorage is an extension of raw.UnstructuredStorage, that
+// adds the possiblility to listen for object updates from a FileEventsEmitter.
+//
+// When the Sync() function is run; the ObjectEvents that are emitted to the
+// listening channels with have ObjectEvent.Type == ObjectEventSync.
+type UnstructuredEventStorage interface {
+	unstructured.Storage
+	fileevents.StorageCommon
+}
+
+const defaultEventsBufferSize = 4096
+
+// NewManifest is a high-level constructor for a generic
+// MappedFileFinder and filesystem.Storage, together with a
+// inotify FileWatcher; all combined into an UnstructuredEventStorage.
+func NewManifest(
+	dir string,
+	contentTyper filesystem.ContentTyper,
+	namespacer core.Namespacer,
+	recognizer core.ObjectRecognizer,
+	pathExcluder filesystem.PathExcluder,
+) (UnstructuredEventStorage, error) {
+	fs := filesystem.NewOSFilesystem(dir)
+	fileFinder := unstructured.NewGenericMappedFileFinder(contentTyper, fs)
+	fsRaw, err := filesystem.NewGeneric(fileFinder, namespacer)
+	if err != nil {
+		return nil, err
+	}
+	emitter, err := inotify.NewFileWatcher(dir, &inotify.FileWatcherOptions{
+		PathExcluder: pathExcluder,
+	})
+	if err != nil {
+		return nil, err
+	}
+	unstructuredRaw, err := unstructured.NewGeneric(fsRaw, recognizer, pathExcluder)
+	if err != nil {
+		return nil, err
+	}
+	return NewGeneric(unstructuredRaw, emitter, GenericStorageOptions{
+		SyncAtStart:   true,
+		EmitSyncEvent: true,
+	})
+}
+
+// NewGeneric is an extended Storage implementation, which
+// together with the provided ObjectRecognizer and FileEventsEmitter listens for
+// file events, keeps the mappings of the filesystem.Storage's MappedFileFinder
+// in sync (s must use the mapped variant), and sends high-level ObjectEvents
+// upstream.
+//
+// Note: This WatchStorage only works for one-frame files (i.e. only one YAML document
+// per file is supported).
+func NewGeneric(
+	s unstructured.Storage,
+	emitter fileevents.Emitter,
+	opts GenericStorageOptions,
+) (UnstructuredEventStorage, error) {
+	return &Generic{
+		Storage: s,
+		emitter: emitter,
+
+		inbound: make(fileevents.FileEventStream, defaultEventsBufferSize),
+		// outbound set by WatchForObjectEvents
+		outboundMu: &gosync.Mutex{},
+
+		// monitor set by WatchForObjectEvents, guarded by outboundMu
+
+		opts: opts,
+	}, nil
+}
+
+type GenericStorageOptions struct {
+	// When Sync(ctx) is run, emit a "SYNC" event to the listening channel
+	// Default: false
+	EmitSyncEvent bool
+	// Do a full re-sync at startup of the watcher
+	// Default: true
+	SyncAtStart bool
+}
+
+// Generic implements UnstructuredEventStorage.
+var _ UnstructuredEventStorage = &Generic{}
+
+// Generic is an extended raw.Storage implementation, which provides a watcher
+// for watching changes in the directory managed by the embedded Storage's RawStorage.
+// If the RawStorage is a MappedRawStorage instance, it's mappings will automatically
+// be updated by the WatchStorage. Update events are sent to the given event stream.
+// Note: This WatchStorage only works for one-frame files (i.e. only one YAML document
+// per file is supported).
+// TODO: Update description
+type Generic struct {
+	unstructured.Storage
+	// the filesystem events emitter
+	emitter fileevents.Emitter
+
+	// channels
+	inbound    fileevents.FileEventStream
+	outbound   event.ObjectEventStream
+	outboundMu *gosync.Mutex
+
+	// goroutine
+	monitor *sync.Monitor
+
+	// opts
+	opts GenericStorageOptions
+}
+
+func (s *Generic) FileEventsEmitter() fileevents.Emitter {
+	return s.emitter
+}
+
+func (s *Generic) WatchForObjectEvents(ctx context.Context, into event.ObjectEventStream) error {
+	s.outboundMu.Lock()
+	defer s.outboundMu.Unlock()
+	// We don't support more than one listener
+	// TODO: maybe support many listeners in the future?
+	if s.outbound != nil {
+		return fmt.Errorf("WatchStorage: not more than one watch supported: %w", fileevents.ErrTooManyWatches)
+	}
+	// Hook up our inbound channel to the emitter, to make the pipeline functional
+	if err := s.emitter.WatchForFileEvents(ctx, s.inbound); err != nil {
+		return err
+	}
+	// Set outbound at this stage so Sync possibly can send events.
+	s.outbound = into
+	// Start the backing goroutines
+	s.monitor = sync.RunMonitor(s.monitorFunc)
+
+	// Do a full sync in the beginning only if asked. Be aware that without running a Sync
+	// at all before events start happening, the reporting might not work as it should
+	if s.opts.SyncAtStart {
+		// Disregard the changed files at Sync.
+		if _, err := s.Sync(ctx); err != nil {
+			return err
+		}
+	}
+	return nil // all ok
+}
+
+func (s *Generic) Sync(ctx context.Context) ([]unstructured.ChecksumPathID, error) {
+	// Sync the underlying UnstructuredStorage, and see what files had changed since last sync
+	changedObjects, err := s.Storage.Sync(ctx)
+	if err != nil {
+		return nil, err
+	}
+
+	// Send special "sync" events for each of the changed objects, if configured
+	if s.opts.EmitSyncEvent {
+		for _, changedObject := range changedObjects {
+			// Send a special "sync" event for this ObjectID to the events channel
+			s.sendEvent(event.ObjectEventSync, changedObject.ID)
+		}
+	}
+
+	return changedObjects, nil
+}
+
+// Write writes the given content to the resource indicated by the ID.
+// Error returns are implementation-specific.
+func (s *Generic) Write(ctx context.Context, id core.UnversionedObjectID, content []byte) error {
+	// Get the path and verify namespacing info
+	p, err := s.getPath(ctx, id)
+	if err != nil {
+		return err
+	}
+	// Suspend the write event
+	s.emitter.Suspend(ctx, p)
+	// Call the underlying filesystem.Storage
+	return s.Storage.Write(ctx, id, content)
+}
+
+// Delete deletes the resource indicated by the ID.
+// If the resource does not exist, it returns ErrNotFound.
+func (s *Generic) Delete(ctx context.Context, id core.UnversionedObjectID) error {
+	// Get the path and verify namespacing info
+	p, err := s.getPath(ctx, id)
+	if err != nil {
+		return err
+	}
+	// Suspend the write event
+	s.emitter.Suspend(ctx, p)
+	// Call the underlying filesystem.Storage
+	return s.Storage.Delete(ctx, id)
+}
+
+func (s *Generic) getPath(ctx context.Context, id core.UnversionedObjectID) (string, error) {
+	// Verify namespacing info
+	if err := storage.VerifyNamespaced(s.Namespacer(), id.GroupKind(), id.ObjectKey().Namespace); err != nil {
+		return "", err
+	}
+	// Get the path
+	return s.FileFinder().ObjectPath(ctx, id)
+}
+
+func (s *Generic) Close() error {
+	err := s.emitter.Close()
+	// No need to check the error here
+	_ = s.monitor.Wait()
+	return err
+}
+
+func (s *Generic) monitorFunc() error {
+	logrus.Debug("WatchStorage: Monitoring thread started")
+	defer logrus.Debug("WatchStorage: Monitoring thread stopped")
+
+	ctx := context.Background()
+
+	for {
+		// TODO: handle context cancellations, i.e. ctx.Done()
+		ev, ok := <-s.inbound
+		if !ok {
+			logrus.Error("WatchStorage: Fatal: Got non-ok response from watcher.GetFileEventStream()")
+			return nil
+		}
+
+		logrus.Tracef("WatchStorage: Processing event: %s", ev.Type)
+
+		// Skip the file if it has an invalid path
+		if !filesystem.IsValidFileInFilesystem(
+			ctx,
+			s.FileFinder().Filesystem(),
+			s.FileFinder().ContentTyper(),
+			s.PathExcluder(),
+			ev.Path) {
+			logrus.Tracef("WatchStorage: Skipping file %q as it is ignored by the ContentTyper/PathExcluder", ev.Path)
+			continue
+		}
+
+		var err error
+		switch ev.Type {
+		// FileEventModify is also sent for newly-created files
+		case fileevents.FileEventModify, fileevents.FileEventMove:
+			err = s.handleModifyMove(ctx, ev)
+		case fileevents.FileEventDelete:
+			err = s.handleDelete(ctx, ev)
+		default:
+			err = fmt.Errorf("cannot handle update of type %v for path %q", ev.Type, ev.Path)
+		}
+		if err != nil {
+			logrus.Errorf("WatchStorage: %v", err)
+		}
+	}
+}
+
+func (s *Generic) handleDelete(ctx context.Context, ev *fileevents.FileEvent) error {
+	// The object is deleted, so we need to do a reverse-lookup of what kind of object
+	// was there earlier, based on the path. This assumes that the filefinder organizes
+	// the known objects in such a way that it is able to do the reverse-lookup. For
+	// mapped FileFinders, by this point the path should still be in the local cache,
+	// which should make us able to get the ID before deleted from the cache.
+	objectID, err := s.MappedFileFinder().ObjectAt(ctx, ev.Path)
+	if err != nil {
+		return fmt.Errorf("failed to reverse lookup ID for deleted file %q: %v", ev.Path, err)
+	}
+
+	// Remove the mapping from the FileFinder cache for this ID as it's now deleted
+	s.deleteMapping(ctx, objectID)
+	// Send the delete event to the channel
+	s.sendEvent(event.ObjectEventDelete, objectID)
+	return nil
+}
+
+func (s *Generic) handleModifyMove(ctx context.Context, ev *fileevents.FileEvent) error {
+	// Read the content of this modified, moved or created file
+	content, err := s.FileFinder().Filesystem().ReadFile(ctx, ev.Path)
+	if err != nil {
+		return fmt.Errorf("could not read %q: %v", ev.Path, err)
+	}
+
+	// Try to recognize the object
+	versionedID, err := s.ObjectRecognizer().ResolveObjectID(ctx, ev.Path, content)
+	if err != nil {
+		return fmt.Errorf("did not recognize object at path %q: %v", ev.Path, err)
+	}
+
+	// If the file was just moved around, just overwrite the earlier mapping
+	if ev.Type == fileevents.FileEventMove {
+		// This assumes that the file content does not change in the move
+		// operation. TODO: document this as a requirement for the Emitter.
+		s.setMapping(ctx, versionedID, ev.Path)
+
+		// Internal move events are a no-op
+		return nil
+	}
+
+	// Determine if this object already existed in the fileFinder's cache,
+	// in order to find out if the object was created or modified (default).
+	// TODO: In the future, maybe support multiple files pointing to the same
+	// ObjectID? Case in point here is e.g. a Modify event for a known path that
+	// changes the underlying ObjectID.
+	objectEvent := event.ObjectEventUpdate
+	// Set the mapping if it didn't exist before; assume this is a Create event
+	if _, ok := s.MappedFileFinder().GetMapping(ctx, versionedID); !ok {
+		// This is what actually determines if an Object is created,
+		// so update the event to update.ObjectEventCreate here
+		objectEvent = event.ObjectEventCreate
+	}
+	// Update the mapping between this object and path (this updates
+	// the checksum underneath too).
+	s.setMapping(ctx, versionedID, ev.Path)
+	// Send the event to the channel
+	s.sendEvent(objectEvent, versionedID)
+	return nil
+}
+
+func (s *Generic) sendEvent(eventType event.ObjectEventType, id core.UnversionedObjectID) {
+	logrus.Tracef("Generic: Sending event: %v", eventType)
+	s.outbound <- &event.ObjectEvent{
+		ID:   id,
+		Type: eventType,
+	}
+}
+
+// setMapping registers a mapping between the given object and the specified path, if raw is a
+// MappedRawStorage. If a given mapping already exists between this object and some path, it
+// will be overridden with the specified new path
+func (s *Generic) setMapping(ctx context.Context, id core.UnversionedObjectID, path string) {
+	// Get the current checksum of the new file
+	checksum, err := s.MappedFileFinder().Filesystem().Checksum(ctx, path)
+	if err != nil {
+		logrus.Errorf("Unexpected error when getting checksum of file %q: %v", path, err)
+		return
+	}
+	// Register the current state in the cache
+	s.MappedFileFinder().SetMapping(ctx, id, unstructured.ChecksumPath{
+		Path:     path,
+		Checksum: checksum,
+	})
+}
+
+// deleteMapping removes a mapping a file that doesn't exist
+func (s *Generic) deleteMapping(ctx context.Context, id core.UnversionedObjectID) {
+	s.MappedFileFinder().DeleteMapping(ctx, id)
+}
diff --git a/pkg/storage/filesystem/unstructured/filefinder_mapped.go b/pkg/storage/filesystem/unstructured/filefinder_mapped.go
new file mode 100644
index 0000000..274da22
--- /dev/null
+++ b/pkg/storage/filesystem/unstructured/filefinder_mapped.go
@@ -0,0 +1,157 @@
+package unstructured
+
+import (
+	"context"
+	"errors"
+
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem"
+	utilerrs "k8s.io/apimachinery/pkg/util/errors"
+	"k8s.io/apimachinery/pkg/util/sets"
+)
+
+var (
+	// ErrNotTracked is returned when the requested resource wasn't found.
+	ErrNotTracked = errors.New("untracked object")
+)
+
+// GenericMappedFileFinder implements MappedFileFinder.
+var _ MappedFileFinder = &GenericMappedFileFinder{}
+
+// NewGenericMappedFileFinder creates a new instance of GenericMappedFileFinder,
+// that implements the MappedFileFinder interface. The contentTyper is optional,
+// by default core.DefaultContentTyper will be used.
+func NewGenericMappedFileFinder(contentTyper filesystem.ContentTyper, fs filesystem.Filesystem) MappedFileFinder {
+	if contentTyper == nil {
+		contentTyper = filesystem.DefaultContentTyper
+	}
+	if fs == nil {
+		panic("NewGenericMappedFileFinder: fs is mandatory")
+	}
+	return &GenericMappedFileFinder{
+		contentTyper: contentTyper,
+		// TODO: Support multiple branches
+		branch: &branchImpl{},
+		fs:     fs,
+	}
+}
+
+// GenericMappedFileFinder is a generic implementation of MappedFileFinder.
+// It uses a ContentTyper to identify what content type a file uses.
+//
+// This implementation relies on that all information about what files exist
+// is fed through SetMapping(s). If a file or ID is requested that doesn't
+// exist in the internal cache, ErrNotTracked will be returned.
+//
+// Hence, this implementation does not at the moment support creating net-new
+// Objects without someone calling SetMapping() first.
+type GenericMappedFileFinder struct {
+	// Default: DefaultContentTyper
+	contentTyper filesystem.ContentTyper
+	fs           filesystem.Filesystem
+
+	branch branch
+}
+
+func (f *GenericMappedFileFinder) Filesystem() filesystem.Filesystem {
+	return f.fs
+}
+
+func (f *GenericMappedFileFinder) ContentTyper() filesystem.ContentTyper {
+	return f.contentTyper
+}
+
+// ObjectPath gets the file path relative to the root directory
+func (f *GenericMappedFileFinder) ObjectPath(ctx context.Context, id core.UnversionedObjectID) (string, error) {
+	cp, ok := f.GetMapping(ctx, id)
+	if !ok {
+		// TODO: separate interface for "new creates"?
+		return "", utilerrs.NewAggregate([]error{ErrNotTracked, core.NewErrNotFound(id)})
+	}
+	return cp.Path, nil
+}
+
+// ObjectAt retrieves the ID containing the virtual path based
+// on the given physical file path.
+func (f *GenericMappedFileFinder) ObjectAt(ctx context.Context, path string) (core.UnversionedObjectID, error) {
+	// TODO: Add reverse tracking too?
+	for gk, gkIter := range f.branch.raw() {
+		for ns, nsIter := range gkIter.raw() {
+			for name, cp := range nsIter.raw() {
+				if cp.Path == path {
+					return core.NewUnversionedObjectID(gk, core.ObjectKey{Name: name, Namespace: ns}), nil
+				}
+			}
+		}
+	}
+	// TODO: Support "creation" of Objects easier, in a generic way through an interface, e.g.
+	// NewObjectPlacer?
+	return nil, ErrNotTracked
+}
+
+// ListNamespaces lists the available namespaces for the given GroupKind.
+// This function shall only be called for namespaced objects, it is up to
+// the caller to make sure they do not call this method for root-spaced
+// objects. If any of the given rules are violated, ErrNamespacedMismatch
+// should be returned as a wrapped error.
+//
+// The implementer can choose between basing the answer strictly on e.g.
+// v1.Namespace objects that exist in the system, or just the set of
+// different namespaces that have been set on any object belonging to
+// the given GroupKind.
+func (f *GenericMappedFileFinder) ListNamespaces(ctx context.Context, gk core.GroupKind) (sets.String, error) {
+	m := f.branch.groupKind(gk).raw()
+	nsSet := sets.NewString()
+	for ns := range m {
+		nsSet.Insert(ns)
+	}
+	return nsSet, nil
+}
+
+// ListObjectIDs returns a list of unversioned ObjectIDs.
+// For namespaced GroupKinds, the caller must provide a namespace, and for
+// root-spaced GroupKinds, the caller must not. When namespaced, this function
+// must only return object IDs for that given namespace. If any of the given
+// rules are violated, ErrNamespacedMismatch should be returned as a wrapped error.
+func (f *GenericMappedFileFinder) ListObjectIDs(ctx context.Context, gk core.GroupKind, namespace string) ([]core.UnversionedObjectID, error) {
+	m := f.branch.groupKind(gk).namespace(namespace).raw()
+	ids := make([]core.UnversionedObjectID, 0, len(m))
+	for name := range m {
+		ids = append(ids, core.NewUnversionedObjectID(gk, core.ObjectKey{Name: name, Namespace: namespace}))
+	}
+	return ids, nil
+}
+
+// GetMapping retrieves a mapping in the system
+func (f *GenericMappedFileFinder) GetMapping(ctx context.Context, id core.UnversionedObjectID) (ChecksumPath, bool) {
+	cp, ok := f.branch.
+		groupKind(id.GroupKind()).
+		namespace(id.ObjectKey().Namespace).
+		name(id.ObjectKey().Name)
+	return cp, ok
+}
+
+// SetMapping binds an ID's virtual path to a physical file path
+func (f *GenericMappedFileFinder) SetMapping(ctx context.Context, id core.UnversionedObjectID, checksumPath ChecksumPath) {
+	f.branch.
+		groupKind(id.GroupKind()).
+		namespace(id.ObjectKey().Namespace).
+		setName(id.ObjectKey().Name, checksumPath)
+}
+
+// ResetMappings replaces all mappings at once
+func (f *GenericMappedFileFinder) ResetMappings(ctx context.Context, m map[core.UnversionedObjectID]ChecksumPath) {
+	f.branch = &branchImpl{}
+	for id, cp := range m {
+		f.SetMapping(ctx, id, cp)
+	}
+}
+
+// DeleteMapping removes the physical file path mapping
+// matching the given id
+func (f *GenericMappedFileFinder) DeleteMapping(ctx context.Context, id core.UnversionedObjectID) {
+	f.branch.
+		groupKind(id.GroupKind()).
+		namespace(id.ObjectKey().Namespace).
+		deleteName(id.ObjectKey().Name)
+}
diff --git a/pkg/storage/filesystem/unstructured/interfaces.go b/pkg/storage/filesystem/unstructured/interfaces.go
new file mode 100644
index 0000000..814b437
--- /dev/null
+++ b/pkg/storage/filesystem/unstructured/interfaces.go
@@ -0,0 +1,75 @@
+package unstructured
+
+import (
+	"context"
+
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem"
+)
+
+// Storage is a raw Storage interface that builds on top
+// of Storage. It uses an ObjectRecognizer to recognize
+// otherwise unknown objects in unstructured files.
+// The Storage must use a MappedFileFinder underneath.
+//
+// Multiple Objects in the same file, or multiple Objects with the
+// same ID in multiple files are not supported.
+type Storage interface {
+	filesystem.Storage
+
+	// Sync synchronizes the current state of the filesystem with the
+	// cached mappings in the MappedFileFinder.
+	Sync(ctx context.Context) ([]ChecksumPathID, error)
+
+	// ObjectRecognizer returns the underlying ObjectRecognizer used.
+	ObjectRecognizer() core.ObjectRecognizer
+	// PathExcluder specifies what paths to not sync
+	PathExcluder() filesystem.PathExcluder
+	// MappedFileFinder returns the underlying MappedFileFinder used.
+	MappedFileFinder() MappedFileFinder
+}
+
+// MappedFileFinder is an extension to FileFinder that allows it to have an internal
+// cache with mappings between UnversionedObjectID and a ChecksumPath. This allows
+// higher-order interfaces to manage Objects in files in an unorganized directory
+// (e.g. a Git repo).
+//
+// Multiple Objects in the same file, or multiple Objects with the
+// same ID in multiple files are not supported.
+type MappedFileFinder interface {
+	filesystem.FileFinder
+
+	// GetMapping retrieves a mapping in the system.
+	GetMapping(ctx context.Context, id core.UnversionedObjectID) (ChecksumPath, bool)
+	// SetMapping binds an ID to a physical file path. This operation overwrites
+	// any previous mapping for id.
+	SetMapping(ctx context.Context, id core.UnversionedObjectID, checksumPath ChecksumPath)
+	// ResetMappings replaces all mappings at once to the ones in m.
+	ResetMappings(ctx context.Context, m map[core.UnversionedObjectID]ChecksumPath)
+	// DeleteMapping removes the mapping for the given id.
+	DeleteMapping(ctx context.Context, id core.UnversionedObjectID)
+}
+
+// ChecksumPath is a tuple of a given Checksum and relative file Path,
+// for use in MappedFileFinder.
+type ChecksumPath struct {
+	// Checksum is the checksum of the file at the given path.
+	//
+	// What the checksum is is application-dependent, however, it
+	// should be the same for two invocations, as long as the stored
+	// data is the same. It might change over time although the
+	// underlying data did not. Examples of checksums that can be
+	// used is: the file modification timestamp, a sha256sum of the
+	// file content, or the latest Git commit when the file was
+	// changed.
+	//
+	// The checksum is calculated by the filesystem.Filesystem.
+	Checksum string
+	// Path to the file, relative to filesystem.Filesystem.RootDirectory().
+	Path string
+}
+
+type ChecksumPathID struct {
+	ChecksumPath
+	ID core.ObjectID
+}
diff --git a/pkg/storage/filesystem/unstructured/mapped_cache.go b/pkg/storage/filesystem/unstructured/mapped_cache.go
new file mode 100644
index 0000000..08aeb83
--- /dev/null
+++ b/pkg/storage/filesystem/unstructured/mapped_cache.go
@@ -0,0 +1,104 @@
+package unstructured
+
+import "github.com/weaveworks/libgitops/pkg/storage/core"
+
+// This file contains a set of private interfaces and implementations
+// that allows caching mappings between a core.UnversionedObjectID
+// and a ChecksumPath.
+
+// TODO: rename this interface
+type branch interface {
+	groupKind(core.GroupKind) groupKind
+	raw() map[core.GroupKind]groupKind
+}
+
+type groupKind interface {
+	namespace(string) namespace
+	raw() map[string]namespace
+}
+
+type namespace interface {
+	name(string) (ChecksumPath, bool)
+	setName(string, ChecksumPath)
+	deleteName(string)
+	raw() map[string]ChecksumPath
+}
+
+type branchImpl struct {
+	m map[core.GroupKind]groupKind
+}
+
+func (b *branchImpl) groupKind(gk core.GroupKind) groupKind {
+	if b.m == nil {
+		b.m = make(map[core.GroupKind]groupKind)
+	}
+	val, ok := b.m[gk]
+	if !ok {
+		val = &groupKindImpl{}
+		b.m[gk] = val
+	}
+	return val
+}
+
+func (b *branchImpl) raw() map[core.GroupKind]groupKind {
+	if b.m == nil {
+		b.m = make(map[core.GroupKind]groupKind)
+	}
+	return b.m
+}
+
+type groupKindImpl struct {
+	m map[string]namespace
+}
+
+func (g *groupKindImpl) namespace(ns string) namespace {
+	if g.m == nil {
+		g.m = make(map[string]namespace)
+	}
+	val, ok := g.m[ns]
+	if !ok {
+		val = &namespaceImpl{}
+		g.m[ns] = val
+	}
+	return val
+}
+
+func (g *groupKindImpl) raw() map[string]namespace {
+	if g.m == nil {
+		g.m = make(map[string]namespace)
+	}
+	return g.m
+}
+
+type namespaceImpl struct {
+	m map[string]ChecksumPath
+}
+
+func (n *namespaceImpl) name(name string) (ChecksumPath, bool) {
+	if n.m == nil {
+		n.m = make(map[string]ChecksumPath)
+	}
+	cp, ok := n.m[name]
+	return cp, ok
+}
+
+func (n *namespaceImpl) setName(name string, cp ChecksumPath) {
+	if n.m == nil {
+		n.m = make(map[string]ChecksumPath)
+	}
+	n.m[name] = cp
+}
+
+func (n *namespaceImpl) deleteName(name string) {
+	if n.m == nil {
+		n.m = make(map[string]ChecksumPath)
+	}
+	delete(n.m, name)
+}
+
+func (n *namespaceImpl) raw() map[string]ChecksumPath {
+	if n.m == nil {
+		n.m = make(map[string]ChecksumPath)
+	}
+	return n.m
+}
diff --git a/pkg/storage/filesystem/unstructured/storage.go b/pkg/storage/filesystem/unstructured/storage.go
new file mode 100644
index 0000000..9109734
--- /dev/null
+++ b/pkg/storage/filesystem/unstructured/storage.go
@@ -0,0 +1,120 @@
+package unstructured
+
+import (
+	"context"
+	"errors"
+	"fmt"
+
+	"github.com/sirupsen/logrus"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"github.com/weaveworks/libgitops/pkg/storage/filesystem"
+)
+
+func NewGeneric(storage filesystem.Storage, recognizer core.ObjectRecognizer, pathExcluder filesystem.PathExcluder) (Storage, error) {
+	if storage == nil {
+		return nil, fmt.Errorf("storage is mandatory")
+	}
+	if recognizer == nil {
+		return nil, fmt.Errorf("recognizer is mandatory")
+	}
+	mappedFileFinder, ok := storage.FileFinder().(MappedFileFinder)
+	if !ok {
+		return nil, errors.New("the given filesystem.Storage must use a MappedFileFinder")
+	}
+	return &Generic{
+		Storage:          storage,
+		recognizer:       recognizer,
+		mappedFileFinder: mappedFileFinder,
+		pathExcluder:     pathExcluder,
+	}, nil
+}
+
+type Generic struct {
+	filesystem.Storage
+	recognizer       core.ObjectRecognizer
+	mappedFileFinder MappedFileFinder
+	pathExcluder     filesystem.PathExcluder
+}
+
+// Sync synchronizes the current state of the filesystem with the
+// cached mappings in the MappedFileFinder.
+func (s *Generic) Sync(ctx context.Context) ([]ChecksumPathID, error) {
+	fileFinder := s.MappedFileFinder()
+
+	// List all valid files in the fs
+	files, err := filesystem.ListValidFilesInFilesystem(
+		ctx,
+		fileFinder.Filesystem(),
+		fileFinder.ContentTyper(),
+		s.PathExcluder(),
+	)
+	if err != nil {
+		return nil, err
+	}
+
+	// Send SYNC events for all files (and fill the mappings
+	// of the MappedFileFinder) before starting to monitor changes
+	updatedFiles := make([]ChecksumPathID, 0, len(files))
+	for _, filePath := range files {
+		// Get the current checksum of the file
+		currentChecksum, err := fileFinder.Filesystem().Checksum(ctx, filePath)
+		if err != nil {
+			logrus.Errorf("Could not get checksum for file %q: %v", filePath, err)
+			continue
+		}
+
+		// If the given file already is tracked; i.e. has a mapping with a
+		// non-empty checksum, and the current checksum matches, we do not
+		// need to do anything.
+		if id, err := fileFinder.ObjectAt(ctx, filePath); err == nil {
+			if cp, ok := fileFinder.GetMapping(ctx, id); ok && len(cp.Checksum) != 0 {
+				if cp.Checksum == currentChecksum {
+					logrus.Tracef("Checksum for file %q is up-to-date: %q, skipping...", filePath, cp.Checksum)
+					continue
+				}
+			}
+		}
+
+		// If the file is not known to the FileFinder yet, or if the checksum
+		// was empty, read the file, and recognize it.
+		content, err := s.FileFinder().Filesystem().ReadFile(ctx, filePath)
+		if err != nil {
+			logrus.Warnf("Ignoring %q: %v", filePath, err)
+			continue
+		}
+
+		id, err := s.recognizer.ResolveObjectID(ctx, filePath, content)
+		if err != nil {
+			logrus.Warnf("Could not recognize object ID in %q: %v", filePath, err)
+			continue
+		}
+
+		// Add a mapping between this object and path
+		cp := ChecksumPath{
+			Checksum: currentChecksum,
+			Path:     filePath,
+		}
+		s.MappedFileFinder().SetMapping(ctx, id, cp)
+		// Add to the slice which we'll return
+		updatedFiles = append(updatedFiles, ChecksumPathID{
+			ChecksumPath: cp,
+			ID:           id,
+		})
+	}
+	return updatedFiles, nil
+}
+
+// ObjectRecognizer returns the underlying ObjectRecognizer used.
+func (s *Generic) ObjectRecognizer() core.ObjectRecognizer {
+	return s.recognizer
+}
+
+// PathExcluder specifies what paths to not sync
+func (s *Generic) PathExcluder() filesystem.PathExcluder {
+	return s.pathExcluder
+}
+
+// MappedFileFinder returns the underlying MappedFileFinder used.
+func (s *Generic) MappedFileFinder() MappedFileFinder {
+	return s.mappedFileFinder
+}
diff --git a/pkg/storage/format.go b/pkg/storage/format.go
deleted file mode 100644
index 84993ce..0000000
--- a/pkg/storage/format.go
+++ /dev/null
@@ -1,20 +0,0 @@
-package storage
-
-import "github.com/weaveworks/libgitops/pkg/serializer"
-
-// ContentTypes describes the connection between
-// file extensions and a content types.
-var ContentTypes = map[string]serializer.ContentType{
-	".json": serializer.ContentTypeJSON,
-	".yaml": serializer.ContentTypeYAML,
-	".yml":  serializer.ContentTypeYAML,
-}
-
-func extForContentType(wanted serializer.ContentType) string {
-	for ext, ct := range ContentTypes {
-		if ct == wanted {
-			return ext
-		}
-	}
-	return ""
-}
diff --git a/pkg/storage/interfaces.go b/pkg/storage/interfaces.go
new file mode 100644
index 0000000..c5698e0
--- /dev/null
+++ b/pkg/storage/interfaces.go
@@ -0,0 +1,103 @@
+package storage
+
+import (
+	"context"
+	"errors"
+
+	"github.com/weaveworks/libgitops/pkg/serializer"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"k8s.io/apimachinery/pkg/util/sets"
+)
+
+var (
+	// ErrNamespacedMismatch is returned by Storage methods if the given UnversionedObjectID
+	// carries invalid data, according to the Namespacer.
+	ErrNamespacedMismatch = errors.New("mismatch between namespacing info for object and the given parameter")
+)
+
+// Storage is a Key-indexed low-level interface to
+// store byte-encoded Objects (resources) in non-volatile
+// memory.
+//
+// This Storage operates entirely on GroupKinds; without enforcing
+// a specific version of the encoded data format. This is possible
+// with the assumption that any older format stored at disk can be
+// read successfully and converted into a more recent version.
+//
+// TODO: Add thread-safety so it is not possible to issue a Write() or Delete()
+// at the same time as any other read operation.
+type Storage interface {
+	Reader
+	Writer
+}
+
+// StorageCommon is an interface that contains the resources both needed
+// by Reader and Writer.
+type StorageCommon interface {
+	// Namespacer gives access to the namespacer that is used
+	Namespacer() core.Namespacer
+	// Exists checks if the resource indicated by the ID exists.
+	Exists(ctx context.Context, id core.UnversionedObjectID) bool
+}
+
+// Reader provides the read operations for the Storage.
+type Reader interface {
+	StorageCommon
+
+	// Read returns a resource's content based on the ID.
+	// If the resource does not exist, it returns core.NewErrNotFound.
+	Read(ctx context.Context, id core.UnversionedObjectID) ([]byte, error)
+
+	// Checksum returns a checksum of the Object with the given ID.
+	//
+	// What the checksum is is application-dependent, however, it
+	// should be the same for two invocations, as long as the stored
+	// data is the same. It might change over time although the
+	// underlying data did not. Examples of checksums that can be
+	// used is: the file modification timestamp, a sha256sum of the
+	// file content, or the latest Git commit when the file was
+	// changed.
+	Checksum(ctx context.Context, id core.UnversionedObjectID) (string, error)
+
+	// ContentType returns the content type that should be used when serializing
+	// the object with the given ID. This operation must function also before the
+	// Object with the given id exists in the system, in order to be able to
+	// create new Objects.
+	ContentType(ctx context.Context, id core.UnversionedObjectID) (serializer.ContentType, error)
+
+	// List operations
+	Lister
+}
+
+type Lister interface {
+	// ListNamespaces lists the available namespaces for the given GroupKind.
+	// This function shall only be called for namespaced objects, it is up to
+	// the caller to make sure they do not call this method for root-spaced
+	// objects. If any of the given rules are violated, ErrNamespacedMismatch
+	// should be returned as a wrapped error.
+	//
+	// The implementer can choose between basing the answer strictly on e.g.
+	// v1.Namespace objects that exist in the system, or just the set of
+	// different namespaces that have been set on any object belonging to
+	// the given GroupKind.
+	ListNamespaces(ctx context.Context, gk core.GroupKind) (sets.String, error)
+
+	// ListObjectIDs returns a list of unversioned ObjectIDs.
+	// For namespaced GroupKinds, the caller must provide a namespace, and for
+	// root-spaced GroupKinds, the caller must not. When namespaced, this function
+	// must only return object IDs for that given namespace. If any of the given
+	// rules are violated, ErrNamespacedMismatch should be returned as a wrapped error.
+	ListObjectIDs(ctx context.Context, gk core.GroupKind, namespace string) ([]core.UnversionedObjectID, error)
+}
+
+// Reader provides the write operations for the Storage.
+type Writer interface {
+	StorageCommon
+
+	// Write writes the given content to the resource indicated by the ID.
+	// Error returns are implementation-specific.
+	Write(ctx context.Context, id core.UnversionedObjectID, content []byte) error
+	// Delete deletes the resource indicated by the ID.
+	// If the resource does not exist, it returns ErrNotFound.
+	Delete(ctx context.Context, id core.UnversionedObjectID) error
+}
diff --git a/pkg/storage/key.go b/pkg/storage/key.go
deleted file mode 100644
index 015cac4..0000000
--- a/pkg/storage/key.go
+++ /dev/null
@@ -1,64 +0,0 @@
-package storage
-
-import (
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"k8s.io/apimachinery/pkg/runtime/schema"
-)
-
-type kindKey schema.GroupVersionKind
-
-func (gvk kindKey) GetGroup() string                { return gvk.Group }
-func (gvk kindKey) GetVersion() string              { return gvk.Version }
-func (gvk kindKey) GetKind() string                 { return gvk.Kind }
-func (gvk kindKey) GetGVK() schema.GroupVersionKind { return schema.GroupVersionKind(gvk) }
-func (gvk kindKey) EqualsGVK(kind KindKey, respectVersion bool) bool {
-	// Make sure kind and group match, otherwise return false
-	if gvk.GetKind() != kind.GetKind() || gvk.GetGroup() != kind.GetGroup() {
-		return false
-	}
-	// If we allow version mismatches (i.e. don't need to respect the version), return true
-	if !respectVersion {
-		return true
-	}
-	// Otherwise, return true if the version also is the same
-	return gvk.GetVersion() == kind.GetVersion()
-}
-func (gvk kindKey) String() string { return gvk.GetGVK().String() }
-
-// kindKey implements KindKey.
-var _ KindKey = kindKey{}
-
-type KindKey interface {
-	// String implements fmt.Stringer
-	String() string
-
-	GetGroup() string
-	GetVersion() string
-	GetKind() string
-	GetGVK() schema.GroupVersionKind
-
-	EqualsGVK(kind KindKey, respectVersion bool) bool
-}
-
-type ObjectKey interface {
-	KindKey
-	runtime.Identifyable
-}
-
-// objectKey implements ObjectKey.
-var _ ObjectKey = &objectKey{}
-
-type objectKey struct {
-	KindKey
-	runtime.Identifyable
-}
-
-func (key objectKey) String() string { return key.KindKey.String() + " " + key.GetIdentifier() }
-
-func NewKindKey(gvk schema.GroupVersionKind) KindKey {
-	return kindKey(gvk)
-}
-
-func NewObjectKey(kind KindKey, id runtime.Identifyable) ObjectKey {
-	return objectKey{kind, id}
-}
diff --git a/pkg/storage/kube/namespaces.go b/pkg/storage/kube/namespaces.go
new file mode 100644
index 0000000..3e509ce
--- /dev/null
+++ b/pkg/storage/kube/namespaces.go
@@ -0,0 +1,111 @@
+package kube
+
+import (
+	"sync"
+
+	"github.com/weaveworks/libgitops/pkg/storage/backend"
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+	"k8s.io/apimachinery/pkg/api/meta"
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+	"k8s.io/apimachinery/pkg/runtime/schema"
+)
+
+// TODO: Make an example component that iterates through all of a raw.Storage's
+// or FileFinder's objects, and just reads them, converts them into the current
+// hub version.
+
+// TODO: Make a composite Storage that encrypts secrets using a key
+
+// NewNamespaceEnforcer returns a backend.NamespaceEnforcer that
+// enforces namespacing rules (approximately) in the same way as
+// Kubernetes itself does. The following rules are applied:
+//
+// if object is namespaced {
+// 		if .metadata.namespace == "" {
+// 			.metadata.namespace = "default"
+// 		} else { // .metadata.namespace != ""
+// 			Make sure that such a v1.Namespace object
+// 			exists in the system.
+//		}
+// }else { // object is non-namespaced
+//		if .metadata.namespace != "" {
+// 			.metadata.namespace = ""
+//		}
+// }
+//
+// Underneath, backend.GenericNamespaceEnforcer is used. Refer
+// to the documentation of that if you want the functionality
+// to be slightly different. (e.g. any namespace value is valid).
+//
+// TODO: Maybe we want to validate the namespace string itself?
+func NewNamespaceEnforcer() backend.NamespaceEnforcer {
+	return backend.GenericNamespaceEnforcer{
+		DefaultNamespace: metav1.NamespaceDefault,
+		NamespaceGroupKind: &core.GroupKind{
+			Group: "", // legacy name for the core API group
+			Kind:  "Namespace",
+		},
+	}
+}
+
+// SimpleRESTMapper is a subset of the meta.RESTMapper interface
+type SimpleRESTMapper interface {
+	// RESTMapping identifies a preferred resource mapping for the provided group kind.
+	RESTMapping(gk schema.GroupKind, versions ...string) (*meta.RESTMapping, error)
+}
+
+// RESTMapperToNamespacer implements the Namespacer interface by fetching (and caching) data
+// from the given RESTMapper interface, that is compatible with any meta.RESTMapper implementation.
+// This allows you to e.g. pass in a meta.RESTMapper yielded from
+// sigs.k8s.io/controller-runtime/pkg/client/apiutil.NewDiscoveryRESTMapper(c *rest.Config), or
+// k8s.io/client-go/restmapper.NewDiscoveryRESTMapper(groups []*restmapper.APIGroupResources)
+// in order to look up namespacing information from either a running API server, or statically, from
+// the list of restmapper.APIGroupResources.
+func RESTMapperToNamespacer(mapper SimpleRESTMapper) core.Namespacer {
+	return &restNamespacer{
+		mapper:        mapper,
+		mappingByType: make(map[schema.GroupKind]*meta.RESTMapping),
+		mu:            &sync.RWMutex{},
+	}
+}
+
+var _ core.Namespacer = &restNamespacer{}
+
+type restNamespacer struct {
+	mapper SimpleRESTMapper
+
+	mappingByType map[schema.GroupKind]*meta.RESTMapping
+	mu            *sync.RWMutex
+}
+
+func (n *restNamespacer) IsNamespaced(gk schema.GroupKind) (bool, error) {
+	m, err := n.getMapping(gk)
+	if err != nil {
+		return false, err
+	}
+	return mappingNamespaced(m), nil
+}
+
+func (n *restNamespacer) getMapping(gk schema.GroupKind) (*meta.RESTMapping, error) {
+	n.mu.RLock()
+	mapping, ok := n.mappingByType[gk]
+	n.mu.RUnlock()
+	// If already cached, we're ok
+	if ok {
+		return mapping, nil
+	}
+
+	// Write the mapping info to our cache
+	n.mu.Lock()
+	defer n.mu.Unlock()
+	m, err := n.mapper.RESTMapping(gk)
+	if err != nil {
+		return nil, err
+	}
+	n.mappingByType[gk] = m
+	return m, nil
+}
+
+func mappingNamespaced(mapping *meta.RESTMapping) bool {
+	return mapping.Scope.Name() == meta.RESTScopeNameNamespace
+}
diff --git a/pkg/storage/mappedrawstorage.go b/pkg/storage/mappedrawstorage.go
deleted file mode 100644
index d41641c..0000000
--- a/pkg/storage/mappedrawstorage.go
+++ /dev/null
@@ -1,177 +0,0 @@
-package storage
-
-import (
-	"fmt"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"sync"
-
-	log "github.com/sirupsen/logrus"
-	"github.com/weaveworks/libgitops/pkg/serializer"
-	"github.com/weaveworks/libgitops/pkg/util"
-)
-
-var (
-	// ErrNotTracked is returned when the requested resource wasn't found.
-	ErrNotTracked = fmt.Errorf("untracked object: %w", ErrNotFound)
-)
-
-// MappedRawStorage is an interface for RawStorages which store their
-// data in a flat/unordered directory format like manifest directories.
-type MappedRawStorage interface {
-	RawStorage
-
-	// AddMapping binds a Key's virtual path to a physical file path
-	AddMapping(key ObjectKey, path string)
-	// RemoveMapping removes the physical file
-	// path mapping matching the given Key
-	RemoveMapping(key ObjectKey)
-
-	// SetMappings overwrites all known mappings
-	SetMappings(m map[ObjectKey]string)
-}
-
-func NewGenericMappedRawStorage(dir string) MappedRawStorage {
-	return &GenericMappedRawStorage{
-		dir:          dir,
-		fileMappings: make(map[ObjectKey]string),
-		mux:          &sync.Mutex{},
-	}
-}
-
-// GenericMappedRawStorage is the default implementation of a MappedRawStorage,
-// it stores files in the given directory via a path translation map.
-type GenericMappedRawStorage struct {
-	dir          string
-	fileMappings map[ObjectKey]string
-	mux          *sync.Mutex
-}
-
-func (r *GenericMappedRawStorage) realPath(key ObjectKey) (string, error) {
-	r.mux.Lock()
-	path, ok := r.fileMappings[key]
-	r.mux.Unlock()
-	if !ok {
-		return "", fmt.Errorf("GenericMappedRawStorage: cannot resolve %q: %w", key, ErrNotTracked)
-	}
-
-	return path, nil
-}
-
-// If the file doesn't exist, returns ErrNotFound + ErrNotTracked.
-func (r *GenericMappedRawStorage) Read(key ObjectKey) ([]byte, error) {
-	file, err := r.realPath(key)
-	if err != nil {
-		return nil, err
-	}
-
-	return ioutil.ReadFile(file)
-}
-
-func (r *GenericMappedRawStorage) Exists(key ObjectKey) bool {
-	file, err := r.realPath(key)
-	if err != nil {
-		return false
-	}
-
-	return util.FileExists(file)
-}
-
-func (r *GenericMappedRawStorage) Write(key ObjectKey, content []byte) error {
-	// GenericMappedRawStorage isn't going to generate files itself,
-	// only write if the file is already known
-	file, err := r.realPath(key)
-	if err != nil {
-		return err
-	}
-
-	return ioutil.WriteFile(file, content, 0644)
-}
-
-// If the file doesn't exist, returns ErrNotFound + ErrNotTracked.
-func (r *GenericMappedRawStorage) Delete(key ObjectKey) (err error) {
-	file, err := r.realPath(key)
-	if err != nil {
-		return
-	}
-
-	// GenericMappedRawStorage files can be deleted
-	// externally, check that the file exists first
-	if util.FileExists(file) {
-		err = os.Remove(file)
-	}
-
-	if err == nil {
-		r.RemoveMapping(key)
-	}
-
-	return
-}
-
-func (r *GenericMappedRawStorage) List(kind KindKey) ([]ObjectKey, error) {
-	result := make([]ObjectKey, 0)
-
-	for key := range r.fileMappings {
-		// Include objects with the same kind and group, ignore version mismatches
-		if key.EqualsGVK(kind, false) {
-			result = append(result, key)
-		}
-	}
-
-	return result, nil
-}
-
-// This returns the modification time as a UnixNano string.
-// If the file doesn't exist, returns ErrNotFound + ErrNotTracked.
-func (r *GenericMappedRawStorage) Checksum(key ObjectKey) (string, error) {
-	path, err := r.realPath(key)
-	if err != nil {
-		return "", err
-	}
-
-	return checksumFromModTime(path)
-}
-
-func (r *GenericMappedRawStorage) ContentType(key ObjectKey) (ct serializer.ContentType) {
-	if file, err := r.realPath(key); err == nil {
-		ct = ContentTypes[filepath.Ext(file)] // Retrieve the correct format based on the extension
-	}
-
-	return
-}
-
-func (r *GenericMappedRawStorage) WatchDir() string {
-	return r.dir
-}
-
-func (r *GenericMappedRawStorage) GetKey(path string) (ObjectKey, error) {
-	for key, p := range r.fileMappings {
-		if p == path {
-			return key, nil
-		}
-	}
-
-	return objectKey{}, fmt.Errorf("no mapping found for path %q", path)
-}
-
-func (r *GenericMappedRawStorage) AddMapping(key ObjectKey, path string) {
-	log.Debugf("GenericMappedRawStorage: AddMapping: %q -> %q", key, path)
-	r.mux.Lock()
-	r.fileMappings[key] = path
-	r.mux.Unlock()
-}
-
-func (r *GenericMappedRawStorage) RemoveMapping(key ObjectKey) {
-	log.Debugf("GenericMappedRawStorage: RemoveMapping: %q", key)
-	r.mux.Lock()
-	delete(r.fileMappings, key)
-	r.mux.Unlock()
-}
-
-func (r *GenericMappedRawStorage) SetMappings(m map[ObjectKey]string) {
-	log.Debugf("GenericMappedRawStorage: SetMappings: %v", m)
-	r.mux.Lock()
-	r.fileMappings = m
-	r.mux.Unlock()
-}
diff --git a/pkg/storage/rawstorage.go b/pkg/storage/rawstorage.go
deleted file mode 100644
index 9330433..0000000
--- a/pkg/storage/rawstorage.go
+++ /dev/null
@@ -1,217 +0,0 @@
-package storage
-
-import (
-	"fmt"
-	"io/ioutil"
-	"os"
-	"path"
-	"path/filepath"
-	"strconv"
-	"strings"
-
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/serializer"
-	"github.com/weaveworks/libgitops/pkg/util"
-	"k8s.io/apimachinery/pkg/runtime/schema"
-)
-
-// RawStorage is a Key-indexed low-level interface to
-// store byte-encoded Objects (resources) in non-volatile
-// memory.
-type RawStorage interface {
-	// Read returns a resource's content based on key.
-	// If the resource does not exist, it returns ErrNotFound.
-	Read(key ObjectKey) ([]byte, error)
-	// Exists checks if the resource indicated by key exists.
-	Exists(key ObjectKey) bool
-	// Write writes the given content to the resource indicated by key.
-	// Error returns are implementation-specific.
-	Write(key ObjectKey, content []byte) error
-	// Delete deletes the resource indicated by key.
-	// If the resource does not exist, it returns ErrNotFound.
-	Delete(key ObjectKey) error
-	// List returns all matching object keys based on the given KindKey.
-	List(key KindKey) ([]ObjectKey, error)
-	// Checksum returns a string checksum for the resource indicated by key.
-	// If the resource does not exist, it returns ErrNotFound.
-	Checksum(key ObjectKey) (string, error)
-	// ContentType returns the content type of the contents of the resource indicated by key.
-	ContentType(key ObjectKey) serializer.ContentType
-
-	// WatchDir returns the path for Watchers to watch changes in.
-	WatchDir() string
-	// GetKey retrieves the Key containing the virtual path based
-	// on the given physical file path returned by a Watcher.
-	GetKey(path string) (ObjectKey, error)
-}
-
-func NewGenericRawStorage(dir string, gv schema.GroupVersion, ct serializer.ContentType) RawStorage {
-	ext := extForContentType(ct)
-	if ext == "" {
-		panic("Invalid content type")
-	}
-	return &GenericRawStorage{
-		dir: dir,
-		gv:  gv,
-		ct:  ct,
-		ext: ext,
-	}
-}
-
-// GenericRawStorage is a rawstorage which stores objects as JSON files on disk,
-// in the form: <dir>/<kind>/<identifier>/metadata.json.
-// The GenericRawStorage only supports one GroupVersion at a time, and will error if given
-// any other resources
-type GenericRawStorage struct {
-	dir string
-	gv  schema.GroupVersion
-	ct  serializer.ContentType
-	ext string
-}
-
-func (r *GenericRawStorage) keyPath(key ObjectKey) string {
-	return path.Join(r.dir, key.GetKind(), key.GetIdentifier(), fmt.Sprintf("metadata%s", r.ext))
-}
-
-func (r *GenericRawStorage) kindKeyPath(kindKey KindKey) string {
-	return path.Join(r.dir, kindKey.GetKind())
-}
-
-func (r *GenericRawStorage) validateGroupVersion(kind KindKey) error {
-	if r.gv.Group == kind.GetGroup() && r.gv.Version == kind.GetVersion() {
-		return nil
-	}
-
-	return fmt.Errorf("GroupVersion %s/%s not supported by this GenericRawStorage", kind.GetGroup(), kind.GetVersion())
-}
-
-func (r *GenericRawStorage) Read(key ObjectKey) ([]byte, error) {
-	// Validate GroupVersion first
-	if err := r.validateGroupVersion(key); err != nil {
-		return nil, err
-	}
-
-	// Check if the resource indicated by key exists
-	if !r.Exists(key) {
-		return nil, ErrNotFound
-	}
-
-	return ioutil.ReadFile(r.keyPath(key))
-}
-
-func (r *GenericRawStorage) Exists(key ObjectKey) bool {
-	// Validate GroupVersion first
-	if err := r.validateGroupVersion(key); err != nil {
-		return false
-	}
-
-	return util.FileExists(r.keyPath(key))
-}
-
-func (r *GenericRawStorage) Write(key ObjectKey, content []byte) error {
-	// Validate GroupVersion first
-	if err := r.validateGroupVersion(key); err != nil {
-		return err
-	}
-
-	file := r.keyPath(key)
-
-	// Create the underlying directories if they do not exist already
-	if !r.Exists(key) {
-		if err := os.MkdirAll(path.Dir(file), 0755); err != nil {
-			return err
-		}
-	}
-
-	return ioutil.WriteFile(file, content, 0644)
-}
-
-func (r *GenericRawStorage) Delete(key ObjectKey) error {
-	// Validate GroupVersion first
-	if err := r.validateGroupVersion(key); err != nil {
-		return err
-	}
-
-	// Check if the resource indicated by key exists
-	if !r.Exists(key) {
-		return ErrNotFound
-	}
-
-	return os.RemoveAll(path.Dir(r.keyPath(key)))
-}
-
-func (r *GenericRawStorage) List(kind KindKey) ([]ObjectKey, error) {
-	// Validate GroupVersion first
-	if err := r.validateGroupVersion(kind); err != nil {
-		return nil, err
-	}
-
-	entries, err := ioutil.ReadDir(r.kindKeyPath(kind))
-	if err != nil {
-		return nil, err
-	}
-
-	result := make([]ObjectKey, 0, len(entries))
-	for _, entry := range entries {
-		result = append(result, NewObjectKey(kind, runtime.NewIdentifier(entry.Name())))
-	}
-
-	return result, nil
-}
-
-// This returns the modification time as a UnixNano string
-// If the file doesn't exist, return ErrNotFound
-func (r *GenericRawStorage) Checksum(key ObjectKey) (string, error) {
-	// Validate GroupVersion first
-	if err := r.validateGroupVersion(key); err != nil {
-		return "", err
-	}
-
-	// Check if the resource indicated by key exists
-	if !r.Exists(key) {
-		return "", ErrNotFound
-	}
-
-	return checksumFromModTime(r.keyPath(key))
-}
-
-func (r *GenericRawStorage) ContentType(_ ObjectKey) serializer.ContentType {
-	return r.ct
-}
-
-func (r *GenericRawStorage) WatchDir() string {
-	return r.dir
-}
-
-func (r *GenericRawStorage) GetKey(p string) (ObjectKey, error) {
-	splitDir := strings.Split(filepath.Clean(r.dir), string(os.PathSeparator))
-	splitPath := strings.Split(filepath.Clean(p), string(os.PathSeparator))
-
-	if len(splitPath) < len(splitDir)+2 {
-		return nil, fmt.Errorf("path not long enough: %s", p)
-	}
-
-	for i := 0; i < len(splitDir); i++ {
-		if splitDir[i] != splitPath[i] {
-			return nil, fmt.Errorf("path has wrong base: %s", p)
-		}
-	}
-	kind := splitPath[len(splitDir)]
-	uid := splitPath[len(splitDir)+1]
-	gvk := schema.GroupVersionKind{
-		Group:   r.gv.Group,
-		Version: r.gv.Version,
-		Kind:    kind,
-	}
-
-	return NewObjectKey(NewKindKey(gvk), runtime.NewIdentifier(uid)), nil
-}
-
-func checksumFromModTime(path string) (string, error) {
-	fi, err := os.Stat(path)
-	if err != nil {
-		return "", err
-	}
-
-	return strconv.FormatInt(fi.ModTime().UnixNano(), 10), nil
-}
diff --git a/pkg/storage/storage.go b/pkg/storage/storage.go
deleted file mode 100644
index 4d94232..0000000
--- a/pkg/storage/storage.go
+++ /dev/null
@@ -1,454 +0,0 @@
-package storage
-
-import (
-	"bytes"
-	"errors"
-	"fmt"
-	"io"
-
-	"github.com/sirupsen/logrus"
-	"github.com/weaveworks/libgitops/pkg/filter"
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/serializer"
-	patchutil "github.com/weaveworks/libgitops/pkg/util/patch"
-	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
-	kruntime "k8s.io/apimachinery/pkg/runtime"
-	"k8s.io/apimachinery/pkg/runtime/schema"
-)
-
-var (
-	// ErrAmbiguousFind is returned when the user requested one object from a List+Filter process.
-	ErrAmbiguousFind = errors.New("two or more results were aquired when one was expected")
-	// ErrNotFound is returned when the requested resource wasn't found.
-	ErrNotFound = errors.New("resource not found")
-	// ErrAlreadyExists is returned when when WriteStorage.Create is called for an already stored object.
-	ErrAlreadyExists = errors.New("resource already exists")
-)
-
-type ReadStorage interface {
-	// Get returns a new Object for the resource at the specified kind/uid path, based on the file content.
-	// If the resource referred to by the given ObjectKey does not exist, Get returns ErrNotFound.
-	Get(key ObjectKey) (runtime.Object, error)
-
-	// List lists Objects for the specific kind. Optionally, filters can be applied (see the filter package
-	// for more information, e.g. filter.NameFilter{} and filter.UIDFilter{})
-	List(kind KindKey, opts ...filter.ListOption) ([]runtime.Object, error)
-
-	// Find does a List underneath, also using filters, but always returns one object. If the List
-	// underneath returned two or more results, ErrAmbiguousFind is returned. If no match was found,
-	// ErrNotFound is returned.
-	Find(kind KindKey, opts ...filter.ListOption) (runtime.Object, error)
-
-	//
-	// Partial object getters.
-	// TODO: Figure out what we should do with these, do we need them and if so where?
-	//
-
-	// GetMeta returns a new Object's APIType representation for the resource at the specified kind/uid path.
-	// If the resource referred to by the given ObjectKey does not exist, GetMeta returns ErrNotFound.
-	GetMeta(key ObjectKey) (runtime.PartialObject, error)
-	// ListMeta lists all Objects' APIType representation. In other words,
-	// only metadata about each Object is unmarshalled (uid/name/kind/apiVersion).
-	// This allows for faster runs (no need to unmarshal "the world"), and less
-	// resource usage, when only metadata is unmarshalled into memory
-	ListMeta(kind KindKey) ([]runtime.PartialObject, error)
-
-	//
-	// Cache-related methods.
-	//
-
-	// Checksum returns a string representing the state of an Object on disk
-	// The checksum should change if any modifications have been made to the
-	// Object on disk, it can be e.g. the Object's modification timestamp or
-	// calculated checksum. If the Object is not found, ErrNotFound is returned.
-	Checksum(key ObjectKey) (string, error)
-	// Count returns the amount of available Objects of a specific kind
-	// This is used by Caches to check if all Objects are cached to perform a List
-	Count(kind KindKey) (uint64, error)
-
-	//
-	// Access to underlying Resources.
-	//
-
-	// RawStorage returns the RawStorage instance backing this Storage
-	RawStorage() RawStorage
-	// Serializer returns the serializer
-	Serializer() serializer.Serializer
-
-	//
-	// Misc methods.
-	//
-
-	// ObjectKeyFor returns the ObjectKey for the given object
-	ObjectKeyFor(obj runtime.Object) (ObjectKey, error)
-	// Close closes all underlying resources (e.g. goroutines) used; before the application exits
-	Close() error
-}
-
-type WriteStorage interface {
-	// Create creates an entry for and stores the given Object in the storage. The Object must be new to the storage.
-	// The ObjectMeta.CreationTimestamp field is set automatically to the current time if it is unset.
-	Create(obj runtime.Object) error
-	// Update updates the state of the given Object in the storage. The Object must exist in the storage.
-	// The ObjectMeta.CreationTimestamp field is set automatically to the current time if it is unset.
-	Update(obj runtime.Object) error
-
-	// Patch performs a strategic merge patch on the Object with the given UID, using the byte-encoded patch given
-	Patch(key ObjectKey, patch []byte) error
-	// Delete removes an Object from the storage
-	Delete(key ObjectKey) error
-}
-
-// Storage is an interface for persisting and retrieving API objects to/from a backend
-// One Storage instance handles all different Kinds of Objects
-type Storage interface {
-	ReadStorage
-	WriteStorage
-}
-
-// NewGenericStorage constructs a new Storage
-func NewGenericStorage(rawStorage RawStorage, serializer serializer.Serializer, identifiers []runtime.IdentifierFactory) Storage {
-	return &GenericStorage{rawStorage, serializer, patchutil.NewPatcher(serializer), identifiers}
-}
-
-// GenericStorage implements the Storage interface
-type GenericStorage struct {
-	raw         RawStorage
-	serializer  serializer.Serializer
-	patcher     patchutil.Patcher
-	identifiers []runtime.IdentifierFactory
-}
-
-var _ Storage = &GenericStorage{}
-
-func (s *GenericStorage) Serializer() serializer.Serializer {
-	return s.serializer
-}
-
-// Get returns a new Object for the resource at the specified kind/uid path, based on the file content
-func (s *GenericStorage) Get(key ObjectKey) (runtime.Object, error) {
-	content, err := s.raw.Read(key)
-	if err != nil {
-		return nil, err
-	}
-
-	return s.decode(key, content)
-}
-
-// TODO: Verify this works
-// GetMeta returns a new Object's APIType representation for the resource at the specified kind/uid path
-func (s *GenericStorage) GetMeta(key ObjectKey) (runtime.PartialObject, error) {
-	content, err := s.raw.Read(key)
-	if err != nil {
-		return nil, err
-	}
-
-	return s.decodeMeta(key, content)
-}
-
-// TODO: Make sure we don't save a partial object
-func (s *GenericStorage) write(key ObjectKey, obj runtime.Object) error {
-	// Set the content type based on the format given by the RawStorage, but default to JSON
-	contentType := serializer.ContentTypeJSON
-	if ct := s.raw.ContentType(key); len(ct) != 0 {
-		contentType = ct
-	}
-
-	// Set creationTimestamp if not already populated
-	t := obj.GetCreationTimestamp()
-	if t.IsZero() {
-		obj.SetCreationTimestamp(metav1.Now())
-	}
-
-	var objBytes bytes.Buffer
-	err := s.serializer.Encoder().Encode(serializer.NewFrameWriter(contentType, &objBytes), obj)
-	if err != nil {
-		return err
-	}
-
-	return s.raw.Write(key, objBytes.Bytes())
-}
-
-func (s *GenericStorage) Create(obj runtime.Object) error {
-	key, err := s.ObjectKeyFor(obj)
-	if err != nil {
-		return err
-	}
-
-	if s.raw.Exists(key) {
-		return ErrAlreadyExists
-	}
-
-	// The object was not found so we can safely create it
-	return s.write(key, obj)
-}
-
-func (s *GenericStorage) Update(obj runtime.Object) error {
-	key, err := s.ObjectKeyFor(obj)
-	if err != nil {
-		return err
-	}
-
-	if !s.raw.Exists(key) {
-		return ErrNotFound
-	}
-
-	// The object was found so we can safely update it
-	return s.write(key, obj)
-}
-
-// Patch performs a strategic merge patch on the object with the given UID, using the byte-encoded patch given
-func (s *GenericStorage) Patch(key ObjectKey, patch []byte) error {
-	oldContent, err := s.raw.Read(key)
-	if err != nil {
-		return err
-	}
-
-	newContent, err := s.patcher.Apply(oldContent, patch, key.GetGVK())
-	if err != nil {
-		return err
-	}
-
-	return s.raw.Write(key, newContent)
-}
-
-// Delete removes an Object from the storage
-func (s *GenericStorage) Delete(key ObjectKey) error {
-	return s.raw.Delete(key)
-}
-
-// Checksum returns a string representing the state of an Object on disk
-func (s *GenericStorage) Checksum(key ObjectKey) (string, error) {
-	return s.raw.Checksum(key)
-}
-
-func (s *GenericStorage) list(kind KindKey) (result []runtime.Object, walkerr error) {
-	walkerr = s.walkKind(kind, func(key ObjectKey, content []byte) error {
-		obj, err := s.decode(key, content)
-		if err != nil {
-			return err
-		}
-
-		result = append(result, obj)
-		return nil
-	})
-	return
-}
-
-// List lists Objects for the specific kind. Optionally, filters can be applied (see the filter package
-// for more information, e.g. filter.NameFilter{} and filter.UIDFilter{})
-func (s *GenericStorage) List(kind KindKey, opts ...filter.ListOption) ([]runtime.Object, error) {
-	// First, complete the options struct
-	o, err := filter.MakeListOptions(opts...)
-	if err != nil {
-		return nil, err
-	}
-
-	// Do an internal list to get all objects
-	objs, err := s.list(kind)
-	if err != nil {
-		return nil, err
-	}
-
-	// For all list filters, pipe the output of the previous as the input to the next, in order.
-	for _, filter := range o.Filters {
-		objs, err = filter.Filter(objs...)
-		if err != nil {
-			return nil, err
-		}
-	}
-	return objs, nil
-}
-
-// Find does a List underneath, also using filters, but always returns one object. If the List
-// underneath returned two or more results, ErrAmbiguousFind is returned. If no match was found,
-// ErrNotFound is returned.
-func (s *GenericStorage) Find(kind KindKey, opts ...filter.ListOption) (runtime.Object, error) {
-	// Do a normal list underneath
-	objs, err := s.List(kind, opts...)
-	if err != nil {
-		return nil, err
-	}
-	// Return based on the object count
-	switch l := len(objs); l {
-	case 0:
-		return nil, fmt.Errorf("no Find match found: %w", ErrNotFound)
-	case 1:
-		return objs[0], nil
-	default:
-		return nil, fmt.Errorf("too many (%d) matches: %v: %w", l, objs, ErrAmbiguousFind)
-	}
-}
-
-// ListMeta lists all Objects' APIType representation. In other words,
-// only metadata about each Object is unmarshalled (uid/name/kind/apiVersion).
-// This allows for faster runs (no need to unmarshal "the world"), and less
-// resource usage, when only metadata is unmarshalled into memory
-func (s *GenericStorage) ListMeta(kind KindKey) (result []runtime.PartialObject, walkerr error) {
-	walkerr = s.walkKind(kind, func(key ObjectKey, content []byte) error {
-
-		obj, err := s.decodeMeta(key, content)
-		if err != nil {
-			return err
-		}
-
-		result = append(result, obj)
-		return nil
-	})
-	return
-}
-
-// Count counts the Objects for the specific kind
-func (s *GenericStorage) Count(kind KindKey) (uint64, error) {
-	entries, err := s.raw.List(kind)
-	return uint64(len(entries)), err
-}
-
-func (s *GenericStorage) ObjectKeyFor(obj runtime.Object) (ObjectKey, error) {
-	var gvk schema.GroupVersionKind
-	var err error
-
-	_, isPartialObject := obj.(runtime.PartialObject)
-	if isPartialObject {
-		gvk = obj.GetObjectKind().GroupVersionKind()
-		// TODO: Error if empty
-	} else {
-		gvk, err = serializer.GVKForObject(s.serializer.Scheme(), obj)
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	id := s.identify(obj)
-	if id == nil {
-		return nil, fmt.Errorf("couldn't identify object")
-	}
-	return NewObjectKey(NewKindKey(gvk), id), nil
-}
-
-// RawStorage returns the RawStorage instance backing this Storage
-func (s *GenericStorage) RawStorage() RawStorage {
-	return s.raw
-}
-
-// Close closes all underlying resources (e.g. goroutines) used; before the application exits
-func (s *GenericStorage) Close() error {
-	return nil // nothing to do here for GenericStorage
-}
-
-// identify loops through the identifiers, in priority order, to identify the object correctly
-func (s *GenericStorage) identify(obj runtime.Object) runtime.Identifyable {
-	for _, identifier := range s.identifiers {
-
-		id, ok := identifier.Identify(obj)
-		if ok {
-			return id
-		}
-	}
-	return nil
-}
-
-func (s *GenericStorage) decode(key ObjectKey, content []byte) (runtime.Object, error) {
-	gvk := key.GetGVK()
-	// Decode the bytes to the internal version of the Object, if desired
-	isInternal := gvk.Version == kruntime.APIVersionInternal
-
-	// Decode the bytes into an Object
-	ct := s.raw.ContentType(key)
-	logrus.Infof("Decoding with content type %s", ct)
-	obj, err := s.serializer.Decoder(
-		serializer.WithConvertToHubDecode(isInternal),
-	).Decode(serializer.NewFrameReader(ct, serializer.FromBytes(content)))
-	if err != nil {
-		return nil, err
-	}
-
-	// Cast to runtime.Object, and make sure it works
-	metaObj, ok := obj.(runtime.Object)
-	if !ok {
-		return nil, fmt.Errorf("can't convert to libgitops.runtime.Object")
-	}
-
-	// Set the desired gvk of this Object from the caller
-	metaObj.GetObjectKind().SetGroupVersionKind(gvk)
-	return metaObj, nil
-}
-
-func (s *GenericStorage) decodeMeta(key ObjectKey, content []byte) (runtime.PartialObject, error) {
-	gvk := key.GetGVK()
-	partobjs, err := DecodePartialObjects(serializer.FromBytes(content), s.serializer.Scheme(), false, &gvk)
-	if err != nil {
-		return nil, err
-	}
-
-	return partobjs[0], nil
-}
-
-func (s *GenericStorage) walkKind(kind KindKey, fn func(key ObjectKey, content []byte) error) error {
-	keys, err := s.raw.List(kind)
-	if err != nil {
-		return err
-	}
-
-	for _, key := range keys {
-		// Allow metadata.json to not exist, although the directory does exist
-		if !s.raw.Exists(key) {
-			continue
-		}
-
-		content, err := s.raw.Read(key)
-		if err != nil {
-			return err
-		}
-
-		if err := fn(key, content); err != nil {
-			return err
-		}
-	}
-
-	return nil
-}
-
-// DecodePartialObjects reads any set of frames from the given ReadCloser, decodes the frames into
-// PartialObjects, validates that the decoded objects are known to the scheme, and optionally sets a default
-// group
-func DecodePartialObjects(rc io.ReadCloser, scheme *kruntime.Scheme, allowMultiple bool, defaultGVK *schema.GroupVersionKind) ([]runtime.PartialObject, error) {
-	fr := serializer.NewYAMLFrameReader(rc)
-
-	frames, err := serializer.ReadFrameList(fr)
-	if err != nil {
-		return nil, err
-	}
-
-	// If we only allow one frame, signal that early
-	if !allowMultiple && len(frames) != 1 {
-		return nil, fmt.Errorf("DecodePartialObjects: unexpected number of frames received from ReadCloser: %d expected 1", len(frames))
-	}
-
-	objs := make([]runtime.PartialObject, 0, len(frames))
-	for _, frame := range frames {
-		partobj, err := runtime.NewPartialObject(frame)
-		if err != nil {
-			return nil, err
-		}
-
-		gvk := partobj.GetObjectKind().GroupVersionKind()
-
-		// Don't decode API objects unknown to the scheme (e.g. Kubernetes manifests)
-		if !scheme.Recognizes(gvk) {
-			// TODO: Typed error
-			return nil, fmt.Errorf("unknown GroupVersionKind: %s", partobj.GetObjectKind().GroupVersionKind())
-		}
-
-		if defaultGVK != nil {
-			// Set the desired gvk from the caller of this Object, if defaultGVK is set
-			// In practice, this means, although we got an external type,
-			// we might want internal Objects later in the client. Hence,
-			// set the right expectation here
-			partobj.GetObjectKind().SetGroupVersionKind(gvk)
-		}
-
-		objs = append(objs, partobj)
-	}
-	return objs, nil
-}
diff --git a/pkg/storage/sync/storage.go b/pkg/storage/sync/storage.go
deleted file mode 100644
index 458f7fa..0000000
--- a/pkg/storage/sync/storage.go
+++ /dev/null
@@ -1,188 +0,0 @@
-package sync
-
-/*
-
-TODO: Revisit if we need this file/package in the future.
-
-import (
-	"fmt"
-
-	log "github.com/sirupsen/logrus"
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/storage"
-	"github.com/weaveworks/libgitops/pkg/storage/watch"
-	"github.com/weaveworks/libgitops/pkg/storage/watch/update"
-	"github.com/weaveworks/libgitops/pkg/util/sync"
-)
-
-const updateBuffer = 4096 // How many updates to buffer, 4096 should be enough for even a high update frequency
-
-// SyncStorage is a Storage implementation taking in multiple Storages and
-// keeping them in sync. Any write operation executed on the SyncStorage
-// is propagated to all of the Storages it manages (including the embedded
-// one). For any retrieval or generation operation, the embedded Storage
-// will be used (it is treated as read-write). As all other Storages only
-// receive write operations, they can be thought of as write-only.
-type SyncStorage struct {
-	storage.Storage
-	storages       []storage.Storage
-	inboundStream  update.UpdateStream
-	outboundStream update.UpdateStream
-	monitor        *sync.Monitor
-}
-
-// SyncStorage implements update.EventStorage.
-var _ update.EventStorage = &SyncStorage{}
-
-// NewSyncStorage constructs a new SyncStorage
-func NewSyncStorage(rwStorage storage.Storage, wStorages ...storage.Storage) storage.Storage {
-	ss := &SyncStorage{
-		Storage:  rwStorage,
-		storages: append(wStorages, rwStorage),
-	}
-
-	for _, s := range ss.storages {
-		if watchStorage, ok := s.(watch.WatchStorage); ok {
-			// Populate eventStream if we found a watchstorage
-			if ss.inboundStream == nil {
-				ss.inboundStream = make(update.UpdateStream, updateBuffer)
-			}
-			watchStorage.SetUpdateStream(ss.inboundStream)
-		}
-	}
-
-	if ss.inboundStream != nil {
-		ss.monitor = sync.RunMonitor(ss.monitorFunc)
-		ss.outboundStream = make(update.UpdateStream, updateBuffer)
-	}
-
-	return ss
-}
-
-// Set is propagated to all Storages
-func (ss *SyncStorage) Set(obj runtime.Object) error {
-	return ss.runAll(func(s storage.Storage) error {
-		return s.Set(obj)
-	})
-}
-
-// Patch is propagated to all Storages
-func (ss *SyncStorage) Patch(key storage.ObjectKey, patch []byte) error {
-	return ss.runAll(func(s storage.Storage) error {
-		return s.Patch(key, patch)
-	})
-}
-
-// Delete is propagated to all Storages
-func (ss *SyncStorage) Delete(key storage.ObjectKey) error {
-	return ss.runAll(func(s storage.Storage) error {
-		return s.Delete(key)
-	})
-}
-
-func (ss *SyncStorage) Close() error {
-	// Close all WatchStorages
-	for _, s := range ss.storages {
-		if watchStorage, ok := s.(watch.WatchStorage); ok {
-			_ = watchStorage.Close()
-		}
-	}
-
-	// Close the event streams if set
-	if ss.inboundStream != nil {
-		close(ss.inboundStream)
-	}
-	if ss.outboundStream != nil {
-		close(ss.outboundStream)
-	}
-	// Wait for the monitor goroutine
-	ss.monitor.Wait()
-	return nil
-}
-
-func (ss *SyncStorage) GetUpdateStream() update.UpdateStream {
-	return ss.outboundStream
-}
-
-// runAll runs the given function for all Storages in parallel and aggregates all errors
-func (ss *SyncStorage) runAll(f func(storage.Storage) error) (err error) {
-	type result struct {
-		int
-		error
-	}
-
-	errC := make(chan result)
-	for i, s := range ss.storages {
-		go func(i int, s storage.Storage) {
-			errC <- result{i, f(s)}
-		}(i, s) // NOTE: This requires i and s as arguments, otherwise they will be evaluated for one Storage only
-	}
-
-	for i := 0; i < len(ss.storages); i++ {
-		if result := <-errC; result.error != nil {
-			if err == nil {
-				err = fmt.Errorf("SyncStorage: Error in Storage %d: %v", result.int, result.error)
-			} else {
-				err = fmt.Errorf("%v\n%29s %d: %v", err, "and error in Storage", result.int, result.error)
-			}
-		}
-	}
-
-	return
-}
-
-func (ss *SyncStorage) monitorFunc() {
-	log.Debug("SyncStorage: Monitoring thread started")
-	defer log.Debug("SyncStorage: Monitoring thread stopped")
-
-	// TODO: Support detecting changes done when the GitOps daemon isn't running
-	// This is difficult to do though, as we have don't know which state is the latest
-	// For now, only update the state on write when the daemon is running
-	for {
-		upd, ok := <-ss.inboundStream
-		if ok {
-			log.Debugf("SyncStorage: Received update %v %t", upd, ok)
-
-			gvk := upd.PartialObject.GetObjectKind().GroupVersionKind()
-			uid := upd.PartialObject.GetUID()
-			key := storage.NewObjectKey(storage.NewKindKey(gvk), runtime.NewIdentifier(string(uid)))
-			log.Debugf("SyncStorage: Object has gvk=%q and uid=%q", gvk, uid)
-
-			switch upd.Event {
-			case update.ObjectEventModify, update.ObjectEventCreate:
-				// First load the Object using the Storage given in the update,
-				// then set it using the client constructed above
-
-				obj, err := upd.Storage.Get(key)
-				if err != nil {
-					log.Errorf("Failed to get Object with UID %q: %v", upd.PartialObject.GetUID(), err)
-					continue
-				}
-
-				if err = ss.Set(obj); err != nil {
-					log.Errorf("Failed to set Object with UID %q: %v", upd.PartialObject.GetUID(), err)
-					continue
-				}
-			case update.ObjectEventDelete:
-				// For deletion we use the generated "fake" APIType object
-				if err := ss.Delete(key); err != nil {
-					log.Errorf("Failed to delete Object with UID %q: %v", upd.PartialObject.GetUID(), err)
-					continue
-				}
-			}
-
-			// Send the update to the listeners unless the channel is full,
-			// in which case issue a warning. The channel can hold as many
-			// updates as updateBuffer specifies.
-			select {
-			case ss.outboundStream <- upd:
-				log.Debugf("SyncStorage: Sent update: %v", upd)
-			default:
-				log.Warn("SyncStorage: Failed to send update, channel full")
-			}
-		} else {
-			return
-		}
-	}
-}
-*/
diff --git a/pkg/storage/transaction/commit.go b/pkg/storage/transaction/commit.go
deleted file mode 100644
index 30e55ae..0000000
--- a/pkg/storage/transaction/commit.go
+++ /dev/null
@@ -1,79 +0,0 @@
-package transaction
-
-import (
-	"fmt"
-
-	"github.com/fluxcd/go-git-providers/validation"
-)
-
-// CommitResult describes a result of a transaction.
-type CommitResult interface {
-	// GetAuthorName describes the author's name (as per git config)
-	// +required
-	GetAuthorName() string
-	// GetAuthorEmail describes the author's email (as per git config)
-	// +required
-	GetAuthorEmail() string
-	// GetTitle describes the change concisely, so it can be used as a commit message or PR title.
-	// +required
-	GetTitle() string
-	// GetDescription contains optional extra information about the change.
-	// +optional
-	GetDescription() string
-
-	// GetMessage returns GetTitle() followed by a newline and GetDescription(), if set.
-	GetMessage() string
-	// Validate validates that all required fields are set, and given data is valid.
-	Validate() error
-}
-
-// GenericCommitResult implements CommitResult.
-var _ CommitResult = &GenericCommitResult{}
-
-// GenericCommitResult implements CommitResult.
-type GenericCommitResult struct {
-	// AuthorName describes the author's name (as per git config)
-	// +required
-	AuthorName string
-	// AuthorEmail describes the author's email (as per git config)
-	// +required
-	AuthorEmail string
-	// Title describes the change concisely, so it can be used as a commit message or PR title.
-	// +required
-	Title string
-	// Description contains optional extra information about the change.
-	// +optional
-	Description string
-}
-
-func (r *GenericCommitResult) GetAuthorName() string {
-	return r.AuthorName
-}
-func (r *GenericCommitResult) GetAuthorEmail() string {
-	return r.AuthorEmail
-}
-func (r *GenericCommitResult) GetTitle() string {
-	return r.Title
-}
-func (r *GenericCommitResult) GetDescription() string {
-	return r.Description
-}
-func (r *GenericCommitResult) GetMessage() string {
-	if len(r.Description) == 0 {
-		return r.Title
-	}
-	return fmt.Sprintf("%s\n%s", r.Title, r.Description)
-}
-func (r *GenericCommitResult) Validate() error {
-	v := validation.New("GenericCommitResult")
-	if len(r.AuthorName) == 0 {
-		v.Required("AuthorName")
-	}
-	if len(r.AuthorEmail) == 0 {
-		v.Required("AuthorEmail")
-	}
-	if len(r.Title) == 0 {
-		v.Required("Title")
-	}
-	return v.Error()
-}
diff --git a/pkg/storage/transaction/git.go b/pkg/storage/transaction/git.go
deleted file mode 100644
index efc57ab..0000000
--- a/pkg/storage/transaction/git.go
+++ /dev/null
@@ -1,161 +0,0 @@
-package transaction
-
-import (
-	"context"
-	"fmt"
-	"strings"
-
-	"github.com/sirupsen/logrus"
-	"github.com/weaveworks/libgitops/pkg/gitdir"
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/serializer"
-	"github.com/weaveworks/libgitops/pkg/storage"
-	"github.com/weaveworks/libgitops/pkg/util"
-	"github.com/weaveworks/libgitops/pkg/util/watcher"
-)
-
-var excludeDirs = []string{".git"}
-
-func NewGitStorage(gitDir gitdir.GitDirectory, prProvider PullRequestProvider, ser serializer.Serializer) (TransactionStorage, error) {
-	// Make sure the repo is cloned. If this func has already been called, it will be a no-op.
-	if err := gitDir.StartCheckoutLoop(); err != nil {
-		return nil, err
-	}
-
-	raw := storage.NewGenericMappedRawStorage(gitDir.Dir())
-	s := storage.NewGenericStorage(raw, ser, []runtime.IdentifierFactory{runtime.Metav1NameIdentifier})
-
-	gitStorage := &GitStorage{
-		ReadStorage: s,
-		s:           s,
-		raw:         raw,
-		gitDir:      gitDir,
-		prProvider:  prProvider,
-	}
-	// Do a first sync now, and then start the background loop
-	if err := gitStorage.sync(); err != nil {
-		return nil, err
-	}
-	gitStorage.syncLoop()
-
-	return gitStorage, nil
-}
-
-type GitStorage struct {
-	storage.ReadStorage
-
-	s          storage.Storage
-	raw        storage.MappedRawStorage
-	gitDir     gitdir.GitDirectory
-	prProvider PullRequestProvider
-}
-
-func (s *GitStorage) syncLoop() {
-	go func() {
-		for {
-			if commit, ok := <-s.gitDir.CommitChannel(); ok {
-				logrus.Debugf("GitStorage: Got info about commit %q, syncing...", commit)
-				if err := s.sync(); err != nil {
-					logrus.Errorf("GitStorage: Got sync error: %v", err)
-				}
-			}
-		}
-	}()
-}
-
-func (s *GitStorage) sync() error {
-	mappings, err := computeMappings(s.gitDir.Dir(), s.s)
-	if err != nil {
-		return err
-	}
-	logrus.Debugf("Rewriting the mappings to %v", mappings)
-	s.raw.SetMappings(mappings)
-	return nil
-}
-
-func (s *GitStorage) Transaction(ctx context.Context, streamName string, fn TransactionFunc) error {
-	// Append random bytes to the end of the stream name if it ends with a dash
-	if strings.HasSuffix(streamName, "-") {
-		suffix, err := util.RandomSHA(4)
-		if err != nil {
-			return err
-		}
-		streamName += suffix
-	}
-
-	// Make sure we have the latest available state
-	if err := s.gitDir.Pull(ctx); err != nil {
-		return err
-	}
-	// Make sure no other Git ops can take place during the transaction, wait for other ongoing operations.
-	s.gitDir.Suspend()
-	defer s.gitDir.Resume()
-	// Always switch back to the main branch afterwards.
-	// TODO ordering of the defers, and return deferred error
-	defer func() { _ = s.gitDir.CheckoutMainBranch() }()
-
-	// Check out a new branch with the given name
-	if err := s.gitDir.CheckoutNewBranch(streamName); err != nil {
-		return err
-	}
-	// Invoke the transaction
-	result, err := fn(ctx, s.s)
-	if err != nil {
-		return err
-	}
-	// Make sure the result is valid
-	if err := result.Validate(); err != nil {
-		return fmt.Errorf("transaction result is not valid: %w", err)
-	}
-	// Perform the commit
-	if err := s.gitDir.Commit(ctx, result.GetAuthorName(), result.GetAuthorEmail(), result.GetMessage()); err != nil {
-		return err
-	}
-	// Return if no PR should be made
-	prResult, ok := result.(PullRequestResult)
-	if !ok {
-		return nil
-	}
-	// If a PR was asked for, and no provider was given, error out
-	if s.prProvider == nil {
-		return ErrNoPullRequestProvider
-	}
-	// Create the PR using the provider.
-	return s.prProvider.CreatePullRequest(ctx, &GenericPullRequestSpec{
-		PullRequestResult: prResult,
-		MainBranch:        s.gitDir.MainBranch(),
-		MergeBranch:       streamName,
-		RepositoryRef:     s.gitDir.RepositoryRef(),
-	})
-}
-
-func computeMappings(dir string, s storage.Storage) (map[storage.ObjectKey]string, error) {
-	validExts := make([]string, 0, len(storage.ContentTypes))
-	for ext := range storage.ContentTypes {
-		validExts = append(validExts, ext)
-	}
-
-	files, err := watcher.WalkDirectoryForFiles(dir, validExts, excludeDirs)
-	if err != nil {
-		return nil, err
-	}
-
-	// TODO: Compute the difference between the earlier state, and implement EventStorage so the user
-	// can automatically subscribe to changes of objects between versions.
-	m := map[storage.ObjectKey]string{}
-	for _, file := range files {
-		partObjs, err := storage.DecodePartialObjects(serializer.FromFile(file), s.Serializer().Scheme(), false, nil)
-		if err != nil {
-			logrus.Errorf("couldn't decode %q into a partial object: %v", file, err)
-			continue
-		}
-		key, err := s.ObjectKeyFor(partObjs[0])
-		if err != nil {
-			logrus.Errorf("couldn't get objectkey for partial object: %v", err)
-			continue
-		}
-		logrus.Debugf("Adding mapping between %s and %q", key, file)
-		m[key] = file
-	}
-	return m, nil
-}
diff --git a/pkg/storage/transaction/pullrequest.go b/pkg/storage/transaction/pullrequest.go
deleted file mode 100644
index bf0fcf2..0000000
--- a/pkg/storage/transaction/pullrequest.go
+++ /dev/null
@@ -1,130 +0,0 @@
-package transaction
-
-import (
-	"context"
-
-	"github.com/fluxcd/go-git-providers/gitprovider"
-	"github.com/fluxcd/go-git-providers/validation"
-)
-
-// PullRequestResult can be returned from a TransactionFunc instead of a CommitResult, if
-// a PullRequest is desired to be created by the PullRequestProvider.
-type PullRequestResult interface {
-	// PullRequestResult is a superset of CommitResult
-	CommitResult
-
-	// GetLabels specifies what labels should be applied on the PR.
-	// +optional
-	GetLabels() []string
-	// GetAssignees specifies what user login names should be assigned to this PR.
-	// Note: Only users with "pull" access or more can be assigned.
-	// +optional
-	GetAssignees() []string
-	// GetMilestone specifies what milestone this should be attached to.
-	// +optional
-	GetMilestone() string
-}
-
-// GenericPullRequestResult implements PullRequestResult.
-var _ PullRequestResult = &GenericPullRequestResult{}
-
-// GenericPullRequestResult implements PullRequestResult.
-type GenericPullRequestResult struct {
-	// GenericPullRequestResult is a superset of a CommitResult.
-	CommitResult
-
-	// Labels specifies what labels should be applied on the PR.
-	// +optional
-	Labels []string
-	// Assignees specifies what user login names should be assigned to this PR.
-	// Note: Only users with "pull" access or more can be assigned.
-	// +optional
-	Assignees []string
-	// Milestone specifies what milestone this should be attached to.
-	// +optional
-	Milestone string
-}
-
-func (r *GenericPullRequestResult) GetLabels() []string {
-	return r.Labels
-}
-func (r *GenericPullRequestResult) GetAssignees() []string {
-	return r.Assignees
-}
-func (r *GenericPullRequestResult) GetMilestone() string {
-	return r.Milestone
-}
-func (r *GenericPullRequestResult) Validate() error {
-	v := validation.New("GenericPullRequestResult")
-	// Just validate the "inner" object
-	v.Append(r.CommitResult.Validate(), r.CommitResult, "CommitResult")
-	return v.Error()
-}
-
-// PullRequestSpec is the messaging interface between the TransactionStorage, and the
-// PullRequestProvider. The PullRequestSpec contains all the needed information for creating
-// a Pull Request successfully.
-type PullRequestSpec interface {
-	// PullRequestSpec is a superset of PullRequestResult.
-	PullRequestResult
-
-	// GetMainBranch returns the main branch of the repository.
-	// +required
-	GetMainBranch() string
-	// GetMergeBranch returns the branch that is pending to be merged into main with this PR.
-	// +required
-	GetMergeBranch() string
-	// GetMergeBranch returns the branch that is pending to be merged into main with this PR.
-	// +required
-	GetRepositoryRef() gitprovider.RepositoryRef
-}
-
-// GenericPullRequestSpec implements PullRequestSpec.
-type GenericPullRequestSpec struct {
-	// GenericPullRequestSpec is a superset of PullRequestResult.
-	PullRequestResult
-
-	// MainBranch returns the main branch of the repository.
-	// +required
-	MainBranch string
-	// MergeBranch returns the branch that is pending to be merged into main with this PR.
-	// +required
-	MergeBranch string
-	// RepositoryRef returns the branch that is pending to be merged into main with this PR.
-	// +required
-	RepositoryRef gitprovider.RepositoryRef
-}
-
-func (r *GenericPullRequestSpec) GetMainBranch() string {
-	return r.MainBranch
-}
-func (r *GenericPullRequestSpec) GetMergeBranch() string {
-	return r.MergeBranch
-}
-func (r *GenericPullRequestSpec) GetRepositoryRef() gitprovider.RepositoryRef {
-	return r.RepositoryRef
-}
-func (r *GenericPullRequestSpec) Validate() error {
-	v := validation.New("GenericPullRequestSpec")
-	// Just validate the "inner" object
-	v.Append(r.PullRequestResult.Validate(), r.PullRequestResult, "PullRequestResult")
-
-	if len(r.MainBranch) == 0 {
-		v.Required("MainBranch")
-	}
-	if len(r.MergeBranch) == 0 {
-		v.Required("MergeBranch")
-	}
-	if r.RepositoryRef == nil {
-		v.Required("RepositoryRef")
-	}
-	return v.Error()
-}
-
-// PullRequestProvider is an interface for providers that can create so-called "Pull Requests",
-// as popularized by Git. A Pull Request is a formal ask for a branch to be merged into the main one.
-// It can be UI-based, as in GitHub and GitLab, or it can be using some other method.
-type PullRequestProvider interface {
-	// CreatePullRequest creates a Pull Request using the given specification.
-	CreatePullRequest(ctx context.Context, spec PullRequestSpec) error
-}
diff --git a/pkg/storage/transaction/pullrequest/github/github.go b/pkg/storage/transaction/pullrequest/github/github.go
deleted file mode 100644
index d8efbd6..0000000
--- a/pkg/storage/transaction/pullrequest/github/github.go
+++ /dev/null
@@ -1,119 +0,0 @@
-package github
-
-import (
-	"context"
-	"errors"
-	"fmt"
-
-	"github.com/fluxcd/go-git-providers/github"
-	"github.com/fluxcd/go-git-providers/gitprovider"
-	gogithub "github.com/google/go-github/v32/github"
-	"github.com/weaveworks/libgitops/pkg/storage/transaction"
-)
-
-// TODO: This package should really only depend on go-git-providers' abstraction interface
-
-var ErrProviderNotSupported = errors.New("only the Github go-git-providers provider is supported at the moment")
-
-// NewGitHubPRProvider returns a new transaction.PullRequestProvider from a gitprovider.Client.
-func NewGitHubPRProvider(c gitprovider.Client) (transaction.PullRequestProvider, error) {
-	// Make sure a Github client was passed
-	if c.ProviderID() != github.ProviderID {
-		return nil, ErrProviderNotSupported
-	}
-	return &prCreator{c}, nil
-}
-
-type prCreator struct {
-	c gitprovider.Client
-}
-
-func (c *prCreator) CreatePullRequest(ctx context.Context, spec transaction.PullRequestSpec) error {
-	// First, validate the input
-	if err := spec.Validate(); err != nil {
-		return fmt.Errorf("given PullRequestSpec wasn't valid")
-	}
-
-	// Use the "raw" go-github client to do this
-	ghClient := c.c.Raw().(*gogithub.Client)
-
-	// Helper variables
-	owner := spec.GetRepositoryRef().GetIdentity()
-	repo := spec.GetRepositoryRef().GetRepository()
-	var body *string
-	if spec.GetDescription() != "" {
-		body = gogithub.String(spec.GetDescription())
-	}
-
-	// Create the Pull Request
-	pr, _, err := ghClient.PullRequests.Create(ctx, owner, repo, &gogithub.NewPullRequest{
-		Head:  gogithub.String(spec.GetMergeBranch()),
-		Base:  gogithub.String(spec.GetMainBranch()),
-		Title: gogithub.String(spec.GetTitle()),
-		Body:  body,
-	})
-	if err != nil {
-		return err
-	}
-
-	// If spec.GetMilestone() is set, fetch the ID of the milestone
-	// Only set milestoneID to non-nil if specified
-	var milestoneID *int
-	if len(spec.GetMilestone()) != 0 {
-		milestoneID, err = getMilestoneID(ctx, ghClient, owner, repo, spec.GetMilestone())
-		if err != nil {
-			return err
-		}
-	}
-
-	// Only set assignees to non-nil if specified
-	var assignees *[]string
-	if a := spec.GetAssignees(); len(a) != 0 {
-		assignees = &a
-	}
-
-	// Only set labels to non-nil if specified
-	var labels *[]string
-	if l := spec.GetLabels(); len(l) != 0 {
-		labels = &l
-	}
-
-	// Only PATCH the PR if any of the fields were set
-	if milestoneID != nil || assignees != nil || labels != nil {
-		_, _, err := ghClient.Issues.Edit(ctx, owner, repo, pr.GetNumber(), &gogithub.IssueRequest{
-			Milestone: milestoneID,
-			Assignees: assignees,
-			Labels:    labels,
-		})
-		if err != nil {
-			return err
-		}
-	}
-
-	return nil
-}
-
-func getMilestoneID(ctx context.Context, c *gogithub.Client, owner, repo, milestoneName string) (*int, error) {
-	// List all milestones in the repo
-	// TODO: This could/should use pagination
-	milestones, _, err := c.Issues.ListMilestones(ctx, owner, repo, &gogithub.MilestoneListOptions{
-		State: "all",
-	})
-	if err != nil {
-		return nil, err
-	}
-	// Loop through all milestones, search for one with the right name
-	for _, milestone := range milestones {
-		// Only consider a milestone with the right name
-		if milestone.GetTitle() != milestoneName {
-			continue
-		}
-		// Validate nil to avoid panics
-		if milestone.Number == nil {
-			return nil, fmt.Errorf("didn't expect milestone Number to be nil: %v", milestone)
-		}
-		// Return the Milestone number
-		return milestone.Number, nil
-	}
-	return nil, fmt.Errorf("couldn't find milestone with name: %s", milestoneName)
-}
diff --git a/pkg/storage/transaction/storage.go b/pkg/storage/transaction/storage.go
deleted file mode 100644
index 8a60e93..0000000
--- a/pkg/storage/transaction/storage.go
+++ /dev/null
@@ -1,28 +0,0 @@
-package transaction
-
-import (
-	"context"
-	"errors"
-
-	"github.com/weaveworks/libgitops/pkg/storage"
-)
-
-var (
-	ErrAbortTransaction      = errors.New("transaction aborted")
-	ErrTransactionActive     = errors.New("transaction is active")
-	ErrNoPullRequestProvider = errors.New("no pull request provider given")
-)
-
-type TransactionFunc func(ctx context.Context, s storage.Storage) (CommitResult, error)
-
-type TransactionStorage interface {
-	storage.ReadStorage
-
-	// Transaction creates a new "stream" (for Git: branch) with the given name, or
-	// prefix if streamName ends with a dash (in that case, a 8-char hash will be appended).
-	// The environment is made sure to be as up-to-date as possible before fn executes. When
-	// fn executes, the given storage can be used to modify the desired state. If you want to
-	// "commit" the changes made in fn, just return nil. If you want to abort, return ErrAbortTransaction.
-	// If you want to
-	Transaction(ctx context.Context, streamName string, fn TransactionFunc) error
-}
diff --git a/pkg/storage/utils.go b/pkg/storage/utils.go
new file mode 100644
index 0000000..d45323b
--- /dev/null
+++ b/pkg/storage/utils.go
@@ -0,0 +1,23 @@
+package storage
+
+import (
+	"fmt"
+
+	"github.com/weaveworks/libgitops/pkg/storage/core"
+)
+
+// VerifyNamespaced verifies that the given GroupKind and namespace parameter follows
+// the rule of the Namespacer.
+func VerifyNamespaced(namespacer core.Namespacer, gk core.GroupKind, ns string) error {
+	// Get namespacing info
+	namespaced, err := namespacer.IsNamespaced(gk)
+	if err != nil {
+		return err
+	}
+	if namespaced && ns == "" {
+		return fmt.Errorf("%w: namespaced kind %v requires non-empty namespace", ErrNamespacedMismatch, gk)
+	} else if !namespaced && ns != "" {
+		return fmt.Errorf("%w: non-namespaced kind %v must not have namespace parameter set", ErrNamespacedMismatch, gk)
+	}
+	return nil
+}
diff --git a/pkg/storage/watch/storage.go b/pkg/storage/watch/storage.go
deleted file mode 100644
index f3d7b0b..0000000
--- a/pkg/storage/watch/storage.go
+++ /dev/null
@@ -1,244 +0,0 @@
-package watch
-
-import (
-	"io/ioutil"
-
-	log "github.com/sirupsen/logrus"
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/serializer"
-	"github.com/weaveworks/libgitops/pkg/storage"
-	"github.com/weaveworks/libgitops/pkg/storage/watch/update"
-	"github.com/weaveworks/libgitops/pkg/util/sync"
-	"github.com/weaveworks/libgitops/pkg/util/watcher"
-	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
-	"k8s.io/apimachinery/pkg/types"
-)
-
-// NewManifestStorage returns a pre-configured GenericWatchStorage backed by a storage.GenericStorage,
-// and a GenericMappedRawStorage for the given manifestDir and Serializer. This should be sufficient
-// for most users that want to watch changes in a directory with manifests.
-func NewManifestStorage(manifestDir string, ser serializer.Serializer) (update.EventStorage, error) {
-	return NewGenericWatchStorage(
-		storage.NewGenericStorage(
-			storage.NewGenericMappedRawStorage(manifestDir),
-			ser,
-			[]runtime.IdentifierFactory{runtime.Metav1NameIdentifier},
-		),
-	)
-}
-
-// NewGenericWatchStorage is an extended Storage implementation, which provides a watcher
-// for watching changes in the directory managed by the embedded Storage's RawStorage.
-// If the RawStorage is a MappedRawStorage instance, it's mappings will automatically
-// be updated by the WatchStorage. Update events are sent to the given event stream.
-// Note: This WatchStorage only works for one-frame files (i.e. only one YAML document
-// per file is supported).
-func NewGenericWatchStorage(s storage.Storage) (update.EventStorage, error) {
-	ws := &GenericWatchStorage{
-		Storage: s,
-	}
-
-	var err error
-	var files []string
-	if ws.watcher, files, err = watcher.NewFileWatcher(s.RawStorage().WatchDir()); err != nil {
-		return nil, err
-	}
-
-	ws.monitor = sync.RunMonitor(func() {
-		ws.monitorFunc(ws.RawStorage(), files) // Offload the file registration to the goroutine
-	})
-
-	return ws, nil
-}
-
-// EventDeleteObjectName is used as the name of an object sent to the
-// GenericWatchStorage's event stream when the the object has been deleted
-const EventDeleteObjectName = "<deleted>"
-
-// GenericWatchStorage implements the WatchStorage interface
-type GenericWatchStorage struct {
-	storage.Storage
-	watcher *watcher.FileWatcher
-	events  update.UpdateStream
-	monitor *sync.Monitor
-}
-
-var _ update.EventStorage = &GenericWatchStorage{}
-
-// Suspend modify events during Create
-func (s *GenericWatchStorage) Create(obj runtime.Object) error {
-	s.watcher.Suspend(watcher.FileEventModify)
-	return s.Storage.Create(obj)
-}
-
-// Suspend modify events during Update
-func (s *GenericWatchStorage) Update(obj runtime.Object) error {
-	s.watcher.Suspend(watcher.FileEventModify)
-	return s.Storage.Update(obj)
-}
-
-// Suspend modify events during Patch
-func (s *GenericWatchStorage) Patch(key storage.ObjectKey, patch []byte) error {
-	s.watcher.Suspend(watcher.FileEventModify)
-	return s.Storage.Patch(key, patch)
-}
-
-// Suspend delete events during Delete
-func (s *GenericWatchStorage) Delete(key storage.ObjectKey) error {
-	s.watcher.Suspend(watcher.FileEventDelete)
-	return s.Storage.Delete(key)
-}
-
-func (s *GenericWatchStorage) SetUpdateStream(eventStream update.UpdateStream) {
-	s.events = eventStream
-}
-
-func (s *GenericWatchStorage) Close() error {
-	s.watcher.Close()
-	s.monitor.Wait()
-	return nil
-}
-
-func (s *GenericWatchStorage) monitorFunc(raw storage.RawStorage, files []string) {
-	log.Debug("GenericWatchStorage: Monitoring thread started")
-	defer log.Debug("GenericWatchStorage: Monitoring thread stopped")
-	var content []byte
-
-	// Send a MODIFY event for all files (and fill the mappings
-	// of the MappedRawStorage) before starting to monitor changes
-	for _, file := range files {
-		content, err := ioutil.ReadFile(file)
-		if err != nil {
-			log.Warnf("Ignoring %q: %v", file, err)
-			continue
-		}
-
-		obj, err := runtime.NewPartialObject(content)
-		if err != nil {
-			log.Warnf("Ignoring %q: %v", file, err)
-			continue
-		}
-
-		// Add a mapping between this object and path
-		s.addMapping(raw, obj, file)
-		// Send the event to the events channel
-		s.sendEvent(update.ObjectEventModify, obj)
-	}
-
-	for {
-		if event, ok := <-s.watcher.GetFileUpdateStream(); ok {
-			var partObj runtime.PartialObject
-			var err error
-
-			var objectEvent update.ObjectEvent
-			switch event.Event {
-			case watcher.FileEventModify:
-				objectEvent = update.ObjectEventModify
-			case watcher.FileEventDelete:
-				objectEvent = update.ObjectEventDelete
-			}
-
-			log.Tracef("GenericWatchStorage: Processing event: %s", event.Event)
-			if event.Event == watcher.FileEventDelete {
-				key, err := raw.GetKey(event.Path)
-				if err != nil {
-					log.Warnf("Failed to retrieve data for %q: %v", event.Path, err)
-					continue
-				}
-
-				// This creates a "fake" Object from the key to be used for
-				// deletion, as the original has already been removed from disk
-				apiVersion, kind := key.GetGVK().ToAPIVersionAndKind()
-				partObj = &runtime.PartialObjectImpl{
-					TypeMeta: metav1.TypeMeta{
-						APIVersion: apiVersion,
-						Kind:       kind,
-					},
-					ObjectMeta: metav1.ObjectMeta{
-						Name: EventDeleteObjectName,
-						// TODO: This doesn't take into account where e.g. the identifier is "{namespace}/{name}"
-						UID: types.UID(key.GetIdentifier()),
-					},
-				}
-				// remove the mapping for this key as it's now deleted
-				s.removeMapping(raw, key)
-			} else {
-				content, err = ioutil.ReadFile(event.Path)
-				if err != nil {
-					log.Warnf("Ignoring %q: %v", event.Path, err)
-					continue
-				}
-
-				if partObj, err = runtime.NewPartialObject(content); err != nil {
-					log.Warnf("Ignoring %q: %v", event.Path, err)
-					continue
-				}
-
-				if event.Event == watcher.FileEventMove {
-					// Update the mappings for the moved file (AddMapping overwrites)
-					s.addMapping(raw, partObj, event.Path)
-
-					// Internal move events are a no-op
-					continue
-				}
-
-				// This is based on the key's existence instead of watcher.EventCreate,
-				// as Objects can get updated (via watcher.FileEventModify) to be conformant
-				if _, err = raw.GetKey(event.Path); err != nil {
-					// Add a mapping between this object and path
-					s.addMapping(raw, partObj, event.Path)
-
-					// This is what actually determines if an Object is created,
-					// so update the event to update.ObjectEventCreate here
-					objectEvent = update.ObjectEventCreate
-				}
-			}
-
-			// Send the objectEvent to the events channel
-			if objectEvent != update.ObjectEventNone {
-				s.sendEvent(objectEvent, partObj)
-			}
-		} else {
-			return
-		}
-	}
-}
-
-func (s *GenericWatchStorage) sendEvent(event update.ObjectEvent, partObj runtime.PartialObject) {
-	if s.events != nil {
-		log.Tracef("GenericWatchStorage: Sending event: %v", event)
-		s.events <- update.Update{
-			Event:         event,
-			PartialObject: partObj,
-			Storage:       s,
-		}
-	}
-}
-
-// addMapping registers a mapping between the given object and the specified path, if raw is a
-// MappedRawStorage. If a given mapping already exists between this object and some path, it
-// will be overridden with the specified new path
-func (s *GenericWatchStorage) addMapping(raw storage.RawStorage, obj runtime.Object, file string) {
-	mapped, ok := raw.(storage.MappedRawStorage)
-	if !ok {
-		return
-	}
-
-	// Let the embedded storage decide using its identifiers how to
-	key, err := s.Storage.ObjectKeyFor(obj)
-	if err != nil {
-		log.Errorf("couldn't get object key for: gvk=%s, uid=%s, name=%s", obj.GetObjectKind().GroupVersionKind(), obj.GetUID(), obj.GetName())
-	}
-
-	mapped.AddMapping(key, file)
-}
-
-// removeMapping removes a mapping a file that doesn't exist
-func (s *GenericWatchStorage) removeMapping(raw storage.RawStorage, key storage.ObjectKey) {
-	mapped, ok := raw.(storage.MappedRawStorage)
-	if !ok {
-		return
-	}
-
-	mapped.RemoveMapping(key)
-}
diff --git a/pkg/storage/watch/update/event.go b/pkg/storage/watch/update/event.go
deleted file mode 100644
index 57367b7..0000000
--- a/pkg/storage/watch/update/event.go
+++ /dev/null
@@ -1,31 +0,0 @@
-package update
-
-import "fmt"
-
-// ObjectEvent is an enum describing a change in an Object's state.
-type ObjectEvent byte
-
-var _ fmt.Stringer = ObjectEvent(0)
-
-const (
-	ObjectEventNone   ObjectEvent = iota // 0
-	ObjectEventCreate                    // 1
-	ObjectEventModify                    // 2
-	ObjectEventDelete                    // 3
-)
-
-func (o ObjectEvent) String() string {
-	switch o {
-	case 0:
-		return "NONE"
-	case 1:
-		return "CREATE"
-	case 2:
-		return "MODIFY"
-	case 3:
-		return "DELETE"
-	}
-
-	// Should never happen
-	return "UNKNOWN"
-}
diff --git a/pkg/storage/watch/update/update.go b/pkg/storage/watch/update/update.go
deleted file mode 100644
index 05ea7e0..0000000
--- a/pkg/storage/watch/update/update.go
+++ /dev/null
@@ -1,28 +0,0 @@
-package update
-
-import (
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/storage"
-)
-
-// Update bundles an FileEvent with an
-// APIType for Storage retrieval.
-type Update struct {
-	Event         ObjectEvent
-	PartialObject runtime.PartialObject
-	Storage       storage.Storage
-}
-
-// UpdateStream is a channel of updates.
-type UpdateStream chan Update
-
-// EventStorage is a storage that exposes an UpdateStream.
-type EventStorage interface {
-	storage.Storage
-
-	// SetUpdateStream gives the EventStorage a channel to send events to.
-	// The caller is responsible for choosing a large enough buffer to avoid
-	// blocking the underlying EventStorage implementation unnecessarily.
-	// TODO: In the future maybe enable sending events to multiple listeners?
-	SetUpdateStream(UpdateStream)
-}
diff --git a/pkg/util/fs.go b/pkg/util/fs.go
deleted file mode 100644
index 3e1f7d4..0000000
--- a/pkg/util/fs.go
+++ /dev/null
@@ -1,23 +0,0 @@
-package util
-
-import (
-	"os"
-)
-
-func PathExists(path string) (bool, os.FileInfo) {
-	info, err := os.Stat(path)
-	if os.IsNotExist(err) {
-		return false, nil
-	}
-
-	return true, info
-}
-
-func FileExists(filename string) bool {
-	exists, info := PathExists(filename)
-	if !exists {
-		return false
-	}
-
-	return !info.IsDir()
-}
diff --git a/pkg/util/patch/patch.go b/pkg/util/patch/patch.go
index 11c29ea..535be55 100644
--- a/pkg/util/patch/patch.go
+++ b/pkg/util/patch/patch.go
@@ -1,103 +1,88 @@
 package patch
 
 import (
-	"bytes"
+	"encoding/json"
 	"fmt"
-	"io/ioutil"
 
-	"github.com/weaveworks/libgitops/pkg/runtime"
-	"github.com/weaveworks/libgitops/pkg/serializer"
-	"k8s.io/apimachinery/pkg/runtime/schema"
+	jsonbytepatcher "github.com/evanphx/json-patch"
+	"k8s.io/apimachinery/pkg/api/errors"
+	"k8s.io/apimachinery/pkg/types"
 	"k8s.io/apimachinery/pkg/util/strategicpatch"
 )
 
-type Patcher interface {
-	Create(new runtime.Object, applyFn func(runtime.Object) error) ([]byte, error)
-	Apply(original, patch []byte, gvk schema.GroupVersionKind) ([]byte, error)
-	ApplyOnFile(filePath string, patch []byte, gvk schema.GroupVersionKind) error
+// BytePatcherForType returns the right BytePatcher for the given
+// patch type.
+//
+// Note: if patchType is unknown, the return value will be nil, so make
+// sure you check the BytePatcher is non-nil before using it!
+func BytePatcherForType(patchType types.PatchType) BytePatcher {
+	switch patchType {
+	case types.JSONPatchType:
+		return JSONBytePatcher{}
+	case types.MergePatchType:
+		return MergeBytePatcher{}
+	case types.StrategicMergePatchType:
+		return StrategicMergeBytePatcher{}
+	default:
+		return nil
+	}
 }
 
-func NewPatcher(s serializer.Serializer) Patcher {
-	return &patcher{serializer: s}
-}
+// maximum number of operations a single json patch may contain.
+const maxJSONBytePatcherOperations = 10000
 
-type patcher struct {
-	serializer serializer.Serializer
+type BytePatcher interface {
+	// TODO: SupportedType() types.PatchType
+	// currentData must be versioned bytes of the same GVK as into and patch.Data() (if merge patch)
+	// into must be an empty object
+	Apply(currentJSON, patchJSON []byte, schema strategicpatch.LookupPatchMeta) ([]byte, error)
 }
 
-// Create is a helper that creates a patch out of the change made in applyFn
-func (p *patcher) Create(new runtime.Object, applyFn func(runtime.Object) error) (patchBytes []byte, err error) {
-	var oldBytes, newBytes bytes.Buffer
-	encoder := p.serializer.Encoder()
-	old := new.DeepCopyObject().(runtime.Object)
-
-	if err = encoder.Encode(serializer.NewJSONFrameWriter(&oldBytes), old); err != nil {
-		return
-	}
-
-	if err = applyFn(new); err != nil {
-		return
-	}
-
-	if err = encoder.Encode(serializer.NewJSONFrameWriter(&newBytes), new); err != nil {
-		return
+type JSONBytePatcher struct{}
+
+func (JSONBytePatcher) Apply(currentJSON, patchJSON []byte, _ strategicpatch.LookupPatchMeta) ([]byte, error) {
+	// sanity check potentially abusive patches
+	// TODO(liggitt): drop this once golang json parser limits stack depth (https://github.com/golang/go/issues/31789)
+	// TODO(luxas): Go v1.15 has the above mentioned patch, what needs changing now?
+	if len(patchJSON) > 1024*1024 {
+		v := []interface{}{}
+		if err := json.Unmarshal(patchJSON, &v); err != nil {
+			return nil, fmt.Errorf("error decoding patch: %v", err)
+		}
 	}
 
-	emptyObj, err := p.serializer.Scheme().New(old.GetObjectKind().GroupVersionKind())
-	if err != nil {
-		return
-	}
-
-	patchBytes, err = strategicpatch.CreateTwoWayMergePatch(oldBytes.Bytes(), newBytes.Bytes(), emptyObj)
-	if err != nil {
-		return nil, fmt.Errorf("CreateTwoWayMergePatch failed: %v", err)
-	}
-
-	return patchBytes, nil
-}
-
-func (p *patcher) Apply(original, patch []byte, gvk schema.GroupVersionKind) ([]byte, error) {
-	emptyObj, err := p.serializer.Scheme().New(gvk)
+	patchObj, err := jsonbytepatcher.DecodePatch(patchJSON)
 	if err != nil {
 		return nil, err
 	}
-
-	b, err := strategicpatch.StrategicMergePatch(original, patch, emptyObj)
-	if err != nil {
-		return nil, err
+	if len(patchObj) > maxJSONBytePatcherOperations {
+		return nil, errors.NewRequestEntityTooLargeError(
+			fmt.Sprintf("The allowed maximum operations in a JSON patch is %d, got %d",
+				maxJSONBytePatcherOperations, len(patchObj)))
 	}
-
-	return p.serializerEncode(b)
+	return patchObj.Apply(currentJSON)
 }
 
-func (p *patcher) ApplyOnFile(filePath string, patch []byte, gvk schema.GroupVersionKind) error {
-	oldContent, err := ioutil.ReadFile(filePath)
-	if err != nil {
-		return err
-	}
-
-	newContent, err := p.Apply(oldContent, patch, gvk)
-	if err != nil {
-		return err
+type MergeBytePatcher struct{}
+
+func (MergeBytePatcher) Apply(currentJSON, patchJSON []byte, _ strategicpatch.LookupPatchMeta) ([]byte, error) {
+	// sanity check potentially abusive patches
+	// TODO(liggitt): drop this once golang json parser limits stack depth (https://github.com/golang/go/issues/31789)
+	// TODO(luxas): Go v1.15 has the above mentioned patch, what needs changing now?
+	if len(patchJSON) > 1024*1024 {
+		v := map[string]interface{}{}
+		if err := json.Unmarshal(patchJSON, &v); err != nil {
+			return nil, errors.NewBadRequest(fmt.Sprintf("error decoding patch: %v", err))
+		}
 	}
 
-	return ioutil.WriteFile(filePath, newContent, 0644)
+	return jsonbytepatcher.MergePatch(currentJSON, patchJSON)
 }
 
-// StrategicMergePatch returns an unindented, unorganized JSON byte slice,
-// this helper takes that as an input and returns the same JSON re-encoded
-// with the serializer so it conforms to a runtime.Object
-// TODO: Just use encoding/json.Indent here instead?
-func (p *patcher) serializerEncode(input []byte) ([]byte, error) {
-	obj, err := p.serializer.Decoder().Decode(serializer.NewJSONFrameReader(serializer.FromBytes(input)))
-	if err != nil {
-		return nil, err
-	}
-
-	var result bytes.Buffer
-	if err := p.serializer.Encoder().Encode(serializer.NewJSONFrameWriter(&result), obj); err != nil {
-		return nil, err
-	}
+type StrategicMergeBytePatcher struct{}
 
-	return result.Bytes(), err
+func (StrategicMergeBytePatcher) Apply(currentJSON, patchJSON []byte, schema strategicpatch.LookupPatchMeta) ([]byte, error) {
+	// TODO: Also check for overflow here?
+	// TODO: What to do when schema is nil? error?
+	return strategicpatch.StrategicMergePatchUsingLookupPatchMeta(currentJSON, patchJSON, schema)
 }
diff --git a/pkg/util/patch/patch_test.go b/pkg/util/patch/patch_test.go
index 9a3cf54..c9d1b01 100644
--- a/pkg/util/patch/patch_test.go
+++ b/pkg/util/patch/patch_test.go
@@ -1,5 +1,9 @@
 package patch
 
+/*
+
+TODO: Create good unit tests for this package!
+
 import (
 	"bytes"
 	"testing"
@@ -58,3 +62,4 @@ func TestApplyPatch(t *testing.T) {
 		t.Fatal(err)
 	}
 }
+*/
diff --git a/pkg/util/sync/monitor.go b/pkg/util/sync/monitor.go
index f09c55c..111a294 100644
--- a/pkg/util/sync/monitor.go
+++ b/pkg/util/sync/monitor.go
@@ -1,31 +1,39 @@
 package sync
 
-import "sync"
+import (
+	"errors"
+	"sync"
+)
 
 // Monitor is a convenience wrapper around
 // starting a goroutine with a wait group,
 // which can be used to wait for the
 // goroutine to stop.
 type Monitor struct {
-	wg *sync.WaitGroup
+	wg  *sync.WaitGroup
+	err error
 }
 
-func RunMonitor(f func()) (m *Monitor) {
-	m = &Monitor{
+func RunMonitor(f func() error) *Monitor {
+	m := &Monitor{
 		wg: new(sync.WaitGroup),
 	}
 
 	m.wg.Add(1)
 	go func() {
-		f()
+		m.err = f()
 		m.wg.Done()
 	}()
 
-	return
+	return m
 }
 
-func (m *Monitor) Wait() {
-	if m != nil {
-		m.wg.Wait()
+func (m *Monitor) Wait() error {
+	// TODO: Do we need this check?
+	if m == nil {
+		return errors.New("Monitor: invalid null pointer to m")
 	}
+	// TODO: maybe this could be easier implemented using just a channel?
+	m.wg.Wait()
+	return m.err
 }
diff --git a/pkg/util/util.go b/pkg/util/util.go
deleted file mode 100644
index c80159c..0000000
--- a/pkg/util/util.go
+++ /dev/null
@@ -1,54 +0,0 @@
-package util
-
-import (
-	"bytes"
-	"crypto/rand"
-	"encoding/hex"
-	"fmt"
-	"os/exec"
-	"strings"
-)
-
-func ExecuteCommand(command string, args ...string) (string, error) {
-	cmd := exec.Command(command, args...)
-	out, err := cmd.CombinedOutput()
-	if err != nil {
-		return "", fmt.Errorf("command %q exited with %q: %v", cmd.Args, out, err)
-	}
-
-	return string(bytes.TrimSpace(out)), nil
-}
-
-func MatchPrefix(prefix string, fields ...string) ([]string, bool) {
-	var prefixMatches, exactMatches []string
-
-	for _, str := range fields {
-		if str == prefix {
-			exactMatches = append(exactMatches, str)
-		} else if strings.HasPrefix(str, prefix) {
-			prefixMatches = append(prefixMatches, str)
-		}
-	}
-
-	// If we have exact matches, return them
-	// and set the exact match boolean
-	if len(exactMatches) > 0 {
-		return exactMatches, true
-	}
-
-	return prefixMatches, false
-}
-
-func BoolPtr(b bool) *bool {
-	return &b
-}
-
-// RandomSHA returns a hex-encoded string from {byteLen} random bytes.
-func RandomSHA(byteLen int) (string, error) {
-	b := make([]byte, byteLen)
-	_, err := rand.Read(b)
-	if err != nil {
-		return "", err
-	}
-	return hex.EncodeToString(b), nil
-}
diff --git a/pkg/util/watcher/dir_traversal.go b/pkg/util/watcher/dir_traversal.go
deleted file mode 100644
index 739ecf7..0000000
--- a/pkg/util/watcher/dir_traversal.go
+++ /dev/null
@@ -1,60 +0,0 @@
-package watcher
-
-import (
-	"os"
-	"path/filepath"
-	"strings"
-)
-
-func (w *FileWatcher) getFiles() ([]string, error) {
-	return WalkDirectoryForFiles(w.dir, w.opts.ValidExtensions, w.opts.ExcludeDirs)
-}
-
-func (w *FileWatcher) validFile(path string) bool {
-	return isValidFile(path, w.opts.ValidExtensions, w.opts.ExcludeDirs)
-}
-
-// WalkDirectoryForFiles discovers all subdirectories and
-// returns a list of valid files in them
-func WalkDirectoryForFiles(dir string, validExts, excludeDirs []string) (files []string, err error) {
-	err = filepath.Walk(dir,
-		func(path string, info os.FileInfo, err error) error {
-			if err != nil {
-				return err
-			}
-
-			if !info.IsDir() {
-				// Only include valid files
-				if isValidFile(path, validExts, excludeDirs) {
-					files = append(files, path)
-				}
-			}
-
-			return nil
-		})
-
-	return
-}
-
-// isValidFile is used to filter out all unsupported
-// files based on if their extension is unknown or
-// if their path contains an excluded directory
-func isValidFile(path string, validExts, excludeDirs []string) bool {
-	parts := strings.Split(filepath.Clean(path), string(os.PathSeparator))
-	ext := filepath.Ext(parts[len(parts)-1])
-	for _, suffix := range validExts {
-		if ext == suffix {
-			return true
-		}
-	}
-
-	for i := 0; i < len(parts)-1; i++ {
-		for _, exclude := range excludeDirs {
-			if parts[i] == exclude {
-				return false
-			}
-		}
-	}
-
-	return false
-}
diff --git a/pkg/util/watcher/event.go b/pkg/util/watcher/event.go
deleted file mode 100644
index 4da933d..0000000
--- a/pkg/util/watcher/event.go
+++ /dev/null
@@ -1,64 +0,0 @@
-package watcher
-
-import (
-	"fmt"
-	"strings"
-)
-
-// FileEvent is an enum describing a change in a file's state
-type FileEvent byte
-
-const (
-	FileEventNone   FileEvent = iota // 0
-	FileEventModify                  // 1
-	FileEventDelete                  // 2
-	FileEventMove                    // 3
-)
-
-func (e FileEvent) String() string {
-	switch e {
-	case 0:
-		return "NONE"
-	case 1:
-		return "MODIFY"
-	case 2:
-		return "DELETE"
-	case 3:
-		return "MOVE"
-	}
-
-	return "UNKNOWN"
-}
-
-// FileEvents is a slice of FileEvents
-type FileEvents []FileEvent
-
-var _ fmt.Stringer = FileEvents{}
-
-func (e FileEvents) String() string {
-	strs := make([]string, 0, len(e))
-	for _, ev := range e {
-		strs = append(strs, ev.String())
-	}
-
-	return strings.Join(strs, ",")
-}
-
-func (e FileEvents) Bytes() []byte {
-	b := make([]byte, 0, len(e))
-	for _, event := range e {
-		b = append(b, byte(event))
-	}
-
-	return b
-}
-
-// FileUpdates is a slice of FileUpdate pointers
-type FileUpdates []*FileUpdate
-
-// FileUpdate is used by watchers to
-// signal the state change of a file.
-type FileUpdate struct {
-	Event FileEvent
-	Path  string
-}
